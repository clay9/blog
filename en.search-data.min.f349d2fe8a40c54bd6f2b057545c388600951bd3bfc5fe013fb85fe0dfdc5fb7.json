[{"id":0,"href":"/blog/docs/prog_base/01_turing/","title":"图灵机","section":"prog base","content":"图灵机是一种计算模型, 告诉\u0026quot;能计算什么\u0026quot; 推荐阅读# pdf: 图灵机与计算 图灵机基本概念# 图灵机由以下部分构成: 无限长的纸带: 每个格子存储一个符号, 初始状态表示输入, 运算结束后纸带包含输出和中间计算结果 读写头: 可以读取当前格符号, 写入符号, 并向左或向右移动一格 内部状态: 来自有限状态集合的一个元素, 表示机器当前的内部信息 程序: 一张规则表δ, 根据当前状态和当前纸带符号, 操控读写头动作 加法计算表示# TODO fix 错误: 输出的是 \u0026#34;1 1\u0026#34;, 而不是\u0026#34;11\u0026#34;. 少了搬运的动作如何用图灵机来描述一个具体的计算呢? 比如计算1+1 纸带初始状态即是输入: \u0026ldquo;1\u0026rdquo;, \u0026ldquo;+\u0026rdquo;, \u0026ldquo;1\u0026rdquo; 输出如何表示呢? 因为图灵机不是直接处理阿拉伯数字, 而是处理符号. 所以我们使用\u0026quot;11\u0026quot; 表示2 初始: 状态为q0, 读写头在纸带的1 处. 程序: internal status input action internal status q0 1 move next q0 q0 + rm +, move next q0 q0 1 move next q0 q0 stop qhalt 读写头的动作为: 1 -\u0026gt; move next /+ -\u0026gt; remove \u0026ldquo;+\u0026rdquo;, move next 1 -\u0026gt; move next -\u0026gt; 停机, 内部状态变为qhalt 这样经过程序计算, 纸带上的结果为: \u0026ldquo;1\u0026rdquo; \u0026quot;\u0026quot; \u0026ldquo;1\u0026rdquo; 也就是\u0026quot;11\u0026quot; 表示2 扩展为通用加法计算 根据上面的1+1, 我们知道数字n可以使用n 个\u0026quot;1\u0026quot;表示 但我们还要知道现在是在读第一个数字还是第二个数字, 因为内部状态q0 表示读第一个数字, q1 表示在读第二个 那么对于n + m, 程序: internal status input action internal status q0 1 move next q0 q0 + rm +, move next q1 q1 1 move next q1 q1 stop qhalt 为什么图灵机上不使用自然数符号. 比如使用\u0026quot;2\u0026quot; 表示2? 图灵机实际不知道符号的含义, 这些符号的含义是我们赋予的, 而图灵机不知道. 要想让图灵机理解符号的含义, 必然要增加内部状态机的复杂度 减法计算表示# TODO 完成一个通用的减法计算假设 4 -2. 纸带初始状态为: 1111-11 输出应该为11 同样使用q0表示读第一个数, q1表示读第二个数. q2 表示在处理减法, 需要找到第一个数 q3 表示已经到了第一个数 初始: 内部状态q0, 读写头在位置0 处. 程序: internal status input action internal status q0 1 move next q0 q0 - move next q1 q1 1 move previous q2 q2 1 move previous q2 q2 - move previous q3 q3 1 rm 1, move next q3 q3 - move next 1111-11 到了-1位置之后, 应该如何处理呢? 可以goto postion 0, 状态为q3, 然后删除\u0026quot;1\u0026quot;. 如果遇到了\u0026quot;-\u0026quot;, 则变为q4, 表示不够删除的了, 到_结束后加1 如果是\u0026quot;-\u0026ldquo;之前遇到了\u0026quot;1\u0026rdquo;, 则删除, 变为q5. q5 遇到- 之后 遇到第二个数的时候, \u0026ldquo;1\u0026rdquo; 要删除, 同时改变status 为q3. 表示在处理减法. 回到postion 0 如果第一个数字够减法, 则减去\u0026quot;1\u0026quot;, 同时变为q0, 再次计算 (这里导致了重复计算, 不如直接回到postion q3) 如果第一个数字不够了, 则stop, 此时, 留在纸带上的就是结果 不可计算# 停机问题# 图灵机模型是如何想出来的# 图灵机是模拟人类计算过程. 假设碰到了一个具体的计算问题, 把这个问题平铺到了很多张纸上, 并且排列好了 \u0026ndash; 纸带 在上面做一些具体的操作? 内部状态? 程序? "},{"id":1,"href":"/blog/docs/philosophy/gtd/","title":"gtd","section":"philosophy","content":"为什么要用GTD# 每天或每周需要处理的事情非常之多, 小到晚上要洗衣服, 大到明天项目交付. 这些事情如果都存储在脑中, 轻则焦虑不堪, 重则脑子爆炸. 而且脑中一旦塞满了这类事情, 非常不利于思考. 大脑应该是拿来思考的, 而不是用来存储的. 假设一种情形, 大脑只用来思考, 而存储则放在大脑之外, 那么我们就不必因当下之外的事情而焦虑, 能够更专一的处理当下的问题. 同时, 如果外在存储能够提醒我们何时该思考何问题, 那么我们也不会因错过了某事而悔恨, 比如女友生日. 而这也是GTD的目的所在, 大脑只用来思考, 存储在脑外. GTD不是用来提升效率的, 它是用来避免混乱的. 当你没有混乱, 就不需要它 GTD是什么# 人生5楼# 了解GTD之前, 必须了解 人生5楼. 楼数 功能 说明 备注 5楼 人生规划 4楼 3年目标 3楼 1年目标 2楼 职责范围 1楼 项目 GTD管理 地面 行动清单 归属1楼 GTD管理 把人生(或部分人生)比喻成一座大厦, 1楼是我们当下要做的事情, 2楼是我们的职责范围, 3楼是我们1年后的样子, 4楼是我们3年后的样子, 5楼是我们人生(10年, 20年或一辈子)的规划. 我们的人生是高层决定了低层 比如, 如果想成为计算机专家(5楼), 那么3年后要先成为工程师(4楼), 1年后要先成为程序员(3楼), 为了要成为程序员, 也许我们需要去报班学习(2楼 职责为学习),或者成为程序员助理(2楼 职责为搬砖), 而1楼则是我们当下要确确实实需要处理的事情, 比如看书, 工作, 交流等, 所有一切能对我们有提升的事情. 大厦是由低到高建造的 千里之行, 始于足下. 1楼的行为直接决定了能否达到后面的楼层. 大厦最难的地方不在于 _实现_ 5楼的规划, 而在于 _制定_ 5楼的规划. 不过这也正是人生的魅力所在吧. GTD是什么# GTD全名Getting things done, 它只是一种思想, 所能管理的是大厦的1楼. 它的核心目的: 事物存储在脑外, 大脑用来思考. GTD的工作流程(算法)甚至文件(结构)都是可以自定义的. 适合的才是最好的. 吐槽: 中文译本《Getting things done》满篇废话. GTD怎么实现# GTD管理的是project和task. project是可完成的目标, 包含一系列task; task是可立即执行的action. project 一定是可完成的. 比如刷leetcode 这种就不是project, 因为没有终条件, 永远无法达到目标 而刷leetcode 10道题, 这种就是project. 其终止条件为10 道题. GTD使用capture - refile - reflect来管理project/task. 快速capture 到 inbox file, 不打断当前思路 自动refile, inbox file 中的project/task 自动refile 到 task file / project file 方便的reflect. 一般两个视角来回顾: 按时间刻度回顾 按project/task 回顾 很多工具都可以实现GTD, 现在使用的是org-agenda "},{"id":2,"href":"/blog/docs/tool/docker/","title":"docker","section":"tools","content":"docker容器 功能# docker vs 虚拟机# 之前以为docker容器就是简约版本的虚拟机, 所以一直想把不同的软件融合到一个镜像中 现在2020.6.21 发现上面的想法是错误的. 现在的认知: docker是对于app(单个软件)的封装 多个软件协同合作的正确方式, 应该是建立多个互相关联的容器, 而不是企图把所有的软件放到一个容器中 配置# 代理配置 国内无法访问dockerhub, 需要配置代理使用. docker的代理需要单独配置, 使用全局代理无效(不知道为什么TODO). 代理需要http和https都要配置, 否则会导致奇怪问题, 比如卡登陆等. 使用# 推荐阅读教程 image# cmd desc docker search search image docker pull pull image docker run image =\u0026gt; container (实例化) docker save,load image =\u0026gt; file, file=\u0026gt;image docker commit container =\u0026gt; image docker tag image tag 修改名字 docker push push image to dockerhub container# cmd desc docker container ls list containers docker container start,stop, restart docker container attach attach to container docker container exec enter container host \u0026amp;\u0026amp; docker container# cmd desc docker cp like cp docker network# 通过指令docker network可以查看 docker中的网桥信息 网桥可以使多个容器组件局域网 容器可以在创建之前选择网桥 1 docker create --name [容器名称] --network [网桥名称] [镜像名称] 容器也可以在运行状态时 选择网桥 1 docker network connect [网桥名称] [容器名称] volume# cmd desc docker volume crate 创建新卷. 新卷默认使用local驱动, 可通过-d来指定不同驱动 docker volume ls list all volumes docker volume inspect show volume details docker volume prune 删除未被容器或者服务副本使用的全部卷 docker volume rm delete volume Dockerfile \u0026amp;\u0026amp; docker-compose# Dockerfile \u0026ndash; 对镜像的管理, 可以安装并修改镜像 (类比C++中的class) docker-compose \u0026ndash; 对容器的管理, 可以指定使用哪个容器, 并能修改容器 (类比C++中的对象实例) Dockerfile# COPY COPY src tag如果tag不存在, 则会创建, 类似mkdir -p 如果src或tag为目录, 则必须以/结尾 src为目录, 复制的时候src自身不会被复制, 只会复制其里面所有子文件 docker-compose# docker-compose 是一个指令, docker-compose.yml是其配置文件. docker-compose -h查看用法 小技巧# 使用镜像的时候, 不一定要做成容器. 可以直接使用 docker run -it image_name 镜像漏洞排查 docker scan "},{"id":3,"href":"/blog/docs/os/mac/","title":"mac","section":"os","content":"界面整理# Launchpad启动台# # 每一列图标数量 defaults write com.apple.dock springboard-rows -int 7 # 每一行图标数量 defaults write com.apple.dock springboard-columns -int 7 # 添加空白到Dock栏 defaults write com.apple.dock persistent-apps -array-add \u0026#39;{\u0026#34;tile-type\u0026#34;=\u0026#34;spacer-tile\u0026#34;;}\u0026#39;; killall Dock # 重启Launchpad (重启时, 会使launchpad的排序恢复默认值) defaults write com.apple.dock ResetLaunchPad -bool TRUE;killall Dock右上角状态栏# 按住Command之后, 鼠标可以拖动状态栏图标, 拖出即可删除 关闭内置键盘(针对mac book)# # For newer versions on MacOS / alternative solution: # List loaded kexts for keyboard kextstat | grep Keyboard # It\u0026#39;s going to output something like: # 81 0 0xffffff7f833c5000 0xb000 0xb000 com.apple.driver.AppleHIDKeyboard (208) 96DDE905-9D31-38A9-96B7-FB28573587C8 \u0026lt;43 6 5 3\u0026gt; # com.apple.driver.AppleHIDKeyboard is loaded kext identifier. # If you want to plug-in Apple Magic Keyboard / some other Bluetooth keyboard, turn it off first. Then follow the instruction below. # To disable keyboard: sudo kextunload -b com.apple.driver.AppleHIDKeyboard # To enable it back: sudo kextload -b com.apple.driver.AppleHIDKeyboard软件推荐# 软件 介绍 备注 Alfred Alfred 是加强版的聚焦搜索 Karabiner Karabiner 是键位映射软件 已舍弃 HomeBrew HomeBrew 是包管理软件(类似于ubuntu下的apt) Annotate Annotate(AppStore下载)是截屏软件, 同时支持gif录制 IINA IINA 是mac下好用的视频软件 Better Display Better Display可以更好的控制显示器, 尤其是对于2K显示器 Q \u0026amp; A# Mac卡顿处理# 删除Macintosh HD/系统/资源库/Caches中的文件 删除Macintosh HD/资源库/Caches中的文件 如果以上无效, 建议更换操作系统版本 SSH远程连接Mac, 中文乱码# 这种情况一般是终端和服务器的字符集不匹配. MacOSX下默认的是utf8字符集(locale查看)，而我的对应值是空的. # 在.bash_profile中增加字符集设置 export LC_ALL=en_US.UTF-8 \u0026gt;\u0026gt; ~/.bash_profile export LANG=en_US.UTF-8 \u0026gt;\u0026gt; ~/.bash_profile # source ~/.bash_profile # 查看结果 localeMac崩溃日志# # 打印mac 24小时崩溃的原因 # 常见原因 # 5 -- 正常关机 # 3 -- 硬件关机 (holding the power button) log show --predicate \u0026#39;eventMessage contains \u0026#34;Previous shutdown cause\u0026#34;\u0026#39; --last 24h开机启动# mac没有像linux使用init作为系统管理, 而是使用Launchd Launchd# 级别 目录 操作系统级别的服务程序 /System/Library/LaunchDaemons /System/Library/LaunchAgents 本机全局 /Library/LaunchDaemons /Library/LaunchAgents 用户级别 ~/Library/LaunchAgents Daemons是一种无用户交互的服务程序, 而Agents是用户交互 当系统启动时, 依次执行/System/Library/LaunchDaemons 和 /Library/LaunchDaemons 当用户登陆时, 依次执行/System/Library/LaunchAgents, /Library/LaunchAgents 和 ~/Library/LaunchAgents 系统启动过程中不能使用图形交互API, 与用户交互的程序不能在系统启动过程中被调用. 定义一个由Launchd管理服务: 定制一个launchd规则的plist文件. 它告诉launchd如何运行一个程序 根据程序运行的方式, 把这个Plist文件存放到合适的位置, 并设置好文件属性等 操作流程# 编写运行程序, 并添加可执行权限 如果是Daemons调用, 需要给于777权限 编写plist文件 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE plist PUBLIC \u0026#34;-//Apple Computer//DTD PLIST 1.0//EN\u0026#34; \u0026#34;http://www.apple.com/DTDs/PropertyList-1.0.dtd\u0026#34;\u0026gt; \u0026lt;plist version=\u0026#34;1.0\u0026#34;\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;Label\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;com.user.loginscript\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;ProgramArguments\u0026lt;/key\u0026gt; \u0026lt;array\u0026gt; \u0026lt;string\u0026gt;/path/to/my/script.sh\u0026lt;/string\u0026gt; \u0026lt;/array\u0026gt; \u0026lt;key\u0026gt;RunAtLoad\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/plist\u0026gt; 根据功能, plist文件放到合适的目录 load plist # load path/to/plist sudo launchctl load -w ~/Library/LaunchAgents/com.service.name.plist # test. com.user.loginscript defined in plist launchctl start com.user.loginscript "},{"id":4,"href":"/blog/docs/os/os/os/","title":"os","section":"os","content":"os学习整理 启动过程# 开机时, CS=0xFFFF, IP=0x0000 寻址0xFFFF0 (ROM BIOS映射区) BIOS: basic input/output system 检查RAM, 键盘, 显示器等硬件(尤其主板) 将磁盘0磁道0扇区(512 bit)读入0x7c00位置 这里就是引导扇区 设置CS=0x7c0, IP=0x0000 线程创建 与 切换# 用户级线程的创建 与 切换 创建: 创建了新的TCB 初始化了栈 切换: 通过调用yeild来实现. yeild中只需要切换TCB即可 内核级线程的创建 与 切换 用户级线程 与 内核级线程 切换: int: 用户 =\u0026gt; 内核 iret: 内核 =\u0026gt; 用户 内核级线程的切换: 类比yeild即可 内核级线程的创建: 创建TCB 初始化栈 注: int的时候, 硬件往内核的TCB中压入了一下信息 SS:SP(栈信息), EFLAGS(??), IP,CS(PC信息), 1000(内核自身的栈调用?) 信号量# 信号量 信号量就是资源信号量sem 表示的是可用资源的个数 负数 : 表示资源已被用完 正数 : 表示有可用的资源 这里只对资源不可用检测, 不会资源上限检测 //结构体 struct Semaphore { int count; PCB* queue; } //函数 P(sem): 消耗资源; P在苏兰语中是test的意思 V(sem): 产生资源; V在苏兰语中是add的意思 // 信号量 被舍弃的原因 在C++20中增加了std::semaphore(与系统的semaphore不同, 只能在同进程的线程间同步) 信号量语义不明. 既可以用来表示互斥, 又可以用来表示同步 互斥可以使用mutex代替; 同步可以使用condition代替. 加锁, 解锁不在一个线程, 容易导致错误 信号量的加解锁可以不在统一个线程(进程), 容易导致错误, 且不容易发现; mutex规定了必须在同一个线程加解锁, 容易发现错误 生产者, 消费者中 使用2个信号量来处理 第一个信号量 表示一共有多少个位置可用(缓冲区可用位置) producer消耗(--)该资源, consumer产生(++)该资源第二个信号量 表示当前缓冲区的个数 producer产生该资源, consumer消耗该资源 临界区(原子操作)# 临界区 (原子操作) 原则: 互斥进入 有空让进 有限等待 如何生成临界区: 软件方法 a. Peterson算法(2个线程) b. filter算法(多个线程) 硬件方法 a. 关中断, 处理完之后, 再开中断 (不适用现在的硬件了, 现在基本都是多cpu) 关中断之后, 就不会切换进程了. 所以就是临界区了. 但是多cpu无效. 因为中断与cpu绑定b. 原子指令 (mutex) 不会被打断的指令即原子指令. 由硬件设计的 内存 段# 找到一块空闲的内存, 把程序放入内存, 然后由cpu取指执行 逻辑地址 =\u0026gt; 物理地址的 重定位 可以在 编译, 载入, 运行 时重定位运行时重定位 =\u0026gt; 地址翻译 为了能够运行时重定位, 需要进程可以在内存中换入,换出 //段 : 实际对应的虚拟内存 为了更好的管理内存, 对进程进行了分段, 不同类型的代码(数据)放入不同的段(寄存器) 比如代码放入cs, 数据放入ds, 栈放入ss, 函数库(lib,dll)放入其他的寄存器(??) 每个段(寄存器)都有不同的特性(属性), 比如代码段不应该修改, 堆栈是可增长的, 函数库按需加载或不加载 PCB中存放 段的信息即进程段表LDT(存放在寄存器LDTR中 R:register) 而且LDT 和 GDT非常类似. GDT是OS的段表, LDT是进程的段表 分段更像是从人(程序员)的角度 去管理的内存//页 : 实际对应的物理内存 os初始化的时候, mem_map中的初始化 分页是从内存(机器)的角度 去管理的内存//段 与 页 把段分割成页. 比如代码段需要2.3页, 那么就给它3页. 在内存中找未使用的3页 这3页分配到的内存可能是不连续的. 所以段需要知道 对应的 内存地址 使用页表(在寄存器cr3中)来表示. 所以每个段都有自己的页表 段分割成的页就是虚拟地址, 虚拟地址和页框(物理页)通过MMU硬件转换 段-\u0026gt;页 页框(物理页) 保护 0 5 R 1 7 R/W 2 6 R #offset# \u0026ndash; #page# 0-12 \u0026ndash; 12-15 jmp [0x2240] 就是0x2240 右移12bit, 即0x2; 说明jmp 到第2页. 再从页表中找到第二页对应的页框(物理页), 找到页框6 对应的物理地址就是 页框6 + offset, 即0x6240 0x2240 -\u0026gt; 0x6240的获取是由硬件(MMU)计算的 //总结1 程序由多个段组成, 每个段切割成多个页放到物理内存中的页中. 以后根据页表查找内存地址 //总结2 process -\u0026gt; segment -\u0026gt; page(virtual) -\u0026gt; page(物理) 先建立段表 LDT (放到寄存器) 每个段建立 页表(v-\u0026gt;物理) virtual page就是虚拟内存 页表放到内存中的 多级页表 与 快表# 为了提高内存空间利用率, 单张页应该小. 导致进程的页表非常大 (4G内存/4K页大小 = 1M) 页大小为4K, 地址是32位的. 就会有2^20个页面. 如果2^20页面都放入内存中, 就需要4M内存. 单个进程就需要这么大了, 100个进程, 就需要400M了 实际上, 2^20中的大部分项都不会用到. 所以可以把页表改小 所以引入多级页表和快表, 用来减少页表大小 页号 物理页 保护 页号 物理页 保护 0 5 R 0 5 R 1 1 R/W # 修改为=\u0026gt; # 1 1 R/W 2 3 4 R 3 4 R 新的页表, 不再连续, 但是已经排好序了. 可以使用二分法查找 log(2^20)=20 因为页表在内存中, 导致每次操作内存, 都会额外查找20次. 导致机器性能下降10-20% 所以这种页表 虽然节省了内存空间, 但是性能降低太多了//多级页表 10bits \u0026ndash; 10bits \u0026ndash; 12bits 多级页表空间上高效了, 但是效率降低了; 增加了一层访问, 要先看章再看节. 所以多访问了一次内存(章). //快表 (TLB) TLB是一组相连快速存储, 是寄存器. 可以非常快速的找到最近逻辑页使用的物理页号 //快表 与 多级页表 如果 快表命中, 则直接使用快表, 非常快 否则, 使用多级页表 //总结 虚拟内存-\u0026gt;物理 (硬件MMU处理) 为了减少页表的内存size, 使用多级页表 为了加快访问, 使用快表(TLB) TLB能显著加快访问速度, 因为只需要在内存中读取一次, 而多级页表在32bits中需要读取2次(先读章,再读节) register 寄存器# 常用register 通用寄存器 (数据寄存器)# ax, bx, cx, dx (rax, rbx, rcx, rdx) 一般用来存放数据, 也就数据寄存器 AX(Accumulator Register) ：累加寄存器，它主要用于输入/输出和大规模的指令运算。 BX(Base Register)：基址寄存器，用来存储基础访问地址 CX(Count Register)：计数寄存器，CX 寄存器在迭代的操作中会循环计数 DX(data Register)：数据寄存器，它也用于输入/输出操作。它还与 AX 寄存器以及 DX 一起使用，用于涉及大数值的乘法和除法运算。 段寄存器# CS(Code Segment) ：代码寄存器，程序代码的基础位置 DS(Data Segment)：数据寄存器，变量的基本位置 SS(Stack Segment)：栈寄存器，栈的基础位置 ES(Extra Segment)：其他寄存器，内存中变量的其他基本位置。 https://zhuanlan.zhihu.com/p/324210723 索引寄存器# BP(Base Pointer)：基础指针，它是栈寄存器上的偏移量，用来定位栈上变量 SP(Stack Pointer): 栈指针，它是栈寄存器上的偏移量，用来定位栈顶 SI(Source Index): 变址寄存器，用来拷贝源字符串 DI(Destination Index): 目标变址寄存器，用来复制到目标字符串 状态和控制寄存器# IP(Instruction Pointer)：指令指针寄存器，它是从 Code Segment 代码寄存器处的偏移来存储执行的下一条指令 FLAG: Flag 寄存器用于存储当前进程的状态 待整理 TODONOW# 图灵机 =\u0026gt; 通用图灵机 图灵机的控制器是单一的, 比如只能计算加法的加法控制器 通用图灵机是指 控制器通用了 PC, IP, CS CS, IP是两个寄存器. 通过两个寄存器的值运算得到指令的地址, 也就是PC的值 CS: code segment 代码段寄存器 IP: instruction pointer 指令指针寄存器 PC: program count 程序计数器 16位机: CS\u0026lt;\u0026lt;4 + IP 只有20bit. 能访问的内存很小 32位机(即保护模式): PC = 根据CS在gdt中查表 + IP gdt: global describe table(硬件设置的) POSIX 指定了标准的系统调用(system_call) POSIX: Portable Operating System Interface of Unix 系统调用 != 函数调用 系统调用 不能像 普通函数调用那样直接jump 防止直接jump的手段 是通过硬件设计完成的 内核态, 用户态 不允许从用户段jump到内核段 普通函数 想访问 系统调用(内核函数), 只能通过中断(int 0x80) int 0x80 会把CPL设置为0, 允许用户段访问内核段 多进程 共用cpu, 所以有了PCB 共用内存, 所以有了 虚拟内存(内存映射) cpu调度算法 使用单变量counter可以完美实现, 参考linux 0.11 FIFO (公平原则) 短作业优先 轮转调度 Robin 优先级 锁很慢, 慢在哪 //锁机制 尝试使用硬件指令获得锁(现在一般是 compare and swap), 如果获得失败, 则使用内核提供的锁调用. //慢的原因 跨cpu调度 (\u0026gt; 2000ns) cpu自身调度 (900ns) 上下文切换 (150ns) cache不命中 (消耗时间??) TLB不命中 (这是什么?? 消耗时间??) //优化 本质是减少锁冲突 颗粒度. 加锁的范围要小 不要在锁的过程中做阻塞操作 使用读写锁. 读操作之间不互斥 自旋锁 如果锁的时间 \u0026lt; 调度时间, 那么可以自旋 自旋: 循环调用硬件指令获得锁 compare and swap, 一般100次左右 Q \u0026amp; A# 如果高级语言C, C++都是在系统调用(system_call), 那么std::cout 和 printf 为什么会有差异 效率的差异主要体现在哪?? schedule()=\u0026gt;switch_to() 中为什么需要用汇编来精准控制? 教程中说是需要精准控制寄存器. 那么在计算机中, 寄存器的状态是怎样的 多进程通信中的 同步问题 产生同步问题的根因: 多进程交互执行 原子操作, 锁 等都可以解决同步问题 函数调用栈 \u0026amp;\u0026amp; 寄存器信息 保存在TCB中, 那么PCB中会保存什么信息? 函数栈, TCB, esp之间的关系 函数栈: 函数调用栈 TCB: 除了关联(has?)函数栈, 还有PC信息 esp: 寄存器?? 这是什么的寄存器? 或者说 寄存器的作用 A: 寄存器类型: ax,bx,cx,dx, cs,ds,ss, ip, sp sp是16 bit; 后来有了32bit的, 就改名esp; 再后来又有了64bit的, 起名rsp 为什么没有觉得操作系统很复杂?? 当前进度: 多进程视图中的 进程切换 后续: 多进程通信(同步) mem, file 等其他视图 中断本质是什么 指令流水是什么? L12 再学习 先自己画图 再自己写一遍代码 与课程中的对照 信号量课程, 添加了sem之后, 还是需要从唤醒队列中拿取. 既然这样, 直接从唤醒队列中拿取就可以了, 为什么还需要sem sem表示了资源的个数, 只有资源被消耗完之后, 才会变为-1,-2. 信号量课程, 如何保证sem的准确(锁? 原子操作) 参考 临界区 cpu流水指令, cache缓存 CAS compare and swap 实现逻辑 使用银行家算法 来判断是否会 死锁 是否可使用向量来判断? 进程页表中的逻辑地址为什么不会全部使用?? 比如 有页表0,1,2,3. 但是可能只有0,1,3使用了, 但是2未使用 why ?? 已知: 进程 =\u0026gt; (代码, 数据, 栈等)段 =\u0026gt; 每个段都有自己的页表 如果是这样, 为什么还会空着页号呢??? 会不会之前申请了某块内存a(产生了页3), 继续申请(产生页4), 释放内存a, 所以页3空了?? "},{"id":5,"href":"/blog/docs/emacs/org/org/","title":"org","section":"org","content":"org-mode一直被称为神器 主要有2大功能, 一是自身强大的文本模式(依赖 org-mode), 另一个则是 org-agenda 推荐阅读: org心得体会 "},{"id":6,"href":"/blog/docs/emacs/emacs/","title":"emacs","section":"emacs","content":"简述# emacs是什么# emacs最原始,最纯粹的功能: text editor 也可以作为优秀的 program editor 优秀的文本 gtd 软件 良好的扩展性, 很多优秀插件, 比如org,magit,tramp,eshell等 综上, emacs其实更像一个大杂烩, 整合了大多数功能, 使其可以高效的完成任务. 同时, 因为良好的定制性, emacs可以增强个人使用体验, 但也增加了很多学习成本 emacs配置# emacs配置可大致划分如下 emacs作为程序的基本配置 text editor \u0026amp;\u0026amp; completion prog editor org \u0026amp;\u0026amp; gtd 键位设置 编译emacs# # --without-all 最小化编译 (但是包含了x) # --without-x 不使用x # --with-gnutls=ifavailable 移除configure警告 (实际并未编译) # --with-tree-sittter 开启tree-sitter # --with-xml2 package::devdocs依赖 # --with-native-compilation 之前的gccEmacs(据传可增加运行效率) (未使用) ./configure --without-all --without-x --with-gnutls=ifavailable --without-pop --with-tree-sitter --with-xml2 --with-native-compilation 基本配置# emacs作为程序的基本配置 themes ui界面显示 frame window font file recentf files buffers sessions text editor# 文本编辑器是emacs最原始, 最纯粹, 最重要的功能. 大部分配置都是在处理该项, 使其更符合个人习惯. 配置繁琐, 但不复杂 show# text editor最基本的配置, 文本在buffer中显示的样子. 比如行号, break-line, column indicator等 move-and-kill# 即是text editor, 也是emacs最基础的操作. delete, kill, yank, select. 这是emacs中最基础的操作 hide-show# hide, show 方便控制sexp的显示隐藏 completion# text editor的配置使我们可以高效的编辑文本. 而completion则可以使emacs更聪明的理解我们的动作. emacs有非常多的completion前端和后端, 也有前后端大杂烩. 没必要都了解, 选一个常用的即可. completion流程: complete根据我们动作提供候选者 -\u0026gt; 前端显示候选者 -\u0026gt; 我们选择合适的候选 流程本身非常简单, 涉及到的package也很少, 比较复杂的是候选者的提供, 而这个不需要我们自己去做. 现在的方案 ([2023-11-01 Wed]): consult提供候选, vertico \u0026amp;\u0026amp; corfu作为前端显示, marginalia补充候选者信息, orderless过滤候选者. embark提供对候选者的操作. 几个package提供了功能的最小合集, 且与emacs兼容性良好. 因此不再建议使用helm等大杂烩包 其他一些package也是在提供候选, 比如yasnippet, eglot, copilot等. 因为针对的场景不同, 暂时不在这里介绍 prog editor# emacs可以配置为优秀的IDE. 而且因为定制性强, 配置的IDE更能符合个人的工作流程. 合格的IDE需要有以下功能: 编辑, 编译, 调试, 发布 emacs内置了lsp client: eglot. 而且eglot与错误处理flymake搭配良好. eglot可以把lsp server中的错误信息给到flymake, completion信息给到corfu(实际是给到emacs completion通用接口), symbol信息给到xerf 键位设置# 原则# 尽量保留默认常用快捷键 不同mode, 尽量使用相似的快捷键 前缀快捷键# key desc C-s 通用快捷键(与mode无关的 or 所有mode都会使用的) C-j mode自身快捷键 C-d 项目相关快捷键 C-r tool 快捷键 tty keys# step remap tty(console) 物理code =\u0026gt; Sequences Event code emacs: input-decode-map Sequences Event code =\u0026gt; 第一层转换 emacs: local-function-key-map 第一层转换 =\u0026gt; emacs可识别的 emacs : global-set-key等 eamcs可识别的 =\u0026gt; function 由于tty(console)对于有些key(比如C-backspace)等未作Sequences Event code. 所以其(C-backspace)的表现和backspace可能是一样的. 第一步, 先在console中对需要的key 设定Sequences Event code. 第二部, 在emacs的input-decode-map中将这些Sequences Event code映射为我们的按键 详见init-tty-keys.el Ctrl# sdf key command desc a beging-of-line b back-of-char c Prefix d c-d self-Prefix e end-of-line f forward-of-char g quit h Prefix i Tab j self-Prefix k kill l recenter-top-bottom m Enter n forward line o open-line p backward line q r self-Prefix s self-Prefix t u universal-argument v scroll buffer w kill/kill-save x Prefix y yank z "},{"id":7,"href":"/blog/docs/os/socket/socket/","title":"socket base","section":"socket","content":"socket相关网络编程 基本概念# socket# socket是 [应用层] 与 [传输层, 网络层] 之间的一个抽象层 它的出现是为了简化网络进程通信 linux头文件# usr/include/x86_64-linux-gnu/sys/socket.h 结构体 sockaddr 函数 socket() connect() send() recv() shutdown() socket() bind() lisent() accept() recv() send() shutdown() g++的默认目录中已经包含了sys/的上层目录 usr/include/netinet/in.h 结构体 AF_INET 中的 sockaddr_in AF_INET6 中的 sockaddr_in6 AF_UNIx 中的 sockaddr_un user/include/arpa/inet.h 函数 htons() inet_addr() unistd.h 函数 close() socket函数# socket(domain, socket_type, protol) domain socket_type protol socket()本质是创建了一个进程文件表, 返回的值为指向进程文件表的指针的索引. bind(fd, sockaddr*, len) fd: socket()中的文件表指针的索引 sockaddr: 地址, 端口 len: sockaddr的长度 \u0026lt;1\u0026gt; 比较有意思的是sockaddr根据family的不同, 可以与不同的结构体互转 比如 AF_INET sockaddr_in AF_INET6 sockaddr_in6 AF_UNIX sockaddr_un 这几种结构体都与sockaddr可互转(字节对齐blabla) bind()本质是在补充socket()创建的文件表. socket()时候该文件表很多值都是空的, bind()来补充 因为client 在connect的时候, 系统会自动分配端口,以及绑定本机ip, 所以client的socket一般不必要 使用bind() connet(fd, sockaddr*, len) 连接到其他scokaddr listen(fd, iMaxNum) iMaxNum是队列中的最大数, 并不是指可连接的socket数目一般只在server开启listen(), 监听指定的端口信息 accept() accept()会造成阻塞. 它会将listen()中的sockaddr进行处理 处理流程是 accept()会创建一个新的fd_connet, 此fd_connet公用server socket() fd的端口和地址 但是fd_connect仅仅是用来传输数据的 recv(fd, msg) send(fd, msg) 至accetp()时候, 一切操作就和在本地上操作一样, 所以这里的recv() 和 send()操作与本机上的文件操作是一样的 close(fd) shutdown(fd, type) linux一切皆是file原则, fd可以关闭 [ip, port]相关函数# 点分十进制ip 是以字符串形式存储的 网络字节序 即 32位的二进制//in_addr struct in_addr { in_addr_t s_addr; }; //in_addr_t typedef unsigned long in_addr_t 函数原型: in_addr_t inet_addr(const char* strptr); 若字符串有效, 则将点分十进制IP字符串转换为网络字节序地址，否则为INADDR_NONE 函数原型：int inet_aton(const char *IP, struct in_addr *addr); 将点分十进制IP地址转换为网络字节序存储在addr中，并且返回该网络字节序表示的无符号整数 函数原型：char *inet_ntoa(struct in_addr in); 将网络字节序的IP地址（也就是结构体in_addr类型变量）转化为点分十进制的IP地址（字符串) socket fd本质# socket本质是维护了fd进程文件表, 如下: 名称 说明 备注 fd 文件描述符, 表的索引 host 1. 域名(DNS /etc/hosts) 2. ip地址 兼容Ipv4 Ipv6是难点 服务 1. 服务名称(/etc/services) 2. 端口 协议 1. 传输层(/etc/protol) 2. 网络层 链路层用到的比较少 网络 1. 网络名称?(DNS /etc/networks) 2. ip地址 谁会使用到这些信息?? 期间用到的函数主要有 尽量使用ipv4, ipv6通用的函数 流程函数 socket() bind() listen() connect() accept()等 字节处理函数 处理大小字节序 htons() htonl() ntohs() ntohl() 处理域名与十分数字 getaddrinfo() getnameinfo() 处理sockaddr结构体的函数 getsockname() 返回local fd getpeername() 返回remote fd socket问题# 阻塞 影响并发, 多路复用解决方案: 使用非阻塞模型, 比如select, poll, epoll(linux下特有), IOCP(windows下特有) 多线程 \u0026ndash; 不推荐使用 多进程 \u0026ndash; 不推荐使用 粘包 解决方案: 限制发送大小 每个消息增加长度标识 I/O模型# 强烈建议阅读 (链接过期, 直接搜狗搜索epoll, \u0026ldquo;epoll本质\u0026quot;即是) 阻塞式 非阻塞 select poll epoll (linux特有) IOCP (windows特有) epoll使用# epoll本身为我们处理了什么# 之前socket::recv()时, 导致我们的进程阻塞 现在socket::recv()时, 使epoll阻塞; epoll中断时, 告之进程 有了epoll我们还需要处理什么# 创建epoll对象 添加检视的fd对象 \u0026ndash; op, epoll_event 检测是否有中断, 然后处理 socket属性# keep live机制# 当socket服务端开启keep live之后, 服务器检测到 一定时间内 socket不活动的时候, 就会每隔 固定时间 向该sockt发送 固定次数 的查询. 如果一直没有回应, 服务端则关闭该socket 对应的字段为: tcp_keepalive_time（开启keepalive的闲置时长） tcp_keepalive_intvl（keepalive探测包的发送间隔） tcp_keepalive_probes （如果对方不予应答，探测包的发送次数）编程实例# 原始socket模型, recv()中处理分包粘包# 原始socket模型, 考虑到tcp分包 //网络读取 -- 系统检测到网络I/O事件时, 调用该函数 LRESULT CTCPSocketService::OnSocketNotifyRead(WPARAM wParam, LPARAM lParam) { //读取数据 //使用中间量m+cbRecvbuf来当做缓冲区 //使用中间量m_wRecvsize来记录当前缓冲区中已读数据大小 int iRetCode = recv(m_hSocket, (char *)m_cbRecvBuf + m_wRecvSize, sizeof(m_cbRecvBuf) - m_wRecvSize, 0); //读取失败, 则返回SOCKET_ERROR if (iRetCode == SOCKET_ERROR) { ZeroMemory(m_cbRecvBuf, sizeof(m_cbRecvBuf)); m_wRecvSize = 0; return 1;//\u0026#34;网络连接关闭，读取数据失败\u0026#34;; } //读取成功, 则返回读取到的数据的大小 m_wRecvSize += iRetCode; //在tcp数据中, 增加包的大小, 用来校验是否读取完毕; TCP_Head * pHead = (TCP_Head *)m_cbRecvBuf; WORD wPacketSize = pHead-\u0026gt;TCPInfo.wPacketSize; // //数据包大小校验 if (wPacketSize \u0026gt; (SOCKET_TCP_BUFFER + sizeof(TCP_Head))) { //当发生错误时候, 缓冲区置位 ZeroMemory(m_cbRecvBuf, sizeof(m_cbRecvBuf)); m_wRecvSize = 0; return 3;//\u0026#34;数据包太大\u0026#34;; } //解析数据 if (m_wRecvSize == wPacketSize) //数据全部接受完毕之后 再解析 { //拷贝数据 BYTE cbDataBuffer[SOCKET_TCP_BUFFER+sizeof(TCP_Head)]; CopyMemory(cbDataBuffer, m_cbRecvBuf, wPacketSize); //置位缓冲信息 -- 缓冲区中只保存一条tcp信息 m_wRecvSize = 0; ZeroMemory(m_cbRecvBuf, sizeof(m_cbRecvBuf)); //解密数据 WORD wRealySize = CrevasseBuffer(cbDataBuffer, wPacketSize); if(wRealySize \u0026lt; sizeof(TCP_Head)) return 4; //解析后的数据错误 //获得TCP_Head TCP_Command Command = ((TCP_Head *)cbDataBuffer)-\u0026gt;CommandInfo; //获得实际的数据 void * pDataBuffer = cbDataBuffer + sizeof(TCP_Head); //实际的数据 WORD wRealDataSize = wRealySize - sizeof(TCP_Head); //实际的数据大小 //内核命令 if (Command.wMainCmdID == MDM_KN_COMMAND) { switch (Command.wSubCmdID) { case SUB_KN_DETECT_SOCKET:\t//网络检测 { //发送数据 SendData(MDM_KN_COMMAND, SUB_KN_DETECT_SOCKET, pDataBuffer, wRealDataSize); break; } } continue; } //处理数据 bool bSuccess = m_QueueServiceEvent.PostTCPSocketReadEvent(m_wServiceID, Command, pDataBuffer, wRealDataSize); if (bSuccess == false) return 5;//\u0026#34;网络数据包处理失败\u0026#34;; }; return 0; }ipv4# 系统文件在/proc/sys/net/ipv4下面ip_local_port_range # 用户端口范围, [n, m) tcp_timestamp # 针对TIME_WAIT状态的tcp连接; 0关闭,1开启 tcp_tw_recycle # 是否快速回收+ linux内核已删除该字段 tcp_tw_reuse # TIME_WAIT状态的tcp的port是否可以复用;0关闭,1开启 # 需要开启tcp_timestamp; # 这是针对cli的设计,而非svr tcp_rmem # tcp read缓冲区 tcp_wmem # tcp write缓冲区ip_forward 0禁止ip转发, 1打开; ip_default_ttl 数据报的生存周期(time to live), 即最多经过多少路由器 ip_no_pmtu_disc 关闭路径MTU探测 min_pmtu 最小路径MTU的大小 mtu_expires PMTU信息缓存多长时间"},{"id":8,"href":"/blog/docs/prog_vc/git/","title":"git","section":"prog vc","content":"git简易指导, 个人使用心得 git使用流程# git原理# git特性# tag# 获取最近的tag git describe --abbrev=0 --tags 查看2个tag(或HEAD, 或branch)之间的距离, A与B之间的距离(或B与A之间的距离) 如果未branch_name, 实际为branch上的HEAD节点git log --pretty=oneline tagA...tagB查看从A到B的距离, 而不是从B到A的距离 If you just wanted commits reachable from tagB but not tagA: git log --pretty=oneline tagA..tagB #或者 git log --pretty=oneline ^tagA tagB 简化SHA信息 \u0026ndash;abbrev-commit # 一般--pretty=oneline 后面都会加 --abbrev-commit git log --pretty=oneline --abbrev-commit git高级特性# git hooks# 参考文档 删除大文件# 寻找大文件 git rev-list --objects --all | grep \u0026#34;$(git verify-pack -v .git/objects/pack/*.idx | sort -k 3 -n | tail -5 | awk \u0026#39;{print$1}\u0026#39;)\u0026#34; 删除大文件 git filter-branch -f --prune-empty --index-filter \u0026#39;git rm -rf --cached --ignore-unmatch your-file-name\u0026#39; --tag-name-filter cat -- --all 删除之后 git gc --prune=now git lfs# 把大文件排除在git仓库之外, git仓库中只有一个指针指向该大文件 安装lfs# curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash \u0026amp;\u0026amp; sudo apt-get install git-lfs \u0026amp;\u0026amp; git lfs install初始化# git lfs install使用# 过滤大文件 git lfs track file_path 过滤之后, 会生成.gitattributes 提交到远端 git push \u0026ndash; 提交普通文件 git lfs push \u0026ndash; 提交lfs文件 下载大文件 git lfs clone url git submodule# 参考文档 https://www.cnblogs.com/nicksheng/p/6201711.html 当项目越来越庞大之后，不可避免的要拆分成多个子模块， 我们希望各个子模块有独立的版本管理，并且由专门的人去维护，这时候我们就要用到git的submodule功能 submodule 管理的不是分支, 而是一个commit #递归的方式克隆整个项目 git clone \u0026lt;repository\u0026gt; --recursive #添加子模块 git submodule add --branch branch_name \u0026lt;repository\u0026gt; \u0026lt;path\u0026gt; #初始化子模块 -- 根据.gitmodule文件clone子模块 git submodule init # 更新子模块 参数remote表示拉取远端最新的而非仓库对应的; init同上 git submodule update --remote --init # 拉取所有子模块 git submodule foreach git pull 拉取子模块# 方法1 先clone父项目 更新子模块 git submodule update --init 方法2 clone 父项目时 加 \u0026ndash;recursive git clone url path --recursive F\u0026amp;Q# 问: 命令行下的git status如何显示中文 答：git config --global core.quotepath false 问：在命令行下(gnu-bash)中git不能补全git的命令 1) 首先获得源码 git clone git://git.kernel.org/pub/scm/git/git.git 1) 从源码中拷贝git-completion.bash到用户主目录下. git-completion.bash cp git/contrib/completion/git-completion.bash ~/.git-completion.bash 2) 在 .bashrc 中加入 source ~/.git-completion.bash 3) 在shell下执行 . ~/.bashrc 问: 如何取消对文件的跟踪 答: 分情况而定 1) 对于从没有追踪过的文件, 只需要设置.gitignore即可 2) 对于已经追踪过的文件, 需要git rm --cached (-r) file 然后再加入到.gitignoe中即可 git对大小写不敏感问题, 可以通过下面命令修改 git config core.ignorecase false 修改git默认的编辑器 git config --global core.editor \u0026#34;\u0026#39;D:/notepad++/notepad++.exe\u0026#39; -multiInst -notabbar -nosession -noPlugin\u0026#34; "},{"id":9,"href":"/blog/docs/prog_lsp/global/","title":"global","section":"prog lsp","content":"在project中生成TAGS文件, 方便索引 建议使用lsp代替, global响应虽然快速, 但是不如lsp实时定位方便安装# sudo apt install global使用# # step1 make tag-files (GPATH, GRTAGS, GTAGS) gtags # *step2 maybe make htlm htags # step3 find global X #find tag global -r X #find rtag global -s X #find symbolGPATH, GRTAGS, GTAGS# GTAGS 中包含了定义 GRTAGS中包含了引用 GPATH 中是路径名字 对于C++来说 tag包含了class, struct, global-function \u0026amp;\u0026amp; class-function 但是不包含class-symbol(成员变量), 局部变量, 全局变量 rtags中包含了tag中内容的引用 和 非tag中内容的引用(比如成员变量) 所以使用global来查找的时候, 参数非常有必要. 比如 global X 是在GTAGS中查找, 所以是查找不到成员变量的, 因为成员变量没有在GTAGS中 global -r X 是在GRTAGS中查找GTAGS中定义的内容的引用, 所以也是查找不到成员变量的 global -s X 与-r相反, 是在GRTAGS中查找没有在GTAGS中定义内容的引用, 所以可以查找成员变量, 局部变量, 全局变量等 对于C++的.h文件# 通过gtags \u0026ndash;config可以查看gtags生成tags-file的配置 wangruoxudeMacBook-Pro:~ clay$ gtags --config :skip=HTML/,HTML.pub/,tags,TAGS,ID,y.tab.c,y.tab.h,gtags.files,cscope.files,cscope.out,cscope.po.out,cscope.in.out,SCCS/,RCS/,CVS/,CVSROOT/,{arch}/,autom4te.cache/,*.orig,*.rej,*.bak,*~,#*#,*.swp,*.tmp,*_flymake.*,*_flymake,*.o,*.a,*.so,*.lo,*.zip,*.gz,*.bz2,*.xz,*.lzh,*.Z,*.tgz,*.min.js,*min.css:langmap=c\\:.c.h,yacc\\:.y,asm\\:.s.S,java\\:.java,cpp\\:.c++.cc.hh.cpp.cxx.hxx.hpp.C.H,php\\:.php.php3.phtml很明显上面会把.h当作c来处理, 而非C++, 因此我们需要修改其默认行为 # GTAGSFORCECPP 设置为非nil, 表示把.h当作C++来处理 export GTAGSFORCECPP=1参考资料# 官方文档 "},{"id":10,"href":"/blog/docs/prog_language/c++/c++/","title":"c++历史","section":"c++","content":"通过C++历史, 更好的了解C++特性 演变# 1979 诞生# 刚开始叫做New C, 后改名C with Classes 诞生目的: 便于大型软件开发 \u0026amp;\u0026amp; 运行效率 过 程: 增强C语言特性 (选C原因: C用途广, 快速, 可移植性) 新增特性: 类别 衍生类别 存储类型检查 内联 缺省参数 1983 改名C++# 新增特性: 虚拟函数 函数名 运算子多载 参考 ??? 常数 使用者可控制的自由空间存储区控制 改良的型别检查 单行注释 // 1985 发布第一版# 非官方发布 ?? 这时候有官方了??? 1989 发布Release 2.0# 新增特性: 多重继承 抽象类别 静态成员函数 常数成员函数 成员保护 1990 出版了 标准化基础# ??哪一年??稍后还引入了模板例外处理、命名空间、新的强制类型转换，以及布林类型 1998 C++98 第一个C++标准# 标准分为 核心语言 \u0026amp;\u0026amp; C++标准程序库 C++标准程序库主要包含 STL \u0026amp;\u0026amp; C标准库的稍加修改版 语言特性: classes 相关 构造 \u0026amp;\u0026amp; 析构 friend 继承 多态 静态成员 new delete 高级概念 ?? 高级在哪?? 需要对比当时的环境 模板 命名空间 异常 类型转换 隐式转换 \u0026amp;\u0026amp; 显式转换 stl: 异常 \u0026lt;exception\u0026gt; 类型检查 \u0026lt;typeinfo\u0026gt; 输入输出 \u0026lt;iostream\u0026gt; 2003 C++03 第二个C++标准# C++03 主要是在C++98基础上针对实现方的一些问题进行了修复，从而在各个实现间达到一致、保持了可移植性。 该版本共涉及 92 项核心语言缺陷报告、125 项库缺陷报告，所提供的新特性只有一项：值初始化（value initialization） 实现方是指编译器 ??需要重点看一下当时的编译器有哪些?? 对于使用者(程序员)来说, C++03与C++98差异不大(只有一条 值初始化)2006 C++性能技术报告# 2007 C++技术报告: 库扩展# 2010 数学函数扩展# 2011 C++11 第三个C++标准# 先前被称作C++0x, 本预计2000-2009间会发布, 结果一直拖到了2011年. 因此改名C++11. 参考资料 相比于C++03，C++11标准包含核心语言的新机能， 而且扩展C++标准程序库，并入了大部分的C++ Technical Report 1程序库（数学的特殊函数除外) 设计原则# 维持稳定性和与C++98，可能的话还有C之间的兼容性； 尽可能不透过核心语言的扩展，而是透过标准程序库来引进新的特性； 能够演进编程技术的变更优先； 改进C++以帮助系统以及库设计，而不是引进只针对特别应用的新特性； 增进类别安全，提供对现行不安全的技术更安全的替代方案； 增进直接对硬件工作的能力与表现； 提供现实世界中问题的适当解决方案； 实行“zero-overhead”原则（某些功能要求的额外支持只有在该功能被使用时才能使用）； 使C++易于教授与学习 语言变更# C++委员会的主要作用之一是改善语言核心。核心语言将被大幅改善的领域包括 多线程支持 泛型编程 统一的初始化 以及性能表现的加强 在此分成4个区块来讨论核心语言的特色以及变更: 执行期表现强化、构造期表现强化、可用性强化，还有新的功能。 某些特性可能会同时属于多个区块，但在此仅于其最具代表性的区块描述 执行期表现强化\n提升某些性能表现, 像是内存或者速度上的提升 右值引用 \u0026amp;\u0026amp; std::move \u0026amp;\u0026amp; std::forward\n右值引用是语言特性, std::move \u0026amp;\u0026amp; std::forward是stl中新增的函数 (头文件\u0026lt;utility\u0026gt;) 符合设计原则2, 使用stl补充语言特性右值引用的本质是为了解决C++之前版本的深度copy问题. wiki参考资料 template \u0026lt;typename T, typename Arg\u0026gt; shared_ptr\u0026lt;T\u0026gt; factory(Arg arg) { return shared_ptr\u0026lt;T\u0026gt;( new T(arg)); }template \u0026lt;typename T, typename Arg\u0026gt; shared_ptr\u0026lt;T\u0026gt; factory(Arg\u0026amp; arg) { return shared_ptr\u0026lt;T\u0026gt;( new T(arg)); }template\u0026lt; typename T, typename Arg\u0026gt; shared_ptr\u0026lt;T\u0026gt; factory(const Arg\u0026amp; arg) { //无法修改arg对象 return shared_ptr\u0026lt;T\u0026gt;( new T(arg)); }template\u0026lt;typename T, typename Arg\u0026gt; shared_ptr\u0026lt;T\u0026gt; factory(Arg\u0026amp;\u0026amp; arg) { return shared_ptr\u0026lt;T\u0026gt;(new T(std::forward\u0026lt;Arg\u0026gt;(arg))); } /* 调用时候, 参数如果是左值, 只需要std::move()获取对应的右值 *///两者都在\u0026lt;utility\u0026gt;头文件 //std::move(arg) 可以获取左值的右值引用 // 因为右值引用是将原对象的内容移动到新对象, 所以原对象移动后不应再使用 //std::forward\u0026lt;T\u0026gt;(arg) 可以获取arg的T属性. // T如果为int, 则使用arg的右值 // T若果为int\u0026amp;, 则使用arg的左值右值引用使用场景: 上面的exp所展示的 就是在以传值方式传递对象时隐式发生的耗时且不必要的深度拷贝。 举例而言，std::vector\u0026lt;T\u0026gt;本质上是一个C-style数组及其大小的封装， 如果一个std::vector\u0026lt;T\u0026gt;的临时对象是在函数内部或者函数返回时创建， 要将其存储就只能透过生成新的std::vector\u0026lt;T\u0026gt;并且把该临时对象所有的资料复制过去 然后该临时对象会被析构，其使用的内存会被释放 std::vector\u0026lt;int\u0026gt; test(){ std::vector\u0026lt;int\u0026gt; vec_data; //一些操作 //... //返回vec_data实际是 //1.创建了一个新的std::vector\u0026lt;int\u0026gt; 临时对象 //2.把vec_data对象深度copy给 临时对象 //3.返回临时对象 //4.销毁vec_data对象 // // 其中深度copy会造成非常大的开销, 导致性能低下 return vec_data; }std::vector\u0026lt;int\u0026gt; test(){ std::vector\u0026lt;int\u0026gt; vec_data; //一些操作 //... // //1.创建一个新的std::vector\u0026lt;int\u0026gt; 临时对象 //2.把vec_data对象移动到 临时对象 //3.返回临时对象 //4.销毁vec_data对象 // //对比旧版本, 这里少了深度copy这一层 return std::vector\u0026lt;int\u0026gt; (std::move(vec_data) ); } 注意事项 对象被右值引用后, 再操作会导致不可预知的问题(内存相关信息已被置为null) 并非所有情形都合适. 应该使用在避免深度copy的场合 constexpr 泛化的常量表达式\nconstexpr确保对象在编译期完成初始化操作, 因此加快运行期的效率 //const 与 constexpr 均表示该表达式(对象或函数)被声明为常量 //const 不保证对象经历哪种类型的初始化, 可能是编译器初始化, 也可能是运行期初始化 //constexpr 保证对象使用编译器初始化 //const演示 int get_number(){ return 5; } const int mx = get_number(); //mx是常量对象, 但在运行期获得初始化 int arr[mx] ; //错误. 因为mx是在运行期获得初始化; 而int[]需要编译器的常量 //constexpr演示 constexpr int get_number(){ return 5; } int arr[get_number()]; //正确. 因为constexpr保证函数get_number调用在编译器初始化//修饰函数表达式 //函数主体必须是非虚拟的，并且除了 typedef 和静态断言之外，仅包含一个 return 语句 constexpr int max() { return 4; } // ok constexpr long long_max() { return 23423424; } //ok constexpr bool get_val(){ bool res = false; return res; } //error: body只能有一个return statement //修饰变量 //与const类似 //修饰构造函数 //构造函数可以有一个成员初始化列表, 但body必须是空的 //constexpr构造函数 允许编译器在编译时初始化对象, 前提是构造函数的参数都是常量表达式 struct complex { constexpr complex(double r, double i) : re(r), im(i) { } // ok double re; double im; } constexpr complex cx0(0.0, 1.0); //ok. 编译期初始化 double x = 1.0; constexpr complex cx1(x, 0); //error: x不是常量表达式 const complex cx2(x, 0); //ok. 运行期初始化 constexpr double xx = 1.0; constexpr complex cx3(xx, 0); //ok 编译期初始化 complex cx4(1.0, 2.0); //ok 运行期初始化 对POD定义的修正\n?? 这是什么, 完全没有看懂 ?? 构造期表现强化\n外部模版\n在标准C++中，只要在编译单元内遇到被完整定义的模板，编译器都必须将其实例化（instantiate） 这会大大增加编译时间，特别是模板在许多编译单元内使用相同的参数实例化。 C++11之前, 可以告诉编译器在特定位置开始实例化, 但无法告诉编译器不要引发模板实例化 template class std::vector\u0026lt;MyClass\u0026gt;;C++11增加了 阻止编译器在编译期间引发模板实例化 extern template class std::vector\u0026lt;MyClass\u0026gt;; 可用性的加强\n初始化列表\n初始化列表的构想是 结构(或数组)的成员依据定义的顺序 由一串形参产生. struct Test{ int a; double b; int c; } //给予 Test一串形参, Test的成员根据位置,自动获得初始化 //Test成员a, b, c根据自己在Test结构中定义的顺序, 自动与形参1, 2.0, 3获得匹配的初始化 //即a=1, b=2.0, c=3 Test t1{1, 2.0, 3};//C++11 增加了初始化列表构造函数 std::initializer_list\u0026lt;\u0026gt; class Test{ public: Test(std::initializer_list\u0026lt;int\u0026gt; list); //初始化列表构造函数 } Test test{1, 2, 3, 4}; //允许Test对象可以像这样初始化 //初始化列表构造函数的优先级大于普通的构造函数 class Test{ public: Test(std::initializer_list\u0026lt;int\u0026gt; list); //初始化列表构造函数 Test(int i): m_i(i) { }; //普通构造函数 private: int m_i; } //当初始化列表构造函数 与 普通构造函数形参一致的时候, //如果使用{}初始化, 将调用的是初始化列表构造函数 //比如下面调用的是 Test(std::initializer_list\u0026lt;int\u0026gt; list); Test test{1}; //如果想调用普通构造函数, 应该使用标准的构造函数语法 //调用的是 Test(init i); Test test(1);//std::initializer_list除了可以在构造函数中使用, 也可用于普通函数 void Fun(std::initializer_list\u0026lt;int\u0026gt; list); Fun(1, 2, 3); 统一的初始化\nstruct BasicStruct{ int x; float y; } struct AltStruct{ AltStruct(int _x, float _y): x(_x), y(_y) {} private: int x; float y; } //两者都可以采用一样的初始化样式 BasicStruct val1 {5, 2.1f}; AltStruct val2 {2, 2.1f}; auto \u0026amp;\u0026amp; decltype\nC++03使用参数必须明确的指出其类别. 然而随着模板类别的出现以及模板元编程的技巧, 某物的类别, 特被是函数定义明确的返回类别, 不容易表示. C++11提供了auto 自动类别推导, 来解决该问题 有被明确初始化的参数可以使用auto. 对于指针类型, 使用auto 和 auto*是一样的. 对于引用类型, 必须使用auto\u0026amp;. 因为auto总是推断出非引用类型 基于范围的for循环\n简化了for循环. 可以使用在C型数组, 初始化列表, 和任何定义了begin(), end()的类型 int my_array[5] {1, 2, 3, 4, 5}; //每个元素 * 2 //注意这里是auto\u0026amp;, 而非auto for (auto\u0026amp; x : my_array){ x *= 2; } lambda函数表达式 返回类别后置的函数声明\n?? 看样子, 主要用于模板中函数的返回类别 ?? class对象构造改良\n//C++11之前, 构造函数不允许调用其他构造函数 //C++11, 取消了该限制, 允许构造函数调用其他构造函数, 这种做法称为委托构造 class SomeType{ public: SomeType() : SomeType(0, \u0026#34;hahah\u0026#34;) {} SomeType(int i) : SomeType(i, \u0026#34;haha222\u0026#34;) {} SomeType(string\u0026amp; s) : SomeType(1, s) { test(); } private: SomeType(int i, string\u0026amp; s): m_i(i), m_s(s) {} int m_i; string m_s; };//C++03 基类的构造函数不能直接作为派生类的构造函数, 每个派生类必须实现自己的构造函数 //C++11 取消了该限制. 编译器可以使用基类的构造函数完成派生类的构造 //而将基类的构造函数带入派生类的动作. 无法选择性的部分带入. //要么全部带入, 要么一个都不带入 class BaseClass{ public: BaseClass(int v); }; class DerivedClass :public BaseClass { public: using BaseClass::BaseClass; //使用基类的构造函数 };//C++03 class 成员变量只能在构造函数中被初始化 //C++11 取消了该限制, 使其可以在声明的地方初始化 class SomeClass{ public: SomeClass() {} //当构造函数中未初始化m_val时, 使用定义的值45 SomeClass(int i) : m_val(i) {} //如果构造函数中初始化了m_val, 则使用构造函数中的值 private: int m_val = 45; int m_test {45}; //也可以使用列表初始化的样式 }; 显示虚函数重载\nstruct Base{ virtual void func(int); }; struct Derived : Base{ virtual void func(int) override; //ok 显示重载 virtual void func(float) override; //error: struct Base中没有对应的虚函数 };struct Base{ virtual void func(int) final; }; struct Derived : Base{ virtual void func(int); //error: struct Base:func 禁止重载 }; 空指针\n//C++11之前, 使用NULL来表示0和空指针 ( C的做法 ) //但是在函数重载时候, 就容易引发歧义 void foo (char*); void foo (int); void foo (nullptr_t); //调用的实际是 void foo(int); 而非void foo(nullptr_t) foo(NULL) //C++11引入了nullptr 用来表示指针 //这样调用的就是 void foo(nullptr_t) foo(nullptr) 强类型枚举\n?? 不是很明白 这个的意义在哪 ?? ?? 枚举不和int比较, 不会很限制使用场景吗 ?? 角括号\nC++03的分析器一律把 \u0026gt;\u0026gt; 视为右移运算符. 为了避免, 编码时候不能把\u0026gt;\u0026gt;连着写. 尤其在模板编码中 C++11变更了分析器规则, 使其更加智能 显式类别转换 explicit\n?? 完全没有印象 ?? 模板的别名\n?? 对模板 完全不熟悉 ?? 模板参数的缺省值 无限制的unions\n?? 需要详细了解一下 ?? 能力的提升\n这些特性让C++语言能够做一些以前做不到的，或者极其复杂的，或者需求一些不可移植的库的事情。 可变参数模板\n?? 又是模板\u0026hellip; ?? 字符串字面值\n//C++03 提供了两种字符串字面值 \u0026#34;abc\u0026#34; //产生以空字符\\0结尾的 const char 数组 L\u0026#34;abc\u0026#34; //产生以空字符\\0结尾的 const wchat_t数组 //C++11加强了对Unicode的支持, //类别char的定义被修改为其大小至少能够存储UTF-8的8位编码, 并且能够容纳编译器的基本字符集的任何成员 //新增char16_t, char32_t, 分别对应UTF-16, UTF-32 u8\u0026#34;I\u0026#39;m a UTF-8 string.\u0026#34; u\u0026#34;I\u0026#39;m a UTF-16 string.\u0026#34; U\u0026#34;I\u0026#39;m a UTF-32 string.\u0026#34; //并且允许直接在字符串内插入unicode codepoints // \\u之后的是16 bits的十六进制数值; // \\U之后的是32 bits的十六进制数值 u8\u0026#34;This is a Unicode Character: \\u2018.\u0026#34; u\u0026#34;This is a bigger Unicode Character: \\u2018.\u0026#34; u8\u0026#34;This is a Unicode Character: \\U00002018.\u0026#34;R\u0026#34;(The String Data \\ Stuff \u0026#34; )\u0026#34; //()中的内容不会被转义 //R 可以和 u8/u/U组合使用 u8R\u0026#34;(I\u0026#39;m a \u0026#34;raw UTF-8\u0026#34; string.)\u0026#34; 用户定义字面值\nC++11开放用户定义新的字面修饰符（literal modifier），利用自定义的修饰符完成由字面值构造对象。 字面值转换可以定义为两个阶段：原始与转换后（raw与cooked) 原始字面值指特定类型的字符序列，而转换后的字面值则代表另一种类别。 如字面值1234，原始字面值是'1\u0026rsquo;, \u0026lsquo;2\u0026rsquo;, \u0026lsquo;3\u0026rsquo;, \u0026lsquo;4\u0026rsquo;的字符序列； 而转换后的字面值是整数值1234。另外，字面值0xA转换前是序列'0\u0026rsquo;, \u0026lsquo;x\u0026rsquo;, \u0026lsquo;A\u0026rsquo;；转换后代表整数值10。 ?? 如何使用 ?? 多线程编程支持\nC++标准委员会计划统一对多线程编程的支持. 这将涉及两个部分： 设计一个可以使多个线程在一个进程中共存的内存模型； 为线程之间的交互提供支持. 这部分将由程序库提供支持 在多个线程可能会访问相同内存的情形下，由一个内存模型对它们进行调度是非常有必要的。 遵守模型规则的程序是被保证正确运行的， 但违反规则的程序会发生不可预料的行为，这些行为依赖于编译器的优化和内存一致性的问题。 虽然C++11会在语言的定义上提供一个内存模型以支持线程，但线程的使用主要将以C++11标准库的方式呈现。 C++11标准库会提供类别thread（std::thread）。若要执行一个线程，可以创建一个类别thread的实体，其初始参数为一个函数对象，以及该函数对象所需要的参数。透过成员函数std::thread::join()对线程会合的支持，一个线程可以暂停直到其它线程执行完毕。若有底层平台支持，成员函数std::thread::native_handle()将可提供对原生线程对象执行平台特定的操作。 对于线程间的同步，标准库将会提供适当的互斥锁（像是std::mutex，std::recursive_mutex等等）和条件参数（std::condition_variable和std::condition_variable_any）。前述同步机制将会以RAII锁（std::lock_guard和std::unique_lock）和锁相关算法的方式呈现，以方便程序员使用。 对于要求高性能，或是极底层的工作，有时或甚至是必须的，我们希望线程间的通信能避免互斥锁使用上的开销。以原子操作来访问内存可以达成此目的。针对不同情况，我们可以透过显性的内存屏障改变该访问内存动作的可见性。 对于线程间异步的传输，C++11标准库加入了以及std::packaged_task用来包装一个会传回异步结果的函数调用。因为缺少结合数个future的功能，和无法判定一组promise集合中的某一个promise是否完成，futures此一提案因此而受到了批评。 更高级的线程支持，如线程池，已经决定留待在未来的Technical Report加入此类支持。更高级的线程支持不会是C++11的一部分，但设想是其最终实现将创建在目前已有的线程支持之上。 std::async提供了一个简便方法以用来执行线程，并将线程绑定在std::future。用户可以选择一个工作是要多个线程上异步的执行，或是在一个线程上执行并等待其所需要的资料。默认的情况，实现可以根据底层硬件选择前面两个选项的其中之一。另外在较简单的使用情形下，实现也可以利用线程池提供支持。 ?? 后期重点查看 ?? thread-local的存储期限 使用或禁用对象的默认函数\n//C++03中, 用户无法精确控制class的默认函数, 比如默认构造函数, 默认复制构造函数, 默认赋值运算符等 //比方说, 要让class不能被copy, 必须将复制构造函数 与 赋值运算符声明为private, 并不去定义他们. // 这样尝试使用这些为定义的函数会导致编译期或连接器错误 // 但这种手法一点也不理想 // //C++11允许显示的声明采用或禁用编译器提供的内置函数 // struct SomeType{ SomeType() = default; //使用默认的构造函数 }; // struct NonCopyable{ //禁用复制构造函数 \u0026amp;\u0026amp; 赋值运算符 NonCopyable \u0026amp; operator=(const NonCopyable\u0026amp; ) = delete; NonCopyable (const NonCopyable\u0026amp; ) = delete; NonCopyable () = default; } long long int类型\n在32位系统上，一个long long int是保有至少64个有效比特的整数类别。 C99将这个类别引入了标准C中，目前大多数的C++编译器也支持这种类别。 C++11将把这种类别添加到标准C++中。 静态assertion sizeof运算符可以作用于class的所有成员\n//C++11之前, sizeof运算符只能用于class的静态成员 //C++11修改为均可使用 struct SomeType{ OtherType member; }; sizeof(SomeType::member); //传回OtherType的大小 //?? 如果成员是vector数组, 会是什么样 ?? 垃圾回收机制\n?? 没明白\u0026hellip; ?? stl变更# stl组件上的升级\n基于C++11新特性, 实现stl的更优 右值引用和其相关的move支持 支持UTF-16编码，和UTF-32字符集 变长参数模板（与右值引用搭配可以达成完美转发（perfect forwarding）） 编译期常量表达式 Decltype 显式类别转换子 使用或禁用对象的默认函数 线程支持 多元组类别 散列表 正则表达式 通用智能指针 可扩展的随机数功能\n?? C++版本的 也太麻烦了把 \u0026hellip; ?? 包装引用\n?? 与模板有关 ?? 对函数对象的包装 用于元编程的类别属性\n?? ?? ?? 用于计算函数对象返回类型的统一方法 itoa函数\niota 函数可将给定区间的值设定为从某值开始的连续值， 例如将连续十个整数设定为从 1 开始的连续整数（即 1、2、3、4、5、6、7、8、9、10）。 #include \u0026lt;iostream\u0026gt; #include \u0026lt;array\u0026gt; #include \u0026lt;numeric\u0026gt; std::array\u0026lt;int, 10\u0026gt; ai; std::iota(ai.begin(), ai.end(), 1); for(int i: ai){ std::cout\u0026lt;\u0026lt;i\u0026lt;\u0026lt;\u0026#34; \u0026#34;;//1 2 3 4 5 6 7 8 9 10 }?? 貌似 作用不大呀 ?? 2011 十进制浮点数扩展# 2014 C++14 第四个C++标准# C++14旨在作为C++11的一个小扩展, 主要提供漏洞修复和小的改进. 参考资料 语言特性变更# 泛型的lambda\n?? 这是什么玩意 ?? //C++11中, lambda函数的形参必须被声明为具体的类型 //C++14 放宽了这个要求 auto lambda = [](auto x, auto y) { return x + y; } lambda捕获部分中使用表达式\nC++11的lambda函数允许通过 [值copy 或 引用] 捕获已在外层作用域声明的变量. C++14允许lambda成员用任意的被捕获表达式初始化.意味着: 允许 capture by value-move 允许任意声明的lambda成员, 而不需要外层作用域有一个具有相应名字的变量.这称为广义捕获. 即使在闭包区域中存在相同的变量也会被新变量覆盖(只是在lambda中被覆盖). 新变量类型由他的初始化表达式推导, 类似与auto //val新变量不需要特意声明类型, 会根据auto自动推导 //lambda的返回值为1, 说明新变量val成功被初始化 auto lambda = [val = 1]{ return val; } //另一个例子 auto x = 1; //lambda捕获中, r是x(外部x)的引用; x是新变量(会在lambda中覆盖外部变量x) //此处的新变量r为1; 新变量x为10 auto f = [\u0026amp;r=x, x=x*10]{ ++ r; return r + x; } //结果是外部变量x被设置为2; f()返回12 f(); 函数返回类型推导\nC++11允许lambda函数根据return语句的表达式类型推断返回类型; C++14为一般的函数也提供了这个功能. ?? 真的完全想不通这种不易阅读的特性 到底有什么用 ?? decltype(auto)\nconst int x = 0; auto x1 = x; //x1为int类型 decltype(auto) x2 = x; //x2为const int类型 int y =0; int\u0026amp; y1 = y; auto y2 = y1; //int类型 decltype(auto) y3=y1; //int\u0026amp; int\u0026amp;\u0026amp; z =0; auto z1 = std::move(z); //int decltype(auto) z2 = std::move(z); //int\u0026amp;\u0026amp;//函数返回类型为int auto f (const int\u0026amp; i) { return i; } //函数返回类型为const int\u0026amp; decltype(auto) g (const int\u0026amp; i) { return i; } constexpr函数放宽限制\nC++11对constexpr函数做了严格的限制, 允许的语句非常少(基本就是一条return语句\u0026hellip;) C++14放宽了该限制. 允许constexpr有以下内容: 任何声明, 除了 static 或 thread_local变量 没有初始化的变量声明 条件分支语句 if \u0026amp;\u0026amp; switch 所有的循环语句, 包含range for 循环 表达式可以改变一个对象的值 需要该对象的生命期在声明为constexpr的函数内部开始, 包括对有constexpr声明的任何非const非静态成员函数的调用. 此外，C++11指出，所有被声明为constexpr的非静态成员函数也隐含声明为const（即函数不能修改*this的值） C++14中这点已经被删除，非静态成员函数可以为非const 变量模板\nC++14之前模板可以是函数模板或类模板 C++14中引入了变量模板 class对象构造优化 (聚合类的成员初始化)\nC++11中class的成员变量可以在声明的地方初始化. 但是如果构造函数中未定义该变量, 那么该class就不允许使用聚合初始化; C++14中放松了这一限制 struct Test{ int m_x; int m_y = 40; Test(int x) : m_x(x) {} }; Test t1{1}; //在C++11中是不允许的, 因为Test的构造函数Test(int x)中未初始化m_y Test t2{1}; //在C++14中是合法的. m_y会使用默认值40 二进制字面量\nC++14的数字允许使用二进制形式指定.使用前缀0b或0B. 数字分位符\nC++14引入单引号 \u0026rsquo; 作为数字分位符号, 使得数值型的字母量更好的可读性. auto integer_literal = 100\u0026#39;0000; auto floating_point_literal = 1.797\u0026#39;693\u0026#39;134\u0026#39;862\u0026#39;315\u0026#39;7E+308; auto binary_literal = 0b0100\u0026#39;1100\u0026#39;0110; auto silly_example = 1\u0026#39;0\u0026#39;0\u0026#39;000\u0026#39;00; deprecated属性\ndeprecated属性允许标记不推荐使用的实体，该实体仍然能合法使用， 但会让用户注意到使用它是不受欢迎的，并且可能会导致在编译期间输出警告消息。 deprecated可以有一个可选的字符串文字作为参数，以解释弃用的原因和/或建议替代者。 [[deprecated]] void f(); [[deprecated(\u0026#34;g() is unsafe, use h() instead\u0026#34;)]] void g(); void test(){ f(); //warnning: f()已被弃用 g(); //warnning: g() is unsafe, use h() instead } stl变更# 共享的互斥体和锁\nC++14增加了一类共享的互斥体和相应的共享锁 起初选择的名字是std::shared_mutex，但由于后来增加了与std::timed_mutex相似的特性，std::shared_timed_mutex成为了更适合的名字 元函数的别名 关联容器中的异构查找\nC++标准库定义了四个关联容器类。 set和multiset允许用户根据一个值在容器中查找对应的的同类型的值。 map和multimap容器允许用户指定键（key）和值（value）的类型，根据键进行查找并返回对应的值。 然而，查找只能接受指定类型的参数，在map和multimap中是键的类型，而在set和multiset容器中就是值本身的类型。 C++14允许通过其他类型进行查找，只需要这个类型和实际的键类型之间可以进行比较操作。[ 这允许std::set\u0026lt;std::string\u0026gt;使用const char*，或任何可以通过operator\u0026lt; 与std::string比较的类型作为查找的参数。 为保证向后兼容性，这种异构查找只在提供给关联容器的比较器允许的情况下有效。 标准库的泛型比较器，如std::less\u0026lt;\u0026gt;与std::greater\u0026lt;\u0026gt;允许异构查找 stl自定义字面量\nC++11增加了自定义字面量的语言特性. C++14的stl中利用了这个特性 C++14 stl定义了如下字面量后缀 s 创建各种std::basic_string类型 h, min, s, ms, us, ns 创建相应的std::chrono::duration时间间隔 if, i, il 创建std::complex\u0026lt;float\u0026gt;, std::complex\u0026lt;double\u0026gt;, std::complex\u0026lt;long double\u0026gt;复数类型 这些字面量可以用于编译时的constexpr //两个s互补干扰, 表示std::basic_string的s只能对字符串字面量操作, 而表示秒的只针对数字. auto str = \u0026#34;hello world\u0026#34;s; auto dur = 60s; auto z = 99i; 通过类型寻址多元组\nC++11引入的std::tuple类型允许不同类型的值的聚合体用编译期整型常数索引。 C++14还允许使用类型代替常数索引，从多元组中获取对象。 若多元组含有多于一个这个类型的对象，将会产生一个编译错误 tuple\u0026lt;string, string, int\u0026gt; t(\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;, 7); int i = get\u0026lt;2\u0026gt;(t); //i = 7; C++11 int j = get\u0026lt;int\u0026gt;(t); //j = 7; C++14新增 string s = get\u0026lt;string\u0026gt;(t); //编译错误, 歧义 较小的标准库特性\nstd::make_unique可以像std::make_shared一样使用, 用于产生std::unique_str对象 std::is_finale用于识别一个class类型是否禁止被继承 std::integral_constant增加了一个返回常量值的operator() 全局std::begin/std::end函数之外, 增加了std::cbegin/std::cend函数, 用于返回常量迭代器 constant iterators 2015 文件系统# 2015 用于并行计算的扩展# 2015 事务性内存操作# 2015 概念库, 用于优化编译期信息# 2016 用于并行计算的扩展# 2017 标准库扩展# 2017 提供范围机制# 2017 协程库扩展# 2017 C++17 第五个C++标准# C++17旨在作为大型扩展. 参考资料 ?? 新功能 ??# static_assert无需提供出错信息 具有模板形式的模板参数允许使用typename (之前只能使用class) std::uncaught_excepitions取代std::uncaught_exception 变长参数模板的Folding运算 容器访问操作表示方法的统一化 连续迭代器 新增特殊数学函数 语言特性# u8字面量\n//C++11的时候, u8可以修饰字符串 //C++17新增了u8可以修饰单个字符 char x = u8\u0026#39;x\u0026#39;; 使noexcept成为系统的一部分\n?? 需要再仔细的查看 ?? noexcept在C++11中首次加入, 作用是抛出异常, 取代throw ?? 为什么取代throw ?? C++17中使其成为了系统的一部分 ??什么意思?? {}列表初始化的自动推导规则\n具体详见C++11中的说明 初始化列表 //C++11中会被推导为 std::initializer_list\u0026lt;int\u0026gt; //C++17中推导为 int auto x {3}; lambda函数按值捕获this指针\nC++17之前, lambda只能按引用捕获this指针 C++17允许使用*this捕获对象的副本 class 构造函数\n?? 完全没有概念 ?? 编译时 if constexpr 构造函数lambda 内联变量 inline\n过去inline用于函数声明, 现在也可以用于变量声明, 表示函数或定义可定义多次(内容必须完全相同) 这允许在头文件中定义一个内联变量 结构化绑定\n变量定义初始化时, 允许形如auto [x,y,z] = expr; 其中expr的 元组类似的对象包括 std::tuple, std::pair, std::array等聚合结构 //例子1 using Coordinate = std::pair\u0026lt;int, int\u0026gt;; Coordinate origin() { return Coordinate{1,2}; } const auto [x, y] = origin(); //x=1; y=2 //例子2 std::unordered_map\u0026lt;std::string, int\u0026gt; mapping{ {\u0026#34;a\u0026#34;, 1}, {\u0026#34;b\u0026#34;, 2}, {\u0026#34;c\u0026#34;, 3}, }; for (const auto\u0026amp; [key, value] : mapping:){ //do something } if/switch选择语句可以带初始化\n//例子1 //之前需要放到语句块中限制锁的范围 { std::lock_guard\u0026lt;std::mutex\u0026gt; lk(mx); if (v.empty()) v.push_back(val); } //现在可以直接放到if中 if (std::lock_guard\u0026lt;std::mutex\u0026gt; lk(mx); v.empty()) { v.push_back(val); } //例子2 //更好的限制了变量的作用域 Foo gadget(args); switch (auto s = gadget.status()) { case OK: gadget.zip(); break; case Bad: throw BadFoo(s.message()); } //vs.现在 switch (Foo gadget(args); auto s = gadget.status()) { case OK: gadget.zip(); break; case Bad: throw BadFoo(s.message()); } 嵌套的namespace\n//C++17以前 namespace A{ namespace B{ namespace C{ int i; } } } //C++17简化了 namespace A::B::C{ int i; } fallthrough, nodiscard, maybe_unused特性\nC++17中新增 stl# std::variant std::optional std::any std::string_view std::filesystem std::invoke std::apply std::byte maps \u0026amp;\u0026amp; sets更优效率的移动节点 并行算法\n许多stl算法, 如copy, find和sort支持并行执行策略 2018 网络库# 2018 并行扩展# 2018 模块# 2020 C++20 第五个C++标准# C++20是一项非常大的改动. 参考资料 语言特性# 新增关键字\nconcept requires constinit consteval co_await co_return co_yield char8_t 新增标识符\nimport module modules 模块\n优点: 没有头文件 声明实现仍然可以分离, 但非必要 可以显示指定哪些导出(类, 函数等) 不需要头文件重复引入宏 include 模块之间名称可以相同 不会冲突 模块只处理一次, 编译更快 (头文件每次引入都需要处理) 预处理宏只在模块内有效 模块引入顺序无关紧要 (头文件引入顺序不同,可能发生不同结果) //创建模块 //export导出模块; 模块的名字是cppcon export module cppcon; namespace CppCon{ auto GetWelcomeHelper() { return \u0026#34;Hello World\u0026#34;; } export auto GetWelcome() { return GetWelcomehelper(); } } //引用模块 import cppcon; int main(){ std::cout \u0026lt;\u0026lt; CppCon::GetWelcome(); } import头文件\n//隐式的将 iostream 转换为模块 //加速构建, 因为iosteam只会处理一次 //和预编译PCH具有相似的效果 ?? PCH是什么 ?? import \u0026lt;iostream\u0026gt; Ranges\nRange代表一串元素或者一串元素中的一段 意义: 简化语法, 方便使用 防止begin/end不配对 使变换/过滤等串联操作成为可能 vector\u0026lt;int\u0026gt; data{11, 22, 33}; sort(begin(data), end(data)); sort(data); //使用Ranges//View: 延迟计算, 不持有, 不改写 //Actions: 即时处理, 改写 //Algorithms: 所有接受begin/end对的算法都可以使用 //View和Ations使用管道符 | 串联 //例子1 串联view vector\u0026lt;int\u0026gt; data{1,2,3,4,5,6,7,8,9,10}; auto result = data | views::remove_if([] (int i) { return i % 2 == 1;}) | views::transform([])(int i) { return to_string(i);}); //result = {\u0026#34;2\u0026#34;,\u0026#34;4\u0026#34;,\u0026#34;6\u0026#34;,\u0026#34;8\u0026#34;,\u0026#34;10\u0026#34;}; //注意 以上操作被延迟, 只有便利result的时候才触发 //例子2 串联actions //排序然后去重 //操作会原地对data进行更改, 然后返回 vector\u0026lt;int\u0026gt; data{4, 3, 4, 1, 8, 0, 8}; vector\u0026lt;int\u0026gt; result = data| actions::sort | actions::unique; //例子3 过滤和变换 //所有的计算延迟到accumulate累加遍历的时候发生 int total = accumulate( view::ints(1) | //产生一个无限对整型数列 view::transform([] (int i) { return i * i;}) | //平方 view::take(10), //取前10个元素 0); //累加 协程\n意义: 异步I/O 延迟计算 事件驱动的程序 generator //co_wait 挂起协程, 等待其他计算完成 //co_return 从协程返回 (协程禁用return) //co_yield 弹出一个值, 挂起协程, 下一次调用继续协程的运行 //for co_await 循环体 Concepts\n?? 模板相关 ?? lambda\n需要显示捕获this变量 C++20之前 [=] 隐式捕获this C++20开始 需要显示捕获this [=, this] 模板形式的lambda表达式 lambda表达式捕获 支持打包展开 constexpr 更新 原子智能指针 Atomic\n智能指针对于数据读写并非线程安全. C++20之前, 多线程中使用智能指针, 需要使用mutex控制访问. C++20新增 atomic\u0026lt;shared_ptr\u0026lt;T\u0026gt;\u0026gt;, atomic\u0026lt;weak_ptr\u0026lt;T\u0026gt;\u0026gt; class 指定初始化\nstruct Data{ int m_x = 0; std::string m_s; }; Data d{.m_s = \u0026#34;Hellow\u0026#34;}; \u0026lt;=\u0026gt; 运算符\n三路比较运算符 //类似C的strcmp函数返回-1, 0, 1 //但实际\u0026lt;=\u0026gt;返回的并非int类型, 而是\u0026lt;compare\u0026gt;头中的对象 (a \u0026lt;=\u0026gt; b ) \u0026lt; 0 //如果a\u0026lt;b为true (a \u0026lt;=\u0026gt; b ) == 0 //如果a==b为true (a \u0026lt;=\u0026gt; b ) \u0026gt; 0 //如果a\u0026gt;b为true 范围for循环语句 支持初始化语句\nC++17 if, switch语句支持了初始化语句 C++20 新增for循环语句的支持 for (auto data = GetData(); auto\u0026amp; value : data){ //do something } 特性测试宏\n__has_cpp_attribute(fallthrough) __cpp_binary_literals __cpp_chart_t __cpp_coroutines consteval\nconstexpr函数可能编译期执行, 也可以在运行期执行; consteval只能在编译期执行 constinit\n强制指定以常量方式初始化 const char* GetStringDyn() { return \u0026#34;dynamic init\u0026#34;; } constexpr const char* GetString(bool constInit) { return constInit ? \u0026#34;constant init\u0026#34; : GetStringDyn(); } constinit const char* a = GetString(true); // ✔ constinit const char* b = GetString(false); // ❌ 用using引用enum类型\nenum class CardTypeSuit { Clubs, Diamonds, Hearts, Spades }; //C++20之前 std::string_view GetString(const CardTypeSuit cardTypeSuit) { switch (cardTypeSuit) { case CardTypeSuit::Clubs: return \u0026#34;Clubs\u0026#34;; case CardTypeSuit::Diamonds: return \u0026#34;Diamonds\u0026#34;; case CardTypeSuit::Hearts: return \u0026#34;Hearts\u0026#34;; case CardTypeSuit::Spades: return \u0026#34;Spades\u0026#34;; } } //C++20 std::string_view GetString(const CardTypeSuit cardTypeSuit) { switch (cardTypeSuit) { using enum CardTypeSuit; // 这里 case Clubs: return \u0026#34;Clubs\u0026#34;; case Diamonds: return \u0026#34;Diamonds\u0026#34;; case Hearts: return \u0026#34;Hearts\u0026#34;; case Spades: return \u0026#34;Spades\u0026#34;; } } stl# choron 增加日历和时区的支持 std::span\n某段连续数据的视图 不持有数据, 不分配和销毁数据 copy非常快 不支持数据跨步 可通过运行期确定长度, 也可编译期确定长度 特性测试宏\n__cpp_lib_conceps __cpp_lib_ranges __cpp_lib_scoped_lock \u0026lt;version\u0026gt;\n包含c++标准库版本, 发布日期, 版权证书, 特性宏等 std::format\n?? C++ 也有format了 \u0026hellip;. ?? 设计原则# C++设计成直接的和广泛的支援多种程式设计风格（过程化程式设计、数据抽象、物件导向程式设计、泛型程式设计）。 C++设计成给程式设计者更多的选择，即使可能导致程式设计者选择错误。 C++设计成尽可能与C相容，借此提供一个从C到C++的平滑过渡。 C++避免平台限定或没有普遍用途的特性。 C++不使用会带来额外开销的特性。 C++设计成无需复杂的程式设计环境。 待学习# stl C++中很重要的功能, 必须要尽快了解常用的 新的概念 C++20中增加了很多新概念 新的语言特性 只需要学习常用的特性, 有些特性是为了配合模板而来的, 暂时不需要学习 其他常用的库 比如网络库Asio, 格式库protobuf 模板 模板的作用 更多的是用在stl的编写上, 日常开发使用的比较少, 可以暂时先不学习 "},{"id":11,"href":"/blog/docs/prog_debug/gdb/","title":"gdb","section":"prog debug","content":"proc总体状态查看# proc# (gdb) info proc process 217777 cmdline = \u0026#39;/home/clay/my/learn_gdb/a.out\u0026#39; cwd = \u0026#39;/home/clay/my/learn_gdb\u0026#39; exe = \u0026#39;/home/clay/my/learn_gdb/a.out\u0026#39;proc status# //TODONOW 补充对应的字段 info proc status 显示与进程相关的附加信息 1) 用户ID, group id 2) 虚拟内存使用情况 3) 待处理, 阻塞和沪铝的信号 4) 消耗系统和用户的时间 5) 堆栈大小内存分布# 段表 //TODONOW 补充说明 (gdb) info proc mappings process 217777 Mapped address spaces: Start Addr End Addr Size Offset Perms objfile 0x555555554000 0x555555555000 0x1000 0x0 r--p /home/clay/my/learn_gdb/a.out 0x555555555000 0x555555556000 0x1000 0x1000 r-xp /home/clay/my/learn_gdb/a.out 0x555555556000 0x555555557000 0x1000 0x2000 r--p /home/clay/my/learn_gdb/a.out 0x555555557000 0x555555558000 0x1000 0x2000 r--p /home/clay/my/learn_gdb/a.out 0x555555558000 0x555555559000 0x1000 0x3000 rw-p /home/clay/my/learn_gdb/a.out 0x7ffff7d8a000 0x7ffff7d8d000 0x3000 0x0 rw-p 0x7ffff7d8d000 0x7ffff7db5000 0x28000 0x0 r--p /usr/lib/x86_64-linux-gnu/libc.so.6 0x7ffff7db5000 0x7ffff7f4a000 0x195000 0x28000 r-xp /usr/lib/x86_64-linux-gnu/libc.so.6 0x7ffff7f4a000 0x7ffff7fa2000 0x58000 0x1bd000 r--p /usr/lib/x86_64-linux-gnu/libc.so.6 0x7ffff7fa2000 0x7ffff7fa3000 0x1000 0x215000 ---p /usr/lib/x86_64-linux-gnu/libc.so.6 0x7ffff7fa3000 0x7ffff7fa7000 0x4000 0x215000 r--p /usr/lib/x86_64-linux-gnu/libc.so.6 0x7ffff7fa7000 0x7ffff7fa9000 0x2000 0x219000 rw-p /usr/lib/x86_64-linux-gnu/libc.so.6 0x7ffff7fa9000 0x7ffff7fb6000 0xd000 0x0 rw-p 0x7ffff7fbb000 0x7ffff7fbd000 0x2000 0x0 rw-p 0x7ffff7fbd000 0x7ffff7fc1000 0x4000 0x0 r--p [vvar] 0x7ffff7fc1000 0x7ffff7fc3000 0x2000 0x0 r-xp [vdso] 0x7ffff7fc3000 0x7ffff7fc5000 0x2000 0x0 r--p /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2 0x7ffff7fc5000 0x7ffff7fef000 0x2a000 0x2000 r-xp /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2 0x7ffff7fef000 0x7ffff7ffa000 0xb000 0x2c000 r--p /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2 0x7ffff7ffb000 0x7ffff7ffd000 0x2000 0x37000 r--p /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2 0x7ffff7ffd000 0x7ffff7fff000 0x2000 0x39000 rw-p /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2 0x7ffffffde000 0x7ffffffff000 0x21000 0x0 rw-p [stack]页表 (Register: cr3) TODO 待补充 多线程视图# //TODONOW 补充多线程情形 (gdb) info threads Id Target Id Frame * 1 Thread 0x7ffff7d8a740 (LWP 217777) \u0026#34;a.out\u0026#34; main (argc=1, argv=0x7fffffffe138) at main.cc:4frame查看# //info frame 显示的是更详细的信息, 但是可读性很差 (gdb) info frame Stack level 0, frame at 0x7fffffffe030: rip = 0x55555555513f in main (main.cc:4); saved rip = 0x7ffff7db6d90 source language c++. Arglist at 0x7fffffffe020, args: argc=1, argv=0x7fffffffe138 Locals at 0x7fffffffe020, Previous frame\u0026#39;s sp is 0x7fffffffe030 Saved registers: rbp at 0x7fffffffe020, rip at 0x7fffffffe028 //TODONOW 补充多frame (gdb) frame #0 main (argc=1, argv=0x7fffffffe138) at main.cc:4 4\tint b = 2; 脑海中先有进程的view(多线程, 内存); proc 也是一帧一帧(frame by frame)运行的; 查看的是每个frame下的状态(内存, Reigster, 线程等). 在不同frame间查看, 就像播放动画片 当前frame下的其他信息# backtrace 函数栈 register 寄存器 local 本地?变量 //TODONOW 更准确的描述 scope 作用域变量 常用命令# bt (backtrace) 查看函数栈 bt full 查看更加详细的信息 f (frame) 查看栈信息 f 0 表示查看栈顶; f n查看第n+1层 down 查看下一栈 up 查看上一栈 i (info) i program 查看当前进程运行信息 i threads 查看当前线程运行信息 i f 查看当前栈所在层的具体信息 i args 当前函数的参数名及其值 i locals 当前函数中所有局部变量及其值 i catch 异常处理信息 i b 查看断点 i proc mappings 查看程序的内存分布 i reg 查看寄存器 l (list) 查看源码 p (print) 查看变量的值 gcore# gcore #进程pid 执行命令后，会在当前目录下生成一个该进程的core dump文件了 "},{"id":12,"href":"/blog/docs/prog_compile/autotools/","title":"autotools","section":"prog compile","content":"初学autotools 为什么需要autotools# Makefile固然可以帮助make完成它的使命，但要承认的是，编写Makefile确实不是一件轻松的事，尤其对于一个较大的项目而言更是如此。 那么，有没有一种轻松的手段生成Makefile而同时又能让我们享受make的优越性呢？ 本节要讲autotools系列工具正是为此而设的， autotools只需用户输入简单的目标文件、依赖文件、文件目录等就可以轻松地生成Makefile autotools还可以完成系统配置信息的收集，从而可以方便地处理各种移植性的问题。 也正是基于此，现在Linux上的软件开发一般都用autotools来制作Makefile。 什么是autotools# 综上所述, autotools主要就是利用各个工具的脚本文件以生成最后的Makefile. autotools并不是一个工具, 而是一系列工具合集. 主要有: autoscan aclocal autoconf autoheader automake autotools怎么使用# autotools安装# mac下包管理习惯使用homebrew 安装autoscan \u0026amp;\u0026amp; autoconf brew install autoconf 安装aclocal \u0026amp;\u0026amp; automake \u0026amp;\u0026amp; autoheader brew install automake autotools# 在代码当前目录下执行autoscan, 生成configure.scan. configure.scan重命名为configure.ac. 并做以下修改: 初始化AC_INIT 初始化AM_INIT_AUTOMAKE 设定AC_CONFIG_FILES # -*- Autoconf -*- # Process this file with autoconf to produce a configure script. AC_PREREQ([2.69]) #1. _初始化AC_INIT 和 初始化AM_INIT_AUTOMAKE_ AC_INIT(hello,1.0,377133665@qq.com) AM_INIT_AUTOMAKE(hello,1.0) #AC_CONFIG_SCRDIR来侦测源码文件是否存在, 来确定源码目录的有效性 AC_CONFIG_SRCDIR([main.cpp]) AC_CONFIG_HEADERS([config.h]) # Checks for programs. AC_PROG_CXX # Checks for libraries. # Checks for header files. AC_CHECK_HEADERS([stdlib.h unistd.h]) # Checks for typedefs, structures, and compiler characteristics. # Checks for library functions. #2. _生成makefile_ AC_CONFIG_FILES([Makefile]) AC_OUTPUT 执行aclocal命令. 扫描configure.ac文件生成aclocal.m4文件. 该文件主要处理本地宏定义. 它根据已经安装的宏、用户定义宏和 acinclude.m4 文件中的宏将 configure.ac 文件需要的宏集中定义到文件 aclocal.m4 中. 执行autoconf.这个命令将 configure.ac 文件中的宏展开，生成 configure 脚本。 这个过程要用到aclocal.m4中定义的宏. 如果configure.ac宏定义改变了, 需要重新执行aclocal命令 执行autoheader.该命令生成 config.h.in 文件。该命令通常会从 \u0026ldquo;acconfig.h” 文件中复制用户附加的符号定义。该例子中没有附加的符号定义, 所以不需要创建 \u0026ldquo;acconfig.h” 文件。 创建Makefile.am文件.Automake工具会根据 configure.in 中的参量把 Makefile.am 转换成 Makefile.in 文件。最终通过Makefile.in生成Makefile文件，所以Makefile.am这个文件非常重要，定义了一些生成Makefile的规则 AUTOMARK_OPTIONS = foreign bin_PROGRAMS = hello hello_SOURCES = main.cpp 执行automake \u0026ndash;add-missing命令。该命令生成 Makefile.in 文件。使用选项 \u0026ldquo;\u0026ndash;add-missing\u0026rdquo; 可以让 Automake 自动添加一些必需的脚本文件。如果发现一些文件不存在，可以通过手工 touch命令创建 执行./configure。大部分linux软件安装都先需要执行./congigure，然后执行make和make install命令。 ./congigure主要把 Makefile.in 变成最终的 Makefile 文件。configure会把一些配置参数配置到Makefile文件里面。 执行make mac系统gcc与g++默认下都是clang的别名. 所以有可能会在此处产生错误. 实际上并没有发现不同 执行make install autotools流程图# dot流程图源码 推荐文章# autotools使用详解 Makefile中文手册 "},{"id":13,"href":"/blog/docs/emacs/lisp/eshell/","title":"eshell","section":"常用扩展","content":"emacs自带的shell解释器, 正在尝试使用, 期望可以取代其他shell解析器(比如bash, zsh) 官方文档 优势: emacs自带, 不同os环境统一 语法支持tramp cd /method:user@host#22:/path eshell \u0026amp;\u0026amp; elisp# defun为 eshell/xxx的函数, 可以在eshell中直接调用xxx eshell script# 官方不建议在eshell中写shell脚本, eshell脚本也是以.sh结尾 变量赋值# eshell 脚本中使用elisp语法给变量赋值 (setq remote_temp \u0026#34;/ssh:clay@192.168.0.97:~/temp\u0026#34;)变量使用 $# 基本与shell相同, 具体可以详见官方说明 eshell/rm -r $remote_temp"},{"id":14,"href":"/blog/docs/prog_base/02_lambda/","title":"λ验算","section":"prog base","content":"λ演算是一种计算模型, 告诉\u0026quot;计算的本质如何表达\u0026quot; (计算就是函数应用与替换) 推荐阅读# lambda演算教程 (机翻版) λ演算 语法定义# λ演算里的项M,N 定义为: 变量: x 抽象 (函数): λx.M 应用: M N 抽象(abstraction): 创建一个函数, 把x 当作参数, M 是函数体. 在这里, 就是把函数的逻辑从具体值中抽象出来 比如λx.x+1 表示\u0026quot;一个输入, 返回x+1的函数\u0026quot;. 实际上现在叫函数更合适, 但是当时的背景(1930年)下, 可能那时候的函数定义与现在不一致 应用(application): 把函数作用于某个具体值. 比如(λx.x+1) 3 表示把函数λx.x+1 作用在3 上. 实际就是现在的函数调用 f(x=3) λ演算 三种归约# α 归约 改变绑定变量名字, 防止冲突. 只是改了变量名字, 没有改变函数的意义 λx.x+1 = λy.y+1 β 归约 核心归约规则，也是 λ 演算的核心计算方式 (λx.M) N = M[x:=N] η 归约 表示“扩展或收缩函数”，当函数可以被简化为一个等价形式, 反映函数的“本质行为”不变。 λx.(M x) = M. if M 中不包含x 如果M 函数中不包含x, 那么 λx.(M x) 就等于函数 M 数字的定义# 在 λ演算中数字0(以及其他自然数)是可以定义的, 通过函数来表示. 这种表示通常叫做 Church 数字（Church numeral） Church 数字 基本思想： 一个自然数 n 被表示为一个函数，它接收两个参数： 一个函数 f(表示“操作”) 一个初始值 x 重复应用某个操作(f) n 次于 x 上 0 := λf.λx.x 1 := λf.λx.(f x) 2 := λf.λx.(f (f x)) λf.λx.x: 先接收f, 返回λx.x, 再接收x, 返回x 表示对f 调用0次 λf.λx.(f x): 先接受f, 返回λx.(f x), 再接受x, 返回f x 表示对f 调用1次 f(x) λf.λx.(f (f x)): 先接受f, 返回λx.(f (f x)), 再接受x, 返回f (f x) 表示对f 调用2次 f(f(x)) Q: 为什么一定要传入f \u0026amp;\u0026amp; x, 只要f, 去掉x 可以吗? lambda 中的函数一定要有参数, 才能有具体结果. (与编程中的函数有差异) 如果不传x 给函数f, 那么函数f 就不会有具体结果, 只是一堆f(f()) 嵌套调用 所以必须要传递x 给函数 f 加法计算表示# TODO 完成加法计算表示1 + 1 对1 进行 +1 的操作. f 是+1, x 是1 3 + 2 对3 进行 +2 的操作. f 是+2, x 是3 但是上面的理解是基于自然数的, 在λ中自然数不是1,2, 而是Church 数字 如果是使用λ中的Church 数字表示 加法是某个操作(函数), 接受2 个参数, 所以应该是λm.λn.Function 我们用ADD 来表示加法这个操作 ADD = λm.λn.Function 现在剩下的就是来推导ADD 的函数体 m: 是重复调用f m 次 于 x 上 n: 是重复调用f n 次 于 x 上 所以m+n应该是重复调用f m+n 次 于 x 上, 也就是Function 的意义 n(f x) 表示: (f (f (f x))) 对f 重复调用n 次于 x 上 m(f (n(f x))) 表示: 对f 重复调用m 次于 n(f x) 上 TODO 这里的定义错了, 导致后续的推算都是错误的所以ADD 的定义可以是: ADD = λm.λn.λf.λx.(m(f (n(f x)))) 计算ADD λf.λx.(f x) λf.λx.(f x), 也就是计算1+1 λm.λn.λf.λx.(m(f (n(f x)))) λf.λx.(f x) λf.λx.(f x) 先传入参数m λf.λx.(f x) λm.λn.λf.λx.(m(f (n(f x)))) -\u0026gt; λn.λf.λx.(λf.λx.(f x) (f (n(f x)))) -\u0026gt; 其中 λf.λx.(f x) (f (n(f x))) -\u0026gt; λa.λb.(a b) (f (n(f x))) -\u0026gt; λb.(a b) [a := (f (n(f x)))] -\u0026gt; λb.((f (n(f x))) b) -\u0026gt; λx.((f (n(f x))) x) 减法计算表示# TODO 完成减法计算表示"},{"id":15,"href":"/blog/docs/os/linux/","title":"linux","section":"os","content":"查看硬件信息# 信息 命令 cpu cat /proc/cpuinfo 查看OS信息# 信息 命令 linux发行版信息 cat /etc/issue kernel信息 cat /proc/version, uname-a process top memory free fd 查看与设置 socket ss, netstat 常用命令# 命令 信息 | 管道. 将 前面的标准输出 作为 后面的标准输入 xargs 将 前面的标准输出 作为 后面命令的参数 nohup 程序后台运行, 前缀, 占用标准输出 \u0026amp; 程序后台运行, 后缀, 不占用标准输出 watch 周期性执行某个命令 crontab 定时任务 sort 排序 wc 统计行数 readelf, nm, objdump 查看库的封装信息 命令说明# cpuinfo # 总核数 = 物理CPU个数 X 每颗物理CPU的核数 # 总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数 # 查看物理CPU个数 cat /proc/cpuinfo| grep \u0026#34;physical id\u0026#34;| sort| uniq| wc -l # 查看每个物理CPU中core的个数(即核数) cat /proc/cpuinfo| grep \u0026#34;cpu cores\u0026#34;| uniq # 查看逻辑CPU的个数 cat /proc/cpuinfo| grep \u0026#34;processor\u0026#34;| wc -l # 查看CPU信息（型号） cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c top # top header (这一系列信息是系统的信息, docker容器内外是一致的) top - 12:19:58 up 3:45, 1 user, load average: 0.00, 0.02, 0.05 Tasks: 27 total, 1 running, 26 sleeping, 0 stopped, 0 zombie %Cpu(s): 1.5 us, 1.1 sy, 0.0 ni, 97.2 id, 0.0 wa, 0.0 hi, 0.2 si, 0.0 st MiB Mem : 64348.3 total, 39305.2 free, 11285.5 used, 13757.6 buff/cache MiB Swap: 8192.0 total, 8192.0 free, 0.0 used. 52690.6 avail Mem | key | desc | |----------+-------------------------------------------------| | top | 当前系统时间; | | | 启动了3小时45分钟; | | | user同时在线的用户; | | | load average服务器1min, 5min, 15min的负载情况 | |----------+-------------------------------------------------| | Tasks | 总共开启了27个进程 | | | 1个在run, 26个sleep, 0stoped, 0僵尸进程 | |----------+-------------------------------------------------| | %Cpu | 总核数的平均值(不会大于100%) | | | us用户占比, sy系统占比 | | | ni用户进程空间内改变过优先级的进程占用CPU百分比 | | | id空闲cpu百分比 | | | wa用户进程空间内改变过优先级的进程占用CPU百分比 | | | hi硬件中断, si软件中断, st实时 | |----------+-------------------------------------------------| | MiB Mem | total系统物理总内存, | | | free空闲内存, used已使用, buff/cache缓冲区内存 | |----------+-------------------------------------------------| | MiB Swap | total交换总内存 | | | free交换空闲, used交换已用, avail 可用内存 | |----------+-------------------------------------------------|# top body PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 122 root 20 0 12936 7148 6648 S 1.0 0.0 2:32.20 cli 69 root 20 0 12928 7064 6572 S 0.7 0.0 2:07.64 svr | key | desc | |---------+-------------------------------------------| | pid | | | user | 谁启动的该进程 | | PR | 优先级 | | ni | nice值 负值表示高优先级，正值表示低优先级 | | VIRT | 虚拟内存 | | RES | 真实内存 | | SHR | 共享内存 | | %CPU | 单核cpu占比, 大于100%表示占用了多个cpu核 | | TIME+ | 进程运行总时间??占用cpu的总时间?? | | COMMAND | 进程启动时的命令 | |---------+-------------------------------------------| free ## free -h total used free shared buff/cache available Mem: 62Gi 11Gi 38Gi 17Mi 13Gi 51Gi Swap: 8.0Gi 0B 8.0Gi | key | desc | |------------+----------------------------------------| | total | 系统总内存 | |------------+----------------------------------------| | used | 已使用 | |------------+----------------------------------------| | free | 空闲 | |------------+----------------------------------------| | shared | 已舍弃的内存? | |------------+----------------------------------------| | buff/cache | io读写内存; | | | 内存紧张的时候,会自动释放; | | | cache文件系统缓存; buff 裸设备相关缓存 | |------------+----------------------------------------| | available | 可用内存. = free + buff/cache | |------------+----------------------------------------| ss * every 100s 每100s刷新一次 ss-s 851d60ae4404是服务器名字 服务器当前时间 * total: 这个数值是docker容器有关的, 每个单独计算; 貌似是inet + 1 TODONOW. * TCP: 2101 这个数值是docker容器无关的, 容器内外都一样; 貌似是state总和?? TODONOW * estab -- 这个数值是docker容器相关的, 每个单独计算 * closed -- 这个数值是docker容器相关的, 每个单独计算 * orphaned -- * timewait -- Every 100.0s: ss -s 851d60ae4404: Wed Oct 20 17:44:33 2021 Total: 3 TCP: 2101 (estab 0, closed 2100, orphaned 0, timewait 0) * RAW * UDP * TCP 这里的total是docker容器相关的, 每个单独计算 * INET * FRAG Transport Total IP IPv6 RAW 0 0 0 UDP 1 1 0 TCP 1 1 0 INET 2 2 0 FRAG 0 0 0常用参数 | 参数 | 含义 | |---------------------------------------------+---------------------------------------------------| | ss -a | show all state. 默认只显示established state | | ss -[4,6,t,u] | 匹配ipv4, ipv6, tcp协议, udp协议连接 | | ss [dst,src] \u0026lt;ip\u0026gt;:[port] | 匹配远端,本地 地址(端口) | | ss [dport,sport] [le,ge,eq,ne,gt,lt] \u0026lt;port\u0026gt; | 匹配远端,本地相符的连接. port比较参数与sh语法一致 | | ss state [state-status] | 匹配state | |---------------------------------------------+---------------------------------------------------| fd | 信息 | 查看命令 | |------------------------------------------+-----------------------| | 所有进程允许打开的最大fd数量 | /proc/sys/fs/file-max | | 所有进程已经打开的fd数量及允许的最大数量 | /proc/sys/fs/file-nr | | 单个进程允许打开的最大fd数量 | ulimit -n | | 单个进程(例如pid为5454)已打开的fd | ls -l =/proc/5454/fd/= | |------------------------------------------+-----------------------| | 作用 | 命令 | |-----------------------------------------+-----------------------------------------------------------| | 用户单进程最大(仅当前sesstion生效) | ulimit -n | | 用户单进程设置 | ulimit -n xx | | 用户单进程S(软件)最大(需要重新登录生效) | echo \u0026#39;* soft nofile 1048576\u0026#39; \u0026gt;\u0026gt; /etc/security/limits.conf | | 用户单进程H(硬件)最大(需要重新登录生效) | echo \u0026#39;* hard nofile 1048576\u0026#39; \u0026gt;\u0026gt; /etc/security/limits.conf | |-----------------------------------------+-----------------------------------------------------------| 用户单进程H最大的值一定不能大于fs.nr_open, 否则注销后将无法正常登录 以上3个的配置数都受限于fs.nr_open \u0026ndash; 调用sysctl -p生效 sysctl -w fs.nr_open=xxx sort 根据Ascii进行排序, 默认为升序 u 去除重复行 r 降序 n 根据 数值 而非 Ascii 排序 k, t k指定列数, t指定分隔符 f 会将小写字母都转换为大写字母来进行比较，亦即忽略大小写 "},{"id":16,"href":"/blog/docs/tool/k8s/","title":"k8s","section":"tools","content":"kubernetes, 简称k8s k8s概念# namespace 在所有抽象层之前 kubectl delete namespace \u0026lt;namespace-name\u0026gt; 删除namespace会删除namespace下面所有的资源, 比如deployment,pods,svc等等-n xx \u0026ndash; 使用xx命名空间 \u0026ndash;all-namespaces \u0026ndash; 显示所有的命名空间 kubectl get namespaceskubectl delete pod \u0026lt;pod-name\u0026gt; --force -n xx 各种概念 cluster 即k8s集群 master 控制节点 node 工作节点 Namespace CustomResourceDefinition 自定义类型资源crd service deployment \u0026ndash; rc \u0026ndash; pods ingress kubernetes 创建集群# 安装# # 大多数 Pod 网络都需要 CNI_VERSION=\u0026#34;v0.8.2\u0026#34; ARCH=\u0026#34;amd64\u0026#34; sudo mkdir -p /opt/cni/bin curl -L \u0026#34;https://github.com/containernetworking/plugins/releases/download/${CNI_VERSION}/cni-plugins-linux-${ARCH}-${CNI_VERSION}.tgz\u0026#34; | sudo tar -C /opt/cni/bin -xz# kubeadm/kubelet 容器运行时接口（CRI）所需 DOWNLOAD_DIR=/usr/local/bin sudo mkdir -p $DOWNLOAD_DIR CRICTL_VERSION=\u0026#34;v1.17.0\u0026#34; ARCH=\u0026#34;amd64\u0026#34; curl -L \u0026#34;https://github.com/kubernetes-sigs/cri-tools/releases/download/${CRICTL_VERSION}/crictl-${CRICTL_VERSION}-linux-${ARCH}.tar.gz\u0026#34; | sudo tar -C $DOWNLOAD_DIR -xz#RELEASE=\u0026#34;$(curl -sSL https://dl.k8s.io/release/stable.txt)\u0026#34; RELEASE=v1.22.3 ARCH=\u0026#34;amd64\u0026#34; cd $DOWNLOAD_DIR sudo curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/${RELEASE}/bin/linux/${ARCH}/{kubeadm,kubelet,kubectl} sudo chmod +x {kubeadm,kubelet,kubectl} # 添加kubelet系统服务 RELEASE_VERSION=\u0026#34;v0.4.0\u0026#34; curl -sSL \u0026#34;https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubelet/lib/systemd/system/kubelet.service\u0026#34; | sed \u0026#34;s:/usr/bin:${DOWNLOAD_DIR}:g\u0026#34; | sudo tee /etc/systemd/system/kubelet.service sudo mkdir -p /etc/systemd/system/kubelet.service.d curl -sSL \u0026#34;https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubeadm/10-kubeadm.conf\u0026#34; | sed \u0026#34;s:/usr/bin:${DOWNLOAD_DIR}:g\u0026#34; | sudo tee /etc/systemd/system/kubelet.service.d/10-kubeadm.conf # 激活并启动kubelet systemctl enable --now kubelet环境配置# # 加载模块 sudo modprobe br_netfilter # cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system控制平面节点 协议\t方向\t端口范围\t作用\t使用者 TCP\t入站\t6443\tKubernetes API 服务器\t所有组件 TCP\t入站\t2379-2380\tetcd 服务器客户端 API\tkube-apiserver, etcd TCP\t入站\t10250\tKubelet API\tkubelet 自身、控制平面组件 TCP\t入站\t10251\tkube-scheduler\tkube-scheduler 自身 TCP\t入站\t10252\tkube-controller-manager\tkube-controller-manager 自身 工作节点 协议\t方向\t端口范围\t作用\t使用者 TCP\t入站\t10250\tKubelet API\tkubelet 自身、控制平面组件 TCP\t入站\t30000-32767\tNodePort 服务†\t所有组件# 查看需要下载哪些 kubeadm config images list # 替换为mirror-images kubeadm config images list |grep -v \u0026#39;coredns\u0026#39; |sed -e \u0026#39;s/^/docker pull /g\u0026#39; -e \u0026#39;s#k8s.gcr.io#docker.io/clay2019#g\u0026#39; |sh -x kubeadm config images list |grep \u0026#39;coredns\u0026#39; |sed -e \u0026#39;s/^/docker pull /g\u0026#39; -e \u0026#39;s#k8s.gcr.io#docker.io#g\u0026#39; -e \u0026#39;s#:v#:#g\u0026#39; |sh -x kubeadm config images list |grep -v \u0026#39;coredns\u0026#39; |sed -e \u0026#39;s/^/docker pull /g\u0026#39; -e \u0026#39;s#k8s.gcr.io#docker.io/clay2019#g\u0026#39; |sh -x docker images |grep clay2019 |awk \u0026#39;{print \u0026#34;docker tag \u0026#34;,$1\u0026#34;:\u0026#34;$2,$1\u0026#34;:\u0026#34;$2}\u0026#39; |sed -e \u0026#39;s#clay2019#k8s.gcr.io#2\u0026#39; |sh -x docker images |grep clay2019 |awk \u0026#39;{print \u0026#34;docker rmi \u0026#34;, $1\u0026#34;:\u0026#34;$2}\u0026#39; |sh -xkubeadm init 配置# kubeadm的配置文件 kubeadm --config中指定的那个, 会覆盖kubelet等组件的默认行为!!!# 查看kubeadm init-defaults kubeadm config print init-defaults --component-configs KubeProxyConfiguration,KubeletConfiguration \u0026gt; kubeadm.yaml # 有时候 kubeadm init 与 kubeadm init --config kubeadm.yaml 使用的镜像并不相同 # 比如我遇到的kubeadm init使用的是v1.22.3, 但是其init-defaults输出的kubeadm.yaml中的images为v1.22.0!! 需要注意配置完成之后, 使用 kubeadm init \u0026ndash;config xx.yaml来创建master 也可以使用kubeadm init默认安装 如果kubelet没有启动, 修改下kubelet的配置文件, 重新启动即可 网络插件安装# kubectl get nodes中发现Node的STATUS为NotReady, 需要安装网络插件. 如果没有安装网络插件, pods/coredns的状态为pending 这里选的是calico, 详见calico安装 kubernetes 配置集群的# 主要配置deployment 与 service deployment会创建rc, rc会创建pod # 1.写deployment kubectl create deployment alpine --image=alpine # 2.执行 kubectl expose deployment/alpine --name=apine-svc --port=80 --type=NodePort # 3.查看是否成功 kubectl get pods #视情况 加namespace # 4.如果报错, 查看具体错误 kubectl describe pods \u0026lt;pod-name\u0026gt;工具 - kubeadm# 集群创建工具 kubeadm init kubeadm reset 需要重新init的时候, 先执行reset kubeadm config print init-default kubeadm config print init-defaults --component-configs KubeProxyConfiguration,KubeletConfiguration \u0026gt; kubeadm.yaml 工具 - kubectl# 集群管理工具 使用kubectl必须配置kubeconfig文件 放到~/.kube/config中 或者 使用 --kubeconfig来指定## kubectl 在 $HOME/.kube 目录中查找一个名为 config 的配置文件 ## 你可以通过设置 KUBECONFIG 环境变量或设置 --kubeconfig 参数来指定其它 kubeconfig 文件 cp -i /etc/kubernetes/admin.conf ~/.kube/config # 检查是否正常 kubectl cluster-info常用命令# kubectl cmd type cmd: get describe type: node namespace deployment pod 常用命令2# # 转发monitoring/svc=prometheus-k8s的端口9090到 localhost的9000 # 如果不写9000:9090, 只写9090, 表示转发svc的9090到 localhost的9090 kubectl -n monitoring port-forward svc/prometheus-k8s 9000:9090 # 其输出如下 Forwarding from 127.0.0.1:9000 -\u0026gt; 9090 Forwarding from [::1]:9000 -\u0026gt; 9090 # 看上面的输出, 我们知道, 这个端口转发只对localhost生效, 外部网络无法访问 # 如果想从外部可以访问, 我们可以使用nginx反向代理, 转发remote-port到9000 # ingress同样的道理工具 - kubelet# work-node 运行需要, master不建议运行 配置文件在/var/lib/kubelet/config.yaml 如果遇到cgroup错误, 可以修改\u0026ndash;cgroup-driver=cgroupfs, 然后重新启动kubelet systemctl daemon-reload systemctl enable kubelet systemctl status kubelet root@ubt:/home/dev_wangchengqing# kubectl get nodes NAME STATUS ROLES AGE VERSION ubt NotReady \u0026lt;none\u0026gt; 3h21m v1.22.3 # NotReady 是因为还没有部署网络插件插件 - calico# # 1.node节点数小于50的配置文件; 如果node节点数大于50, 请参考官网 curl https://docs.projectcalico.org/manifests/calico.yaml -O # 2.如果本地地址在192.168.0.0/16, 需要设置calico的ip地址 # 修改 CALICO_IPV4POOL_CIDR的value的值即可 # 3.执行插件的安装 kubectl apply -f calico.yaml # 4. 确认是否安装成功 kubectl get pods --all-namespaces # coredns 会在网络插件安装成功之后启动 Pending -\u0026gt; Running # 同时kubectl get nodes中的 STATUS会变为Ready插件 - ingress-nginx# # 下载yaml curl -L https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.0.4/deploy/static/provider/cloud/deploy.yaml \u0026gt; ingress-nginx.yaml # 修改yaml中的mirror sed -i \u0026#39;s#k8s.gcr.io/ingress-nginx#docker.io/clay2019#g\u0026#39; ingress-nginx.yaml # 部署ingress-nginx kubectl apply -f ${ingress-n-yaml} # 查看是否安装成功 kubectl get pods -n ingress-nginx# 1. 查看已有的ingress kubectl get ingress # 不确定是否有用的时候, 可以 kubectl describe ingress \u0026lt;ingress-name\u0026gt; # 2. 编写ingress.yaml ## 编写的时候注意 backend的命名空间 # 3. apply kubectl apply -f ingress.yaml # 4. check 查看是否正常 kubectl describe ingress \u0026lt;ingress-name\u0026gt;apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: test namespace: monitoring # 需要增加annotations字段的内容, 否则会提示404, 不知道为什么 annotations: ingress.kubernetes.io/rewrite-target: / kubernetes.io/ingress.class: nginx spec: rules: - http: paths: - path: / pathType: Prefix backend: service: name: prometheus-k8s port: number: 9090# 当ingress-controller与ingress-rule正确部署之后 # 查看一下ingess-controller命名空间下的svc, 获取到port kubectl get svr -n ingress-nginx # 输出如下 root@ubt:/home/dev_wangchengqing# kubectl get svc -n ingress-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.108.147.62 \u0026lt;pending\u0026gt; 80:31468/TCP,443:31055/TCP 61m ingress-nginx-controller-admission ClusterIP 10.107.83.233 \u0026lt;none\u0026gt; 443/TCP 61m # A为ingress-controller所在的机器的ip地址 # 从输出中可以看到, ingress-controller的svc把自身80端口映射到了31468端口 (31468端口由kube-proxy监听) # 因此我们访问A:31468, 会访问到ingress-controller的10.108.147.62:80 # 然后ingress-controller 会根据 ingress-rule把我们的转发, 下发到不同的backends service命名空间问题# Now, Ingress Controller can be deployed in any namespace and is, in fact, usually deployed in a namespace separate from your app services. It can out-of-the-box see Ingress rules in all namespaces in the cluster and will pick them up. The Ingress rules, however, must reside in the namespace where the app that they configure reside. ingress-controller常常有独立的namespace. 其可以获取所有namespaces中的ingress-rule ingress-rule, 需要与backend保持同一个namespace TODO ingress-rule配置问题# apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: test namespace: monitoring annotations: kubernetes.io/ingress.class: nginx nginx.ingress.kubernetes.io/rewrite-target: / spec: rules: - http: paths: - path: / pathType: Prefix backend: service: name: grafana port: number: 3000如果path配置了/app, curl ip:port/app的时候确实可以拉取到\u0026lt;herf/\u0026gt; 但是进不去 如果path配置了/ , crul ip:port 的时候就是正常的 猜测原因 当配置为/app的时候, 访问ip:port/app时候, 会被重定向为 backend:port/xxx xxx一般为backend service对外提供的, 比如 prometheus的为http://mytest.com/login 这时候url在client被修改为ip:port/login 但是在ingress-rule中并没有对ip:port/login的处理规则, 因此提示404 解决方法 暂时回避了该问题, 使用多个host 取代 \u0026lt;单host+ 多path\u0026gt;的方式 apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: test namespace: monitoring annotations: kubernetes.io/ingress.class: nginx nginx.ingress.kubernetes.io/rewrite-target: / spec: rules: - host: g.mytest.com http: paths: - path: / pathType: Prefix backend: service: name: grafana port: number: 3000 - host: p.mytest.com http: paths: - path: / pathType: Prefix backend: service: name: prometheus-k8s port: number: 9090监控# 使用grafana + prometheus来监控k8s 使用kube-prometheus来配置监控系统 安装# 替换被墙的镜像的源 *-deployment.yaml中搜索image关键字, 可以看到需要下载那些镜像 具体的文件有 blackbox-exporter-deployment.yaml grafana-deployment.yaml kube-state-metrics-deployment.yaml 包含k8s.gcr.io中的镜像, 需要提前替换 prometheus-adapter-deployment.yaml 包含k8s.gcr.io中的镜像, 需要提前替换 prometheus-prometheus.yaml prometheus镜像 修改kubelet configuration cat /var/lib/kubelet/config.yaml查看 set config.yaml authentication.webhook.enabled to true. 或者 kubelet \u0026ndash;authentication-token-webhook=true set config.yaml authorization.mode to Webhook. 或者 kubelet \u0026ndash;authorization-mode=Webhook kubectl create -f manifests/setup 等待下面的镜像下载完成 quay.io/brancz/kube-rbac-proxy quay.io/prometheus-operator/prometheus-operator until kubectl get servicemonitors \u0026ndash;all-namespaces ; do date; sleep 1; echo \u0026ldquo;\u0026rdquo;; done 官方该命令只是确保 kubectl create -f manifests/setup执行完毕, 没有实际意义 kubectl create -f manifests/ 查看images镜像 和 kubectl get pods -n monitoring查看安装进度 卸载kube-prometheus kubectl delete --ignore-not-found=true -f manifests/ -f manifests/setup # 对于某些无法卸载的, 可以使用强制卸载 kubectl delete pod -n monitoring \u0026lt;pod-name\u0026gt; --force grafana dashboard配置# 使用kube-prometheus安装完成之后, 默认的dashboards在defalut目录下, 包含了alertmanager, kubenets,node-export, prometheus等各种dashboard信息, 以及足够使用 报警配置# kubernetes 错误排查# 首先确认master节点是否安装成功 # 查看kube-apiserver, kube-controller-manager, kube-scheduler, etcd, pause服务 #kubectl get pods -n kube-system # -n表示namespace kubectl get pods --all-namespaces # 查看所有namespace的pods信息 # coredns为pending是正常的, 其在等待CNI网络插件 再确认node节点是否成功 kubectl get nodes kubectl get nodes -o wide #获取更详细信息 # Node状态为NotReady是正常的, 其在等待CNI网络插件 Q\u0026amp;A# node的状态显示为NotReady # kubectl get nodes # 显示STATUS为notReady# 1. 先查看node上的kubelet是否启动 systemctl status kubelet #如果未启动或者报错, 重启kubelet, systemctl restart kubelet # 2. 再看网络插件(CNI插件)是否安装 kubectl get pods --all-namespaces kubelet 找不到node journalctl -xeu kubelet Nov 05 17:22:16 ubt kubelet[775493]: E1105 17:22:16.246230 775493 kubelet.go:2412] \u0026#34;Error getting node\u0026#34; err=\u0026#34;node \\\u0026#34;node\\\u0026#34; not found\u0026#34;# kubeadm init --config kubeadm.yaml的 kubeadm.yaml中修改nodeRegistration.name为 执行机的hostname nodeRegistration: criSocket: /var/run/dockershim.sock imagePullPolicy: IfNotPresent name: k8s-m1 # 修改为执行节点的hostname，不然会提示找不到node taints: nulllocalAPIEndpoint: advertiseAddress: 1.2.3.4 #修改为master机器的ip bindPort: 6443 kubelet 提示cgroup错误 # kubeadm init --config kubeadm.yaml的 kubeadm.yaml中修改nodeRegistration.name为 执行机的hostname # cgroupDriver: systemd -- 这里暂时不知道什么意思, 修改为cgroupfs cgroupDriver: cgroupfs pod启动失败: had taint {node-role.kubernetes.io/master: }, that the pod didn\u0026rsquo;t tolerate. root@ubt:/home/dev_wangchengqing# kubectl describe pods alpine-6b967c77f7-9rvv2 Name: alpine-6b967c77f7-9rvv2 Namespace: default Priority: 0 Node: \u0026lt;none\u0026gt; Labels: app=alpine pod-template-hash=6b967c77f7 Annotations: \u0026lt;none\u0026gt; Status: Pending IP: IPs: \u0026lt;none\u0026gt; Controlled By: ReplicaSet/alpine-6b967c77f7 Containers: alpine: Image: alpine Port: \u0026lt;none\u0026gt; Host Port: \u0026lt;none\u0026gt; Environment: \u0026lt;none\u0026gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-kwqhc (ro) Conditions: Type Status PodScheduled False Volumes: kube-api-access-kwqhc: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: \u0026lt;nil\u0026gt; DownwardAPI: true QoS Class: BestEffort Node-Selectors: \u0026lt;none\u0026gt; Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 29s (x3 over 2m51s) default-scheduler 0/1 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn\u0026#39;t tolerate.# 因为 master 节点同时当 node 节点用，需要把 master 标签和污点去掉，默认 master 无法调度 # 去除master标签 kubectl label node ubt node-role.kubernetes.io/master- # 去除污点(无法调用schedule) kubectl taint node ubt node-role.kubernetes.io/master:NoSchedule- ingress-nginx提示404 确定ingress-controler启动 kubectl get svc -n ingress-nginx 确定ingress-rule配置正确 kubectl describe ingress -n ingress-nginx \u0026lt;ingress-name\u0026gt; 重点查看annotations的配置 必须配置kubernetes.io/ingress.class: nginx 必须配置ingress.kubernetes.io/rewrite-target: / 确定访问的方式正确 确定backend的pod-ip:port可以访问 此处的port为backend自己的port(即backend所在的svc的port, backend pod是没有端口的?? TODONOW待确定) 确定backend的svc-ip:port可以访问 此处的port为backend自己的port 确定ingress-nginx的pod-ip:port可以访问 此处的port为ingress-nginxd的port 确定ingress-nginx的svc-ip:port可以访问 此处的port为ingress-nginx的port 确定本地 localhost:port 可以访问 需要添加http标志, ingress-controler是对http的转发 此处的port为ingress-nginx映射的port 比如下方的话, 该port就是31468root@ubt:/home/dev_wangchengqing# kubectl get svc -n ingress-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.108.147.62 \u0026lt;pending\u0026gt; 80:31468/TCP,443:31055/TCP 22h ingress-nginx-controller-admission ClusterIP 10.107.83.233 \u0026lt;none\u0026gt; 443/TCP 22h 确定网络内其他主机可以访问 A-ip:port A-ip是ingress-nginx所在的机器的ip port是ingress-nginx隐射出来的port ingress-nginx svc 一直pending root@ubt:/home/dev_wangchengqing# kubectl get svc -n ingress-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.108.147.62 \u0026lt;pending\u0026gt; 80:31468/TCP,443:31055/TCP 23h ingress-nginx-controller-admission ClusterIP 10.107.83.233 \u0026lt;none\u0026gt; 443/TCP 23h# 1. 确认所在环境是否支持LB(LoadBalancer), 本地以及大部分云服务器商 都不支持 # 如果是使用ingress-controller, 使用NodePort更好 # 2. 确认ingress-nginx/pod是否正常 pod处于ImagePullBackOff状态 kubectl get pods -n monitoring# 通过下面的命令查看是哪个镜像没有拉取到, 然后使用mirror-image拉取即可 kubectl describe pods -n monitoring \u0026lt;pod-name\u0026gt; pod处于pending状态 kubectl get pods -n monitoring# 先查看pod状态 kubectl describe pods -n \u0026lt;pod-name\u0026gt; Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 134m default-scheduler 0/1 nodes are available: 1 Insufficient cpu. # 查看node状态 kubectl describe nodes Allocated resources: (Total limits may be over 100 percent, i.e., overcommitted.) Resource Requests Limits -------- -------- ------ cpu 1906m (95%) 1760m (88%) memory 1580Mi (41%) 2080Mi (54%) ephemeral-storage 0 (0%) 0 (0%) hugepages-1Gi 0 (0%) 0 (0%) hugepages-2Mi 0 (0%) 0 (0%) Events: \u0026lt;none\u0026gt; # 通过输出可以看到, cpu已经被占用到95%了, 所以导致有的pod无法启动, 对于这种情况, 可以通过增加node节点来解决 # k8s实际是对资源的管理, 资源包括cpu, 内存等等 "},{"id":17,"href":"/blog/docs/os/socket/asio/","title":"asio","section":"socket","content":"参考文档# https://mmoaay.gitbooks.io/boost-asio-cpp-network-programming-chinese/content/ http://blog.jqian.net/post/boost-asio.html https://www.limerence2017.com/2023/06/07/asio20/ 阻塞 vs 非阻塞# blocking vs non-blocking. 描述的是 调用线程是否等待结果 阻塞 发起调用后, 如果结果没准备好, 线程会一直开在那里, 直到得到结果. 线程在等待, 不能干别的事情. 例如read() 文件 非阻塞 发起调用后, 如果结果没准备好, 函数立即返回一个状态值, 线程可以继续干别的. 同步 vs 异步# synchronous vs asynchronous 描述的是 调用结果的获取方式 同步 调用方主动等待或轮询, 自己负责把结果取回来. 就算底层操作是非阻塞的, 你也可能要不停的问\u0026quot;好了没\u0026quot;. 异步 调用方发起请求后, 不需要主动等待, 结果准备好时, 会通过回调, 事件通知你. 一个类比（打饭窗口 🍚）# 阻塞同步：排队打饭，直到打好才走。 非阻塞同步：你不排队，隔一会儿自己跑来看看饭打好了没。 阻塞异步：你让食堂阿姨做好给你打电话，但你一直死守着电话，啥也不干。 非阻塞异步：你让食堂阿姨做好给你打电话，你该干啥干啥，饭好了电话通知你。 "},{"id":18,"href":"/blog/docs/prog_language/c++/stl/","title":"C \u0026\u0026 C++ 常见库","section":"c++","content":"C++ 常见库 \u0026lt;format\u0026gt;# 用法: 主要使用std::format() 意义: std::format之前, C++格式化字符要么使用C的format, 要么使用std::iostream C的format非类型安全; std::iostream效率低下 而std::fromat类型安全, 效率也高 备注: C++20中首次加入 1 2 template\u0026lt;typename... Args\u0026gt; std::string fromat(string_view fmt, const Args\u0026amp;... args); //例子1 //format()返回类型或值的字符串表示形式 //{}作为类型安全的占位符 string who{\u0026#34;lilei\u0026#34;}; int val{12}; double pi{std::numbers::pi}; format(\u0026#34;Hello, {}!\\n\u0026#34;, who); //Hello, lilei! format(\u0026#34;Val: {}\\n\u0026#34;, who); //Val: 12 format(\u0026#34;v: {}\\n\u0026#34;, who); //v: 3.141592652589793 //例子2 //左对齐\u0026lt;, 右对齐\u0026gt;, 中心对齐^ //{:.\u0026lt;10} 左对齐, 10占位, 不足使用.代替 //.是填充字符 //10表示占位大小 format(\u0026#34;{:.\u0026lt;10}\u0026#34;, 12); //12........ format(\u0026#34;{:.\u0026gt;10}\u0026#34;, 12); //........12 format(\u0026#34;{:.^10}\u0026#34;, 12); //....12.... //例子3 //设置数值的精读 format(\u0026#34;{:.5}\u0026#34;, std::number::pi); //3.1416*# 下面的都是待整理# *# 转换函数# c++11 支持 std::to_string(XX) XX 为int, short, long, longlong数值类型 std::stoi() 同类型的有std::stol(), std::stoll() 文件操作: fstream类# C++类, 头文件: #include \u0026lt;fstream\u0026gt; 流程函数 构造fstream对象 fstream file; 打开文件 file.open(file_name, mode) mode: fstream::out 写: 内存-\u0026gt;文件 fstream::in 读: 文件-\u0026gt;内存 当带有此模式的时候, 会默认认为文件存在, 即使文件不存在, 也不会创建文件; 所以对于需要创建文件的场景, 应该不带此mode 读文件 file \u0026gt;\u0026gt; string file_val \u0026gt;\u0026gt; 遇到 空格 \\n \\r \\t时候停止 \u0026ndash; 待确认TODONOW file.get(char ch) 每次读取一个字符 getline(file, string \u0026amp;file_val) 读取一行, 遇到\\n停止 file.read(char*buf, length) 在读指针位置读取length长度到buf中, 一般用于二进制文件 写文件 file \u0026lt;\u0026lt; file_val 待确认TODONOW file.put(ch) 写入一个字符 file.write(char*buf, length) 在写指针位置写入length长度的buf, 一般用户二进制文件 关闭文件 file.close 读写指针函数 获得读写指针位置 TODONOW 待确认 设置读写指针函数 读: seekg(postion) //postion绝对位置 一般用户文本文件 读: seekg(offset, ios::beg|ios::end::ios::cur) //offset相对位置 一般用户二进制文件, 最好勿在文本文件中使用 写: seekp(positon) 一般用户文本文件 写: seekp(offset, ios::beg|ios::end|ios::cur) 一般用户二进制文件, 最好勿在文本文件中使用 fstream状态函数 if(file) 检验流是否有效 这个需要重点查看下, 什么时候流会失效 已知: file.eof()时候, file则会变为无效 file.is_open() 流是否打开了文件 file.eof() 是否到了文件尾 file.clear() TODONOW 这个也需要再看下 如果file.eof(), 调用clear可以重置标志; 重置标识后, file重新变为有效流 字符串: string类# 构造 比较 查找 插入 删除 curses使用# 官方地址: http://www.tldp.org/HOWTO/NCURSES-Programming-HOWTO/windows.html *# FILE# FILE是C的文件操作 \u0026ndash; C++的为fstream 问: 为什么有了fstream 还需要FILE? 答: 很多系统函数,都是对C的支持, 比如popen()函数等 fopen fread fwrite fclose *# C++ 与 shell的互相调用,传参,获取运行输出# 左值, 右值, 左值引用, 右值引用# 左值 lvalue(loactor value) \u0026ndash; 地址 右值 rvalue(read value) \u0026ndash; value lvalue 是“loactor value”的缩写，可意为存储在内存中、有明确存储地址（可寻址）的数 rvalue 译为 \u0026#34;read value\u0026#34;，指的是那些可以提供数据值的数据（不一定可以寻址，例如存储于寄存器中的数据） 有名称的, 可以获取到存储地址的 变量或表达式为左值, 其余为右值引用 \u0026amp; \u0026ndash; 只能操作左值, 称为左值引用 \u0026amp;\u0026amp; \u0026ndash; 只能操作右值,称为右值引用 std::move(arg) \u0026ndash; 可以把左值引用转换为右值引用 左值引用, 对于类来说, 会使用copy 构造函数 右值引用, 对于类来说, 会使用移动构造函数 "},{"id":19,"href":"/blog/docs/prog_debug/valgrind/","title":"valgrind","section":"prog debug","content":"程序检测工具 valgrind# 程序性能查看工具,号称程序员的瑞士军刀 可以查看内存信息, 函数调用, cache信息等等 "},{"id":20,"href":"/blog/docs/prog_language/elisp/","title":"elisp","section":"prog language","content":"参考文档 水木社区Emacs版 lisp的本质 基础语法# 函数重载# elisp没有重载的概念, 直接覆盖原定义即可. 相关函数: advice-add 根据key来决定old_fun 与 new_fun的关系 key desc filter-return 先执行old. new对old的结果再处理 before 先执行new, 过滤一下数据, 再把结果给old arround 先执行new, 并在new中主动调用old(也可以不调用) 使用defune 覆盖原函数定义 如果只是重载, 应该使用这种方法. advice-add的本意不是用来override elisp \u0026amp;\u0026amp; shell# bash调用elisp# elisp代码写入el文件(eshell script) bash调用emacs执行el文件 # 实际还是emacs 执行的elisp代码 emacs -u clay --script /Users/clay/.emacs.d/lisp/fun/init-hexo-fun.el elisp 调用bashe# (setq my-command (concat \u0026#34;IFS=: read -ra dirs \u0026lt;\u0026lt;\u0026lt;\\\u0026#34;$PATH\\\u0026#34;\\n\u0026#34; \u0026#34;for dir in ${dirs[@]}; do\\n\u0026#34; \u0026#34; echo got dir \\\u0026#34;$dir\\\u0026#34;\\n\u0026#34; \u0026#34;done\\n\u0026#34;)) (shell-command (format \u0026#34;bash -c %s\u0026#34; (shell-quote-argument my-command)))"},{"id":21,"href":"/blog/docs/emacs/org/org_agenda_for_gtd/","title":"org agenda for GTD","section":"org","content":"需求分析# 所有的设计都是基于需求的. 当前需求: 有哪些task 他们归属于哪个PROJECT 他们的四象限: 紧急\u0026amp;\u0026amp;重要 工作量预估 关联性 A task可能与B, C相关联 TODO 该任务并未完成 当前正在处理的任务 尽可能的关注当前, 忽略其他 当某个task进行时, 快速capture我的想法, 并且自动refile 看到自己花费的时间 一天,一周都做了什么 某个project/task总共花费的时间 流程的设计# -------------------------+------------------------ | | capture (easy) | | v archive +---------+ +-------------------| inbox | | +----+----+ | | | | refile (auto) | | | | | |----------------+--------------------| | | | | | | v v | v +---------+ +---------+ | +---------+ | my/emacs| | work/qy | | | task | | * emacs| | * ker | | +----+----+ | * org | | * frame| | | | * ccIDE| | * sub | | | +---------+ +---------+ | | | | archive (auto) | | | v | +---------+ +-\u0026gt;| archive | +----+----+文件的设计# 每个大型Project 应该单独一个file. 比如emacs.org gtd \\_ gtd_common // 通用gtd流程文件 \\_ inbox.org // 收集箱 \\_ task.org // 任务清单 \\_ archive.org // 归档文件 \\_ gtd \\__ emacs.org // emacs project file \\__ qygame.org // qygame project filegtd_common中保存的是一些通用的, 可能暂时不好归类的PROJECT以及TODO file desc inbox.org 不区分时间,场景, 灵光一闪即可扔进去 task.org 任务清单 archive.org 归档文件 TODO的设计# TODO 或 WAITTING是最小的 执行单元. 不应该再TODO下再设置TODO (可以使用列表来拆分) key desc TODO 等待自己处理 WAITTING 等待他人完成 PROJECT 项目 DONE 完成 CANCEL 取消 TAGS的设计# 四象限使用proirity来区分; TAGS为之后快速查找使用 Effort的设计# effort是自己对某个task工作量的预估. 与task完成时的clock-sum-time比对, 可以更好的进行分析. 对于Project, 在org-agenda-buffe中只会统计Project自身的effort, 忽略subtree的. 如果想看subtree的Effort与Clock对比, 可以进入到file中使用org-columns-view视图 为了方便的effort, 这里只在两处设计了提示: capture的时候, 可以输入effort. 当然为了快速capture, 这里允许输入0跳过 clock-in的时候, 如果item effort还是0, 则会要求进入工作预估 clock的设计# org的clock已经非常好用了. 这里只是修改了clock 的显示样式 capture设计# 经常是在工作的时候, 突然有了某个想法. 这个想法也许值得记录, 但不要打断当前的思路. 所以capture应该是快速的, 但又要明确的(归属要明确) 为了快速capture, 所以不应该考虑这个想法应该放到哪个file. 统一放到inbox即可. 为了后面的auto refile, 这个想法或item 应该携带足够的信息, 可以完成auto refile. 这里的办法是给item一个tag. 比如 capture了一个item, 再给其增加对应的tag 下面表明这是一个与PROJECT emacs有关的task * org应该快速capture :emacs:refile的设计# refile应该是自动完成的, 不应该手动 为了自动完成, item已经给了相关信息(tag) 在gtd的PROJECT中, 也应该携带足够的信息去与该tag匹配. 只有匹配成功了, 就可以auto-refile 这里的办法是匹配PROJECT ITEM的heading, 比如: 当capute-item的tag 与 PROJECT-item的heading相匹配的时候, 会自动refile * PROJECT emacsarchive的设计# archive的目的: 在org file中隐藏已 DONE 的task 后期统计 归档 现在方案: 对于gtd中的task, archive到当前Project Heading的** archive 对于gtd_common中的task, archive到archive.org Agent的设计# agent的目的有2个: 查看各种代办事项 今天的和未来的 (org-agenda-view) TODO的 (org-next-view) inbox中的 (org-inbox-view) 统计信息 以time为视角的统计, 比如今天或这周做了哪些TODO或PROJECT org clock report (day/week/month/year) 以PROJECT为视角的统计. 比如统计emacs PROJECT花费的时间 org-project-view, org-archive-view 以及在特定PROJECT file中的org-colmun-view查看具体task 使用流程# | | capture with add timestamp \u0026amp;\u0026amp; | template +---------+ auto refile +---------+ auto refile +---------+ archive +---------+ +---------------\u0026gt;| inbxo |--------------\u0026gt;|next step|------------------\u0026gt;| agenda |--------------\u0026gt;| archive | | +---+-----+ +---------+ +---------+ +---------+ | | ^ | | archiv | | +----------------------------------------------------------------------------------+ | capture -\u0026gt; inbox -\u0026gt; auto refile 在org-next-view buffer中添加timestamp可放到org-agenda-view; 或者直接执行archive操作 在org-agenda-view buffer中调用archive 其实还有最后一步, 即把archive中的内容输出到blog中 "},{"id":22,"href":"/blog/docs/tool/monitor/","title":"cadvisor, prometheus, grafana","section":"tools","content":"cadvisor, prometheus, grafana 组成的监控系统 总览# cadvisor 收集docker容器数据 nodex_exporter 收集主机数据 prometheus 数据库 grafana 数据展示 cadvisor# cadvisor负责收集docker容器的运行信息, prometheus下的cadvisor metrics指标. cadvisor开箱即用, 不需要专门配置 node exporter# node exporter是prometheus的收集器, 收集linux的硬件和os信息. node exporter开箱即用, 不需要专门配置 prometheus# prometheus不仅仅是数据库, 还是一套完整的监控系统. 配置# prometheus的配置非常简单, 一个 prometheus.yml 即可. 适合集群部署 global: scrape_interval: 15s # By default, scrape targets every 15 seconds. # Attach these labels to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: monitor: \u0026#39;codelab-monitor\u0026#39; # A scrape configuration containing exactly one endpoint to scrape: scrape_configs: # The job name is added as a label `job=\u0026lt;job_name\u0026gt;` to any timeseries scraped from this config. - job_name: \u0026#39;nodeexporter\u0026#39; # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: # - targets: [\u0026#39;host.docker.internal:9100\u0026#39;] - targets: [\u0026#39;node_exporter:9100\u0026#39;] - job_name: \u0026#39;cadvisor\u0026#39; scrape_interval: 5s static_configs: - targets: [\u0026#39;cadvisor:8080\u0026#39;] - job_name: \u0026#39;prometheus\u0026#39; scrape_interval: 10s static_configs: - targets: [\u0026#39;localhost:9090\u0026#39;]grafana# grafana用于数据可视化 \u0026amp;\u0026amp; 监控 TODO 补充 Provision 逻辑 datasource# 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 apiVersion: 1 datasources: - name: Prometheus type: prometheus # Access mode - proxy (server in the UI) or direct (browser in the UI). access: proxy url: http://prometheus:9090 jsonData: httpMethod: POST exemplarTraceIdDestinations: # Field with internal link pointing to data source in Grafana. # datasourceUid value can be anything, but it should be unique across all defined data source uids. - datasourceUid: my_jaeger_uid name: traceID # Field with external link. - name: traceID url: \u0026#39;http://localhost:3000/explore?orgId=1\u0026amp;left=%5B%22now-1h%22,%22now%22,%22Jaeger%22,%7B%22query%22:%22$${__value.raw}%22%7D%5D\u0026#39; dashboard# 一个dashboard 由1个多个panel面板组成, 可以有多个dashboard 每个dashboard对应一个xx.yaml 每个面板对应一个配置文件xx.json dashboard的配置文件xx.yaml中有个特殊的字段, 可以把指定目录下的 子目录变为dashboard, 子目录下的xx.json变为面板 path: $GF_PATHS_PROVISIONING/dashboards foldersFromFilesStructure: true当 foldersFromFilesStructure设置为true的时候, path下的子目录名字会变为dashboard的名字 子目录下的xx.json会变为该dashboard下的panel面板 这样我们只需要配置一个总的yaml, 然后规划path下的目录层级即可, 方便进行统一的管理 面板的配置文件 xx.json 可以找一些经典的, 在此基础上修改为适合自己的 alerting# alter rule contact point notification policy "},{"id":23,"href":"/blog/docs/prog_language/shell/","title":"shell","section":"prog language","content":"shell 记录 记录# exit 与 return return 退出函数; 在非函数地方, 无效 exit 在任何地方, 都代表推出sh $# 代表入参 sh脚本的入参在非函数地方调用 函数的入参在调用函数的地方传递 $@ 可以传递所有的参数到下一层 数组使用echo打印的话 只会显示第一个 与 区别 更高级, 识别与或非等; 而[ ] 不识别 \u0026rsquo; \u0026rsquo; 与 \u0026quot; \u0026ldquo;区别 在 \u0026rsquo; \u0026lsquo;中的变量不会被展开; \u0026lsquo;$a\u0026rsquo;显示出来是字面值$a 空语句 是 : 数组 ${name[@]} ${name[*]} 获取函数返回值 return的返回值 可以通过 $?获取 但是该返回值返回的只能是0-255的数字 fun_check $? # 获取fun_check的返回值 echo的返回值 可以通过$()调用获取 ret=$(fun_check) 获取文件名 和 扩展名 file=\u0026#34;1.2.3.4.5\u0026#34; ${file%%.*} # =\u0026gt;1 ${file%.*} # =\u0026gt;1.2.3.4 ${file#*.} # =\u0026gt;2.3.4.5 ${file##*.} # =\u0026gt;5 "},{"id":24,"href":"/blog/docs/emacs/lisp/tramp/","title":"tramp","section":"常用扩展","content":"全称 transparent remote access multiple protocol tramp是用来编辑远端文件的模块, 支持多种协议 ssh, ftp, smb, adb等, 常用method ssh su | sudo # 这种并不连接到远程主机, 而是允许使用另一个用户身份打开本地文件 /su:root:path/ 用法# basic# /method:user@host#port:/path/to/file # example 1 /ssh:clay@192.1.1.1#22:~ # example 2 windows下可以使用putty作为ssh的client /plink:clay@192.1.1.1:~set default method# (setq tramp-default-method \u0026#34;plink\u0026#34;) ; 设置之后的例子 ; 可以设置linux和windows下默认的method，之后就无需考虑操作系统 /-:clay@192.1.1.1:~multiple hop# # 在本机上, 通过clay用户登录到host1 # 再在host1上, 通过admin登录到host2 /ssh:clay@host1|ssh:admin@host2:/pathsu | sudo# # 使用sudo打开远程文件 /-:clay@192.1.1.1|sudo::/path # 使用sudo打开本地文件 # su::默认的是 su:root@localhost. 配置在tramp-default-method-alist /su::local-path /su:user@localhost:/local-path /sudo:root@localhost:/local-pathuse with bookmarks# tramp使用的时候 需要使用到method user host path的组合，一般较长 我们更希望使用较短的shortcut去远程打开某个file 这里推荐的方法是bookmark. 理由: bookmark emacs内置, 而且非常方便 bookmark 的配置信息 可以方便git管理 使用方法: # 1.远程连接 C-x f /ssh:clay@192.1.1.1:~ # 2.添加到bookmark C-x C-f BOOK-NAME RET # 3.查看bookmark C-x C-f # 4.管理bookmark配置文件 ~/.emacs.d/bookmarks # 5.管理auth信息文件 ~/.emacs.d/authinfo"},{"id":25,"href":"/blog/docs/emacs/lisp/graph/","title":"画图","section":"常用扩展","content":"what# artist-mode和dot都可以完成绘图的功能. mode 简述 优点 缺点 artist-mode ASCII绘图 1.ASCII表示图形 1.功能少 2.短小精悍 2.需要手动绘制图形 mermaid dot绘图 1.只关注逻辑设计,布局自动生成 1.生成的为图片文件, 而非可嵌入的ASCII代码 2.需要学习dot语言 "},{"id":26,"href":"/blog/docs/prog_base/05_programming_paradigm/","title":"编程范式","section":"prog base","content":"Programming paradigm 即编程范型, 编程范式, 程序设计法 简述# paradigm(范式) 表示一种基本的思维方式; Programming paradigm(编程范式) 表示对于 编程 这件事的思维方式; 编程是把 =现实领域问题= 抽象为 =程序模型=常见编程范型# 编程范型只是一种思维方式, 不是互斥的. 比如面向对象编程中虽然把 =现实领域问题= 抽象为对象的交互 但是对于 =对象的方法(成员函数)= 也许仍是 抽象为一个个过程调用(过程式编程) 所以不要拘泥于某种编程范型 指令性编程 早期计算机还不智能(抽象层面还不够), 需要更多注意力在硬件层面. 现实领域问题 就是按顺序一步步执行 程序模型 也更多的是对硬件层面的关注, 需要对硬件精细控制 过程式编程 现实领域问题 被分解为一个个过程(function) 程序模型 就是一个个过程调用(function call) 基于对象编程 现实领域问题 被分解为对象之间的交互 程序模型 就是对象的管理 此时的对象仅仅是对数据和方法的封装 面向对象编程 现实领域问题 被分解为对象之间的交互 程序模型 就是对象的管理 与基于对象编程不同的是, 这里的对象含义有所区别 这里对对象进行了扩展(继承), 丰富了对象的功能 函数式编程 函数式编程将电脑运算视为函数运算，并且避免使用程序状态以及可变对象 TODO 还不是很了解 函数式编程# 函数式编程问答 (重点看 tzaeru的回答) 可以从几个不同的角度来看待这个问题，但我会从可读性/便利性的角度出发； 所以，编程基本上就是获取数据、转换数据，然后输出数据。 函数式编程允许更明确地关注数据的实际转换，而不是关注计算机需要采取的步骤来转换数据。这种更关注“是什么”而不是“怎么做”的范式被称为声明式编程。 例如，假设我们有一个用户列表，我们想找到生日在 1 月份的用户（你可能会在 SQL 或类似的东西中真正做到这一点，但这只是一个假设的例子） 如果你主要用命令式风格来做，它可能看起来像这样： const users = getUsers() var birthdayUsers = array[] for (i = 0; i \u0026lt; users.length(); i++) if (users[i].birthdate.month == months.January) birthdayUsers.push(users[i]) 与更函数式的风格相比： const birthdayUsers = getUsers().filter(user =\u0026gt; user.birthdate.month == months.January) 一旦你习惯了后一种风格，它就更具可读性（因为；你立刻知道这是关于过滤的，并且已经知道 filter 函数是如何工作的），更具可扩展性（你可以立即链接另一个函数调用）并且更不容易出错（在这种情况下，它并不那么明显，但在更大的例子中，命令式风格更容易出现例如差一错误等等） 函数式编程的一个潜在陷阱是，人们最终会编写出过于聪明的代码，一眼难以理解。尤其是在更纯粹的函数式编程语言中的代码可能有点难以阅读，因为可能更喜欢使用大量的内部匿名函数、非常短且无意义的变量名等等，是的，这是一个真正的问题。 一些语言明确希望避免开箱即用的对更函数式编程风格的支持。例如 Go。那里的想法是，该语言应该显而易见、简单，并且不提供太多选项来做同样的事情。对于 Go 来说，这是一个不错的选择。就我个人而言，我有点不喜欢它，而且为那些用简单的 map 或 filter 编写更方便的东西编写 C 风格的循环很烦人。 根据我的经验——虽然我不想把它变成一个权威的争论，但为了说明情况，我想说这种经验非常广泛和多样——最易读、最容易处理的代码库是那些_更喜欢_函数式，但使用命令式概念而不是长函数链或大型嵌套函数结构来将东西分解成更小的步骤的代码库。 函数式编程的实际要点确实不是例如“函数是一等公民”；它们在某些我们不认为特别函数式的语言中是这样的。它不是嵌套函数。它甚至不是匿名函数。 实际要点是命令式编程和声明式编程之间的区别。关注“是什么”而不是“怎么做”。函数式编程是一种声明式编程，它侧重于通过组合函数来描述“是什么”。不幸的是，这通常是一个非常抽象的事情，很难理解，有时也很难解释。因此，许多文章和在线评论都侧重于技术细节，例如“对于函数式语言，你需要将函数作为一等公民”（然后我们可以争论“函数作为一等公民”的含义）。 要点是这样的；我不想向计算机描述我想要一个索引变量，并在索引变量小于 10 时重复这段代码，并在每次迭代时将索引变量递增 1 .. 我不想这样做的原因是因为这与实际数据、与我想对数据进行的实际转换无关。 相反，我想告诉计算机“我有这些数据，我只想从中获取 ID，按降序排列”。我可以更接近于这样做的一种方法是组合函数；一个从数据中仅选择 ID 并返回一个数组的函数，以及一个然后对数组进行排序以使 ID 排序的函数。函数式编程的核心思想是你的函数没有副作用。这意味着它们不会改变自身之外的任何东西。这意味着，任何时候你用相同的输入调用你的函数，你都会得到完全相同的输出。行为将完全相同。 例如，如果你的函数接受一个指针/引用到某个其他对象并增加一个计数器，那将是一个副作用。每次你运行你的函数时，都会发生不同的事情。所以那不是一个“纯”函数。如果函数改为将一个计数器对象作为输入，并返回一个新的计数器对象，其值已增加，那么你现在就有一个纯函数。 这就是核心思想，仅此而已。这个核心思想有很多后果： 单元测试一个函数更容易，因为你知道如果你给它一个特定的输入，你应该得到一个特定的输出。你不需要先检查数据库或外部对象的状态，就知道输出应该是什么。 出于同样的原因，更容易推断该函数 函数可以组合。如果你有一个函数可以向上移动玩家，还有一个函数可以发射玩家的枪，你可以安全地将这些函数组合在一起，进行跳跃-射击，并确信它会按预期工作。将函数传递给函数和部分应用函数都变得更安全，并且效果更好。 使用此类函数的多线程更容易，因为你可以确保多个线程不会同时触及相同的内存 也有一些缺点，首先，一个没有任何副作用的程序是无用的。必须在某个时候向屏幕、数据库或网络输出一些内容才能做一些有用的事情。函数式程序员只是试图最小化它并隔离它。 然后，许多保持最小化副作用的方法都有糟糕的性能后果，所以在某些情况下，你必须在某种程度上放弃它。但即使是像 John Carmack 这样的硬核游戏程序员也写过关于尝试尽可能函数式 *的价值*，这将取决于你正在构建什么。命令式编程例子 向计算机描述我想要一个索引变量，并在索引变量小于10时重复这段代码，并在每次迭代时将索引变量递增1 我不想这样做的原因是因为这与实际数据、与我想对数据进行的实际转换无关函数式编程例子 我想告诉计算机“我有这些数据，我只想从中获取ID，按降序排列”。 我可以更接近于这样做的一种方法是组合函数；一个从数据中仅选择ID并返回一个数组的函数，以及一个然后对数组进行排序以使ID排序的函数。 "},{"id":27,"href":"/blog/docs/tool/hugo/","title":"hugo","section":"tools","content":"使用hugo + github搭建blog 前言# 记录blog好处很多, 却也增加了使用者的难度, 比如要理解html,css等. 同时,外在的表现往往会导致重心偏移, 过多追求外在的东西, 忽略了记录blog的初衷. 因此, 需要一个能让我们专注于文章知识本身, 而无需去关心其他的工具, 来帮助我们搭建blog. 当下, 一个不错的选择是hugo. hugo不拘束文章语言(markdown, org等), 自动将语言转化为html, 并且提供不错的主题外观, 使我们可以专注文章本身. hugo是什么# 如上所言, hugo是一款不错的blog框架 主要优点: 不限制前端语言 自动化生成html 丰富便捷的themes 与github action无缝结合, 无须在本地搭建hugo运行环境 迅速上手, 学习时间短 对org-mode的支持可以忍受 hugo使用# 安装# 不建议在本地搭建hugo环境. 如果blog托管在github, 强烈推荐使用github action来部署. 配置# hugo配置非常简单, 可以参考hugo.toml github action的配置, 可以参考yml 使用# hugo官方guthub action是把content目录下的md文件, 转换为静态的html文件. 所以我们只要把自己的blog文件在官方之前, 转换为md文件放到content目录下面即可. 同样的, 我们也可以把自己生成的html文件直接放到content目录 虽然github action做了很多动作, 但我们需要做的只是维护自己的blog文件, 并git push即可. blog的更新流程由github action完成, 我们无须关心. hugo高级用法# section \u0026amp;\u0026amp; bundle \u0026amp;\u0026amp; menu# key desc menu top navigation (所有文章|分类|标签|关于) section post|docs|menu等 bundle 文件资源的管理方式 bundle 只能是index.md 或者_index.md. 其他后缀名无效 TODO 增加bundle的详细解释 module# hugo module可以代替主题 使用步骤: 把自身仓库变为hugo module 实际就是增加了一个go.mod文件 在config.toml中增加module import 代替了theme, 所以这里的theme要删除, 否则hugo执行的时候会提示找不到theme 调用hugo时, hugo会主动下载module, 并且把它认定为theme文件 vs gitsubmodule 优势 gitsubmodule还需要管理使用的theme的信息, module完全不需要管理 gitsubmodule 可以使用 update \u0026ndash;remote来指定使用远程仓库信息, 但是繁琐, 不如go.mod方便 highlight# 代码高亮风格: hightlight style shortcode# TODO 待补充 简单理解, 每个hugo theme可以定义自己的shortcode 这样可以充分扩展 markdown的语法 自定义域名# 实现子域名www.wcq.life 与 顶域名 wcq.life均可访问 hugo配置# 修改配置文件 baseURL = \u0026#34;https://www.wcq.life\u0026#34;github配置# 在blog/static目录下新增CNAME文件, 其内容为域名, 比如 www.wcq.life static目录下的内容, 会由hugo action自动放到网站根结点. 这符合github的要求 域名服务商配置# wcq.life绑定教程 建议创建 wcq.life指向 github的A记录 www.wcq.life绑定教程 创建www.wcq.life指向clay9.github.io的CNAME即可 blank-line# hugo 默认使用goldmark作为md的解析器 设置markup.goldmark.renderer.hardWraps为true, goldmark 会把 \\n =\u0026gt; \u0026lt;br /\u0026gt; 如果在emacs中设置(setq org-export-preserve-breaks t), ox-hugo也会把 \\n =\u0026gt; \u0026lt;br /\u0026gt; 所以两者只需要设置一个, 这里建议设置emacs中的 hugo book theme# 基本概念# hugo-book-theme 的file-tree-menu (这里的file-tree-menu 不是上面的menu) server \\_ _index \\_ view \\_ _index \\_ page_3 \\_ page_4 \\_ page_1 \\_ page_2server/_index 是server的信息显示 server/view/_index是server/view的信息显示 (也可以没有) page_1, page_2的weight只影响自身节点(server节点)下的排序, 不会影响server/view节点 hugo_book 简介的显示, 需要放到content/_index.md中 参考文档# 可以参考官方的例子去做 官方deamon对应的web展示 官方github网址 Q \u0026amp; A# buildFuture: hugo无法正常发布DATE等于今天的blog date导致的发布时间问题. 与github(美国时间)有时差, 导致发布的贴子无法立刻查看. date的本意是 创作时间. 但是publishData为空的时候, 猜测使用了date时间. 而date又有时差, 导致帖子无法立刻被查看. 解决方案: 在gh-pages.yml中为hugo增加参数 hugo \u0026ndash;minify \u0026ndash;buildFuture "},{"id":28,"href":"/blog/docs/prog_compile/make/","title":"make","section":"prog compile","content":"make记录 常用# make make clean make install \u0026ndash; 编译成功的文件安装到系统目录 make dist 产生发布软件包文件（即distribution package 这个命令将会将可执行文件及相关文件打包成一个tar.gz压缩的文件用来作为发布软件的软件包。 它会在当前目录下生成一个名字类似“PACKAGE-VERSION.tar.gz”的文件 PACKAGE和VERSION，是我们在configure.in中定义的AM_INIT_AUTOMAKE(PACKAGE, VERSION)make distcheck 生成发布软件包并对其进行测试检查，以确定发布包的正确性 这个操作将自动把压缩包文件解开，然后执行configure命令，并且执行make，来确认编译不出现错误 最后提示你软件包已经准备好，可以发布了make# -j num 同时启动多少个jobs一起编译, 一般为系统内核数的2倍 make打印信息 不显示目录 make --no-print-directory make打印信息优化 SHOW_COMPILE=@echo -e \u0026#34;\\033[36mCompling \\033[35m==\u0026gt; \\033[33m$\u0026lt;\\033[0m\u0026#34; SHOW_LINK=@echo -e \u0026#34;\\033[31mLINKING \\033[35m==\u0026gt; \\033[33m$(EXEFILE)\\033[0m\u0026#34; SHOW_DEBUG_BUILD=@echo -e \u0026#34;\\033[31mBuilding Debug...\\033[0m\u0026#34; SHOW_RELEASE_BUILD=@echo -e \u0026#34;\\033[31mBuilding Release...\\033[0m\u0026#34; makefile 中的 \u0026ldquo;+ - @\u0026rdquo; 实际为shell中的规则, 不是makefile中的 符号 作用 @ 使命令被执行前不回显 - 使任何命令行的非0退出状态都被忽略 + 使命令行可以通过制定-n -q或-t选项来执行 内置函数 patsubst 格式：$(patsubst \u0026lt;pattern\u0026gt;,\u0026lt;replacement\u0026gt;,\u0026lt;text\u0026gt; ) 名称：模式字符串替换函数——patsubst。 功能：查找\u0026lt;text\u0026gt;中的单词（单词以“空格”、“Tab”或“回车”“换行”分隔）是否符合模式\u0026lt;pattern\u0026gt;，如果匹配的话，则以\u0026lt;replacement\u0026gt;替换。 这里，\u0026lt;pattern\u0026gt;可以包括通配符“%”，表示任意长度的字串。如果\u0026lt;replacement\u0026gt;中也包含“%”，那么，\u0026lt;replacement\u0026gt;中的这个“%”将是\u0026lt;pattern\u0026gt;中的那个“%”所代表的字串。 （可以用“\\”来转义，以“\\%”来表示真实含义的“%”字符） 返回：函数返回被替换过后的字符串。 示例： $(patsubst %.c,%.o, a.c b.c) 把字串“a.c b.c”符合模式[%.c]的单词替换成[%.o]，返回结果是“a.o b.o” $@ $^ $ $\u0026lt; $? $@ 表示目标文件 $^ 表示所有的依赖文件 $\u0026lt; 表示第一个依赖文件 $? 表示比目标还要新的依赖文件列表 gcc编译过程 预处理 -E .cpp -\u0026gt; .i 汇编 -S .i -\u0026gt; .s 编译 -c .s -\u0026gt; .o -o 仅仅是输出目标的file_name, 不一定是连接后的file_name, 比如 gcc -S hello.i -o hello.sgcc 不带参数可以 跟随.cpp .i .s .o类型的文件, 会自动执行预处理, 汇编, 编译, 连接的动作 所以连接不需要指定参数 wildcard Makefile规则中，通配符会被自动展开。但在变量的定义和函数引用时，通配符将失效。 这种情况下如果需要通配符有效，就需要使用函数“wildcard”，它的用法是：$(wildcard PATTERN\u0026hellip;) 。 在Makefile中，它被展开为已经存在的、使用空格分开的、匹配此模式的所有文件列表。 如果不存在任何符合此模式的文件，函数会忽略模式字符并返回空。 需要注意的是：这种情况下规则中通配符的展开和上一小节匹配通配符的区别。 makefile只能在taget的地方调用shell, 其他地方无效 其他地方调用需要使用 $(shell cmd) "},{"id":29,"href":"/blog/docs/emacs/lisp/mail/","title":"mail","section":"常用扩展","content":"不建议使用, 没啥意义 简述# emacs 流行的email client 有mu4e, notmuch, gnus等 因为对email不是刚需, 只是轻度使用, 所以这里选了内置对gnus. 理由如下: emacs 内置 顺便尝试 newsgroup 轻度使用email 反而发现gnus非常难配置, 因为可定制的选项太多了, 所以不是很友好 gnus的缺点: 配置复杂, 花了24h才看完官方文档. 发现实际用到的也就5% ? gnus是单线程, 所以如果网络不好, 非常容易把emacs卡住, 比如访问gmail 基本概念# gnus概念划分比较友好, server, group, summary, article 各司其职, 又互相联系, 比较方便, 具体可以参考官方文档 操作流程# 设置server subscribe group enter group. show summary read article group level# group在gnus中是比较重要的概念. 而group level 可以更好的理解group 官方描述中: subscribe : 1 - guns-level-subscribed (5) unsubscribe: gnus-level-unsubscribed (7) zommbie: 8 killed: 9 level越高越不重要可以发现killed group有最高的level, 而unsubscribe level 和 subscribe level实际在gnus中处理差异不大. 所以如果不想看到某个组, 直接kill. 因为Gnus 不会向server询问zoomibe \u0026amp;\u0026amp; killed group的数据 gnus-group-list-group 显示 unread subscribe gnus-group-list-all-group 显示 subscribe \u0026amp;\u0026amp; unsubscribe mail# mail 在gnus中是一种特殊的group. 特殊在哪\u0026hellip;TODO 待补充 mail的设置非常简单, 因为我的需求只是阅读邮件, 所以使用了nnimap作为backend. 实际上gnus支持的mail back非常的多, 功能也非常强大 gmail 或者 国外的mail# 不建议使用国外mail, 网络不好会卡住emacs 如果一定要用, 推荐使用代理. 代理可以在emacs中配置, 也可以在代理软件中配置. 比如gmail: imap.gmail.com:993 smtp.gmail.com:587 下面的为个人猜测, 未验证如果设置了代理, 还是无法连接, 有可能是短时间连接次数过多, 被gamil服务器暂时拦截了 等一段时间再试即可 "},{"id":30,"href":"/blog/docs/prog_base/06_principles/","title":"设计原则","section":"prog base","content":"面向对象编程的 六大设计原则 简述# 单一职责原则 原则思想：一个对象只负责一件事情 描述：单一职责原则很简单, 一个对象只负责一个职责, 各个职责的程序改动, 不影响其它程序. 这是常识, 几乎所有程序员都会遵循这个原则. 优点：降低类和类的耦合, 提高可读性, 增加可维护性和可拓展性, 降低可变性的风险. 里氏替换原则 原则思想：使用的基类可以在任何地方使用继承的子类，完美的替换基类。 描述：子类可以扩展父类的功能，但不能改变父类原有的功能。子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法，子类中可以增加自己特有的方法。 优点：增加程序的健壮性，即使增加了子类，原有的子类还可以继续运行，互不影响 依赖倒置原则 原则思想：高层次的模块不应该依赖于低层次的模块，他们都应该依赖于抽象，抽象不应该依赖于具体实现，具体实现应该依赖于抽象。 描述：类A直接依赖类B，假如要将类A改为依赖类C，则必须通过修改类A的代码来达成。这种场景下，类A一般是高层模块，负责复杂的业务逻辑；类B和类C是低层模块，负责基本的原子操作；假如修改类A，会给程序带来不必要的风险。 优点：可以减少需求变化带来的工作量，做并行开发更加友好。 接口隔离原则 原则思想：类和类之间应该建立在最小接口的上。 描述：类A通过接口依赖B，类C通过接口依赖D，如果接口类A和类B不是最小的接口，则依赖的类B和类D必须要实现他们不需要的方法。 优点：提高程序的灵活度，提高内聚，减少对外交互，使得最小的接口做最多的事情。 迪米特法则 原则思想：一个对象应当对其他对象有尽可能少地了解，简称类间解耦 描述：一个类尽量减少自己对其他对象的依赖，原则是低耦合，高内聚，只有使各个模块之间的耦合尽量的低，才能提高代码的复用率。 优点：低耦合，高内聚 开放封闭原则 原则思想：尽量通过扩展软件实体来解决需求变化，而不是通过修改已有的代码来完成变化 描述：一个软件产品在生命周期内，都会发生变化，既然变化是一个既定的事实，我们就应该在设计的时候尽量适应这些变化，以提高项目的稳定性和灵活性。 优点：单一原则告诉我们，每个类都有自己负责的职责，里氏替换原则不能破坏继承关系的体系 "},{"id":31,"href":"/blog/docs/prog_compile/cmake/","title":"cmake","section":"prog compile","content":"cmake 参数# -S path_to_source -B path_to_build -G generator-name cmake . -LH F\u0026amp;Q# err: Tell CMake where to find the compiler by setting either the environment variable \u0026#34;CXX\u0026#34; or the CMake cache entry CMAKE_CXX_COMPILER to the full path to the compiler, or to the compiler name if it is in the PATH.sln: sudo apt install gcc sudo apt install g++ "},{"id":32,"href":"/blog/docs/emacs/lisp/gdb/","title":"gdb \u0026\u0026 gud","section":"常用扩展","content":"简述# emacs使用gud来绘制gdb的调试信息. gud可以认为是gdb的ui client. 具体可以参考github的init-gdb.el和一些自定义gud函数 gdb使用# 指令 简写 描述 attach 附加到已经运行的程序 run r 运行程序，当遇到断点后，程序会在断点处停止运行，等待用户输入下一步命令 continue c 继续执行，到下一个断点停止（或运行结束） next n 单步跟踪程序，当遇到函数调用时，也不进入此函数体 step s 单步调试如果有函数调用，则进入函数；与命令n不同，n是不进入调用的函数的 until u 当你厌倦了在一个循环体内单步跟踪时，这个命令可以运行程序直到退出循环 until+行号 运行至某行，不仅仅用来跳出循环 finish 运行程序，直到当前函数完成返回，并打印函数返回时的堆栈地址和返回值及参数值等信息 quit q 退出gdb up 上个stack down 下个stack watch 变量监控 breakpoint b file :line_num 文件:行号 \u0026lt;fun_name\u0026gt; 函数名字 run相当于重新启动程序, 但是由于某些原因(找不到库? 怀疑是变量不同), 容易导致程序启动失败 continue 相当于继续执行, 一般在接attach和gdb Server之后使用, 使程序继续执行 gud使用# buffer名字 简述 备注 gud gdb命令输入窗口 source 调试时自动显示源码 不要edit, 否则导致source自动关联失效 breakpoint 断点 不会命中的断点显示为pending threads 线程 stack 堆栈 local local变量 register 寄存器 assembler 显示汇编 memory 内存查看 为了显示方便, breakpoint与threads buffer同在一个frame; local与register buffer同在一个frame; 可以按\u0026quot;TAB\u0026quot;快速切换 例子# emacs: M-x gdb RET gud: attch \u0026lt;program pid\u0026gt; 设置breakpoint gud: b source: gud-break; gud-tbreak breakpoint: D 删除断点 设置watch gud: watch souce: gud-watch 问题# gud中在continue之后, 程序运行; 此时输入, gud并没有反应; 但是在程序运行到断点的时候, 之前的输入全部变成了命令. 简单来说, gud没有舍弃之前的无效输入, 而是等待机会, 使之生效 gdb continue之后 如何退出 gdb进程中可以使用C-c, 退出attach所关联的进程 emacs-gdb中如何退出 ?? TODONOW "},{"id":33,"href":"/blog/docs/prog_base/07_design_pattern/","title":"设计模式","section":"prog base","content":"design pattern 设计模式 简介# 推荐阅读 设计模式是一种经验总结, 是对软件设计中 常见问题 的 典型解决方案 常用设计模式# 大概可以分为 创建型模式, 结构性模式, 行为模式 创建型模式提供创建对象的机制, 增加已有代码的灵活性和可复用性 结构型模式介绍如何将对象和类组装成较大的结构, 并同时保持结构的灵活和高效 行为模式负责对象间的高效沟通和职责委派 创建型模式# 抽象工厂模式 "},{"id":34,"href":"/blog/docs/emacs/lisp/ai/","title":"AI","section":"常用扩展","content":"简述# 之前的IDE大多是基于语法的分析, AI代码助手提供了基于自然语义的分析. 效果非常的惊艳, 能更好的帮助编写文档与程序 当下流行的(2023-6)主要有: Github Copilot, Tabnine, Replit Ghostwriter, Amazon CodeWhisperer 和 Codeium 具体可以参考 测评文章 基于以下原因, 暂时使用了github copilot: 配置方便, emacs使用体验良好 github copilot# 使用# github copilot 没有emacs的官方插件, 使用的是第三方package copilot. 安装与配置均比较简单, 可以参考copilot官方文档 其中需要开通github copilot, 建议在某宝购买github学生包, 便宜又方便, 但是容易被封, 千万不要使用自己的github账号;;国内可能无法访问github copilot, 可以配置一下代理 (setq copilot-network-proxy \u0026#39;(:host \u0026#34;127.0.0.1\u0026#34; :port \u0026#34;10887\u0026#34;))快捷键配置# copilot 与company-mode的一些快捷键容易冲突, 可以参考init-local-shortkey.el 使用体验# github copilot自身还好, 但是github学生包账号非常容易被封, 略微影响使用体验 "},{"id":35,"href":"/blog/docs/emacs/org/org_for_hugo/","title":"org for hugo","section":"org","content":"org自带强大的export功能. 但更多的是使用ox-hugo导出hugo样式的md, 再使用hugo生成html. ox-hugo# ox-hugo 只是把org翻译为hugo样式的md. 其支持的功能也是有限的. 翻译之后的md在hugo和hugo theme的作用下转为html, 又损失了部分功能. 这里使用的hugo theme为hugo book. 可以通过此处查看orgmode转为html后, 各个功能的效果. TODO 待做. 预计展示功能为: 字体样式 ref, inline-ref picture shortcodes ox-hugo 图片导出逻辑# ox-hugo shortcodes 导出逻辑# markdown中的shortcode# 对于hugo和hugo theme的shortcode 就是mardown的 shortcode. 主要有下面2类: 单标签（self-closing shortcode) {{ \u0026lt; myshortcode \u0026gt; }} 成对标签（paired shortcode) 内容可被markdown解析器 解析 \u0026lt;details \u0026gt;\u0026lt;summary\u0026gt;\u0026lt;/summary\u0026gt;\u0026lt;div class=\u0026#34;markdown-inner\u0026#34;\u0026gt; ### 可被再解析 \u0026lt;/div\u0026gt;\u0026lt;/details\u0026gt; 内容不可被markdown解析器 解析 Tab1 Tab1 内容 Tab2 Tab2 内容 hugo 支持的shortcode# https://gohugo.io/content-management/shortcodes/#shortcodes-without-markdown 自身使用情况: shortcode 功能说明 使用情况 details 折叠内容块 hugo book已支持 figure 图片展示 org-mode自带 gist github gist 嵌入 hugo已废弃 highlight 代码高亮 org babel自带 instagram instagram嵌入 不使用 param 参数引用 没使用场景 qr 生成二维码 ref 链接引用 org-mode自带 relref 相对引用 org-mode自带 vimeo vimeo视频 X X链接 没使用场景 youtube YouTube链接 hugo book支持的代码块# 如果代码块同时被 hugo解析器 与 hugo book支持, 应该是hugo book的会覆盖hugo解析器效果https://hugo-book-demo.netlify.app/docs/shortcodes/buttons/ shortcode 功能说明 使用情况 badges 标签 适合文章开头增加标识 button 按钮 org-mode自带 card 卡片 org转md过于复杂 columns 列布局 details 折叠块 hints 提示框 images 图片 org-mode自带 mermaid 流程图 steps 步骤框 tabs 选项卡 katex 数学公式 org mode自带 org中的shortcode# org中的shortcode (在org中叫block). 主要有: 文字类型的. center, example, quote等 代码类型的. 由org babel提供支持 artist, c++, emacs-lisp, plantform等 html类型的. 可细分为 org-blackfriday-html5-inline-elements org-html-html5-elements ox-hugo的shortcode导出逻辑# org文字类型# #+begin_sh something #+end_sh # 翻译为: ```sh something ```org代码类型# org html类型# org-blackfriday-html5-inline-elements org-html-html5-elements #+begin_BLOCKTAG something #+end_BLOCKTAG # 翻译为: \u0026lt;BLOCKTAG\u0026gt; something \u0026lt;/BLOCKTAG\u0026gt; org 自定义类型# 这里的自定义是指, ox-hugo为了转为md中的shortcode. 而非org自身的block自定义. ox-hugo没有对单标签shortcode进行自定义处理. 导致对于单标签只能使用org-exprot hugo_paired_shortcodes: myshortcode. 转为markdown解析器不识别的 begin_myshortcode Something end_myshortcode # 翻译为: myshortcode Something /myshortcode# 省略key, 直接下value也是可以的 attr_shortcode: :arg1 foo bar :arg2 color: red; text-align: center; begin_myshortcode Something end_myshortcode # 翻译为: myshortcode arg1=\u0026#34;foo bar\u0026#34; arg2=\u0026#34;color: red; text-align: center;\u0026#34; Something /myshortcode hugo_paired_shortcodes: %myshortcode 转为markdown解析器识别的 单标签 begin_export hugo {{ \u0026lt; myshortcode \u0026gt; }} end_export "},{"id":36,"href":"/blog/docs/os/os/memory_01/","title":"memory 01","section":"os","content":"os中内存段页发展 参考文章# 强烈推荐: x86段寄存器和分段机制 cpu发展历史# x86(8086)之前 处理器4bits TODO 也许补充一下 \u0026lt;\u0026mdash;\u0026gt;x86 处理器变为16bits, 地址总线变为20根 为了能访问到所有的地址空间, 引入了 段寄存器 (CS,DS,SS,ES) \u0026lt;\u0026mdash;\u0026gt;32bits 处理器变为32bits, 地址总线变为32根 为了能访问到所有的地址空间, 同时又要兼容x86, 同时os越来越普遍 引入了 段描述表寄存器 (GDTR, LDTR) \u0026lt;\u0026mdash;\u0026gt;64bits 处理器变为64bits, 地址总线在40-48根 段寄存器# 根据发展史, 知道段寄存器的引入是为了解决 cpu bits \u0026lt; 地址总线 的问题 x86把物理内存分割成一段段的, 段寄存器记录段的高16bits, 剩下的4bits放在IP寄存器. 因此, 进程要访问的线性地址 = (段reigster \u0026lt;\u0026lt; 4) + IP偏移 段描述表寄存器# 32bits cpu时候, os越来越普遍(cpu 16bits时, os还不普及). 32bits cpu为了能完整的使用32地址总线, 同时也要满足os的各种需求(比如用户态, 内存态权限等), 需要对段进行详细的控制, 不仅仅是知道段基址. 在这种情形下, DTR (describe table register)被引入了. 进程在段register拿到index, 在DTR中找到index所在的内存地址(DTR只是表, describe info放在内存中). 去该内存地址中获取describe info. 这其中就包含了段基址 因此, 此时进程访问的线性地址 = [段基址] + IP偏移(这里IP寄存器出了32bits版 EIP) 此时根据硬件(EIP)发展进度, os对 段基址 使用不同的处理模式 有EIP的一般都会直接把 段基址 置为0. 因为不需要再对物理内存切段, 也可以完全访问了. 当出现64bit cpu时, 段基址 基本都被设置为了0. 线性地址 -\u0026gt; 物理地址# 在32bits cpu之前, 线性地址即是物理地址 32bits cpu出现后(或是os出现后?), 需要翻译线性地址与物理地址. 这个翻译动作是硬件MMU做的 为什么需要# 未考证, 不一定对 os中引入了进程, 不同进程的逻辑地址可能相同, 所以其线性地址也可能相同. 这将导致不同的进程访问了同一个物理内存地址. 而逻辑地址到线性地址是根据GDTR (global)获得的, 全局相同. 所以在线性地址到物理地址上做功夫 所以需要一个与进程关联的DTR(实际就是LDTR)来处理这个翻译动作. LDTR就是进程的段表. 线性地址(?待验证)在LDTR中找到describe info. 根据describe info 再找到物理内存即可. 但是这么处理, 对物理内存的利用率不高. 为了更好的利用物理内存, 使用分页. 分页# 分页就是把物理内存切割成一页一页的, 即方便管理, 也方便使用. 为了与物理内存的一页页内存对应, 进程中每个段也是一页页的使用内存. 所以LDTR中应该保存 进程段页 与 物理页 之间的映射关系(即页表) 所以进程中线性地址到物理地址, 除了查段表, 也要看页表 根据段表, 在内存中找到页表, 根据页表, 找到真实的物理页. 这个动作是由MMU做的 多级页表# 为了减少内存, 引入了多级页表. 缺点是导致内存查询次数增多. 每引入一层, 就需要额外查询一次内存 快表 TLB# 为了减少内存的查询次数, 引入的缓存表. 快表保存在寄存器中, 所以如果快表命中, 访问速度要比多级页表快很多 "},{"id":37,"href":"/blog/docs/os/os/","title":"os","section":"os","content":"待整理, 东西很多很杂 "},{"id":38,"href":"/blog/docs/prog_compile/gcc/","title":"gcc","section":"prog compile","content":"gcc gcc# 查看搜索路径 g++ | gcc -print-serach-dirs (可通过\u0026ndash;help查看) 头文件搜索路径 gcc C_INCLUDE_PATH g++ CPLUS_INCLUDE_PATH ep: export CPLUS_INCLUDE_PATH=/usr/lib/ 扩展1 输出 echo $C_INCLUDE_PATH 调用 $C_INCLUDE_PATH 赋值 export C_INCLUDE_PATH 删除变量 unset C_INCLUDE_PATH C++调用 string strValue(getenv(\u0026ldquo;C_INCLUDE_PATH\u0026rdquo;) 库文件搜索路径 LIBRARY_PATH gcc编译时候需要 LD_LIBRARY_PATH 程序运行时候需要 g++ 编译参数 -rdynamic 与 -g# 总览# g++ 编译的支持. -g可以增加调试信息(实际增加的为行号和函数符号等) g++ 编译的支持. -rdynamic. 增加符号信息(只有符号信息) g++ 中的-DDEBUG和-DNDEBUG只是增加了宏定义, 并不表示releas和debug版本. 实际的优化还是-O0 -O3 g++ 实际没有release和debug. -g是增加调试信息, -O3是程序编译优化, -DDEBUG是宏定义如果加了-rdynamic, 不增加-g# 那么崩溃信息中, 崩溃地址 会使用符号名称+偏移地址 E20220104 18:16:43.152771 1127 qysignal.cpp:38] ./qy_gate(main+0x235) [0x408c33]可以看到是main函数崩溃的, 具体位置在main函数偏移0x235, 即0x408c33 所以需要先计算main函数的位置, 然后加上+0x235 nm qy_gate |grep main 得到main的位置 假设偏移后的位置为0x1213, 那么通过下面的命令查看具体信息 addr2line -e qy_gate 0x1213 -sfC 实际上[0x408c33]中既是偏移后的地址, 不需要手动计算会发现, 显示的信息为 main ??? : ????:? 是因为缺少调试信息,即g++编译时候无-g 如果不加-rdynamic# 日志会直接显示地址, 而不是符号+偏移地址 E20220104 18:16:43.152771 1127 qysignal.cpp:38] ./qy_gate(0x235) [0x408c33] 如果加-g# 通过addr2line -e qy_gate 0x1213 -sfC可以显示出具体的行号 main main.cpp : 12 总结# 建议去掉-rdynamic, 增加-g 指定静态库# -static 所有的-l都指定静态库, 找不到则报错 -Bstatic 对跟在后面的所有库执行静态链接 -l:\u0026lt;filename\u0026gt; -l:libmylib.a 只针对于-l的参数 "},{"id":39,"href":"/blog/docs/emacs/org/org_for_hugo_demo/","title":"org for hugo demo","section":"org","content":"org mode content到hugo book theme的演示. 根据orgmode官方文档的顺序进行演示 Document Structure# Headlines# Third level# some text Third level 1 Third level 2 Plain Lists# Unordered list# start with \u0026ldquo;-\u0026rdquo; one two three start with \u0026ldquo;+\u0026rdquo; 1111 2222 3333 Ordered list# start with \u0026ldquo;.\u0026rdquo; one two three start with \u0026ldquo;)\u0026rdquo; 1111 2222 3333 Description list (Unordered list)# Elijah Wood He plays Frodo Sean Astin He plays Sam, Frodo\u0026rsquo;s friend Drawers# outside the drawer inside the drawer after the drawer Block# org 中的block 即是 md中的shortcodes.参考shortcode Tables# Normale# key value desc a 1 a = 1 b 2 c d abdc Column Width and Alignment# 1 one some 2 two boring 3 this is a long text column Column Groups# | N || N^2 | N^3 | N^4 || sqrt(n) | sqrt4 | |\u0026mdash;|\u0026mdash;\u0026ndash;|\u0026mdash;\u0026ndash;|\u0026mdash;\u0026ndash;|\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;| | 1 || 1 | 1 | 1 || 1 | 1 | | 2 || 4 | 8 | 16 || 1.4142136 | 1.1892071 | | 3 || 9 | 27 | 81 || 1.7320508 | 1.3160740 |\nHyperlinks# Link Format# with description link with description without description https://orgmode.org/manual/Link-Format.html Internal Links# \u0026ldquo;\\[\\[#FirstLink\\]\\]\u0026rdquo; Entry with \u0026ldquo;CUSTOM_ID\u0026rdquo; \u0026ldquo;\\[\\[*FirstLink\\]\\]\u0026rdquo; FirstLink \u0026ldquo;\\[\\[FirstLink\\]\\]\u0026rdquo; \u0026ldquo;\\[\\[SecondLink\\]\\]\u0026rdquo; [[#target]] 只会找 Entry with CUSTOM_ID为target [[*target]] 只会找 Headline name为target [[target]] 优先找 entry with \u0026lt;\u0026lt;target\u0026gt;\u0026gt;; 其次Name为targetEntry with \u0026ldquo;CUSTOM_ID\u0026rdquo;# FirstLink# List has \\\u0026lt;\\\u0026lt;FirstLink\\\u0026gt;\\\u0026gt;# one two Table has Name \\\u0026lt;\\\u0026lt;FirstLink\\\u0026gt;\\\u0026gt; \\\u0026lt;\\\u0026lt;SecondLink\\\u0026gt;\\\u0026gt;# a b b b cc c External Links# file# 搜索文件. file: org_for_hugo_demo_link_file.txt \u0026lt;org_for_hugo_demo_link_file.txt\u0026gt; 搜索文件的第20行. file: org_for_hugo.org::20 TODO: not work 搜傅文件中的 ox-hugo Headline. file: org_for_hugo.org::*ox-hugo /blog/docs/emacs/org/org_for_hugo/#ox-hugo 搜傅文件中的ox-hugo. file: org_for_hugo.org::ox-hugo /blog/docs/emacs/org/org_for_hugo/#ox-hugo http, https# link to https://orgmode.org https://orgmode.org/ id (link to org file by ID property)# search org file for Headline has ID property \u0026ldquo;ox-hugo\u0026rdquo; org_for_hugo.md \\TODO Items# TODO Headline has TODO# TODO TODO dependencies# DONE one# TODO two# Priorities# TODO Write letter to Wen# TODO Write letter to Mom# Breaking Down Tasks into Subtasks# TODO Call people [1/2]# TODO XiaoMing DONE XiaoBai TODO Checkboxes [1/3]# [-] call people [1/3] XiaoMing XiaoBai Sam order food think about what music to play Tags# With Tag \u0026ldquo;work\u0026rdquo; work# With Tag \u0026ldquo;home\u0026rdquo; home# Dates and Times# Timestamps# active timestamp \u0026lt;2025-09-10 Wed 10:00\u0026gt; inactive timestamp [2025-09-10 Wed 10:00] time range [2025-09-10 Wed 10:00-12:00] time/date range [2025-09-10 Wed]–[2025-09-13 Sat] [2025-09-10 Wed 10:00]–[2025-09-13 Sat 09:00] Deadlines and Scheduling# TODO Deadlines# TODO Scheduling# Markup for Rich Contents# Paragraphs# this is center balabala * this is examples ** this balabala this is quote Emphasis and Monospace# key format format2 normal 普通 /* bold 粗体 // italics 斜体 = monospace 代码 ~ key-binding 等宽 + strike-through 删除线 /_ underline 下划线 Subscripts and Superscripts# subscripts: 10^8 superscipts: Rsun Embedded LaTex# Literal Examples# 1 2 3 (message \u0026#34;H1\u0026#34;) (message \u0026#34;H2\u0026#34;) (message \u0026#34;H3\u0026#34;) Images# link to an image without description part link to an image with description Horizontal Rules# up aaaaaaaaaaaa down bbbbbbbbbbb Creating Footnotes# 一个脚注1 匿名脚注2 inline footnote3 Shortcodes in Hugo and Hugo book# Hugo# qr# vimeo# youtube# Hugo book# badge# this is badge11 columns# a title aaaaaaaaaaaaa content b title bbbbbbbbbbb content c title cccccccccccccccccc content this is columns abcoulomb sfsdf sadfdsf details# this_is_details this is details s dsfadsfs hint# this is hint steps# this is step one step two step three step tabs# a aaaaaaaa content b bbbbb content c c ccccccccccc sf content A footnote is started by a footnote marker in square brackets in column 0, no indentation allowed. It ends at the next footnote definition, headline, or after two consecutive empty lines. \u0026#160;\u0026#x21a9;\u0026#xfe0e;\nthis is the inline definition of this footnote\u0026#160;\u0026#x21a9;\u0026#xfe0e;\na definition\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":40,"href":"/blog/docs/tool/redis/","title":"redis","section":"tools","content":"redis学习记录 基础# 数据结构# 二进制安全字符串 (key, value) 列表 (链表实现) 集合 排序集合 哈希 位数组(简单的位图) HyperLogLogs 概率数据结构 Streams 键值注意事项# 键一般不要太大, 但又不要太短, 导致不可阅读. 需要平衡 值不能大于512MB 常用的指令# 通用命令# exist 返回1表示存在, 0表示不存在 del 删除 type 返回key对应值的类型, 不存在值, 则为none expire 设置过期时间(秒). key对应的过期时间也会被保存在磁盘上 或者set key 100 ex 10 -- 使用ex来简化expirepersist 删除key的过期时间, 并永久化 字符串# get set getset 将键设置为新值, 并返回旧值为结果 链表相关# 索引从0开始lpush (key v) 在链表的左侧(头部)添加元素 \u0026ndash; 常数时间 rpush (key v) 在链表的右侧(尾部)添加元素 \u0026ndash; 常数时间 可以一次推送多个数据. 返回结果为当前链表中的元素个数lrange (key arg1 arg2) 从链表中提取元素范围 \u0026ndash; 需要的时间与元素数量正比, 非常慢 参数可以为负数表示. -1表示最后一个元素, -2表示倒数第二个lpop (key) rpop (key) 返回结果为左侧或右侧的元素ltrim (key arg1 arg2) 只保留范围内的元素, 删除链表其他元素 llen (key) 链表的长度 Hash# hmset hmget 检索多个字段(可单, 可全部) hget 检索单个字段 hgetall 检索所有字段 hincrby 可以对单个字段的val执行加操作 Set# sadd 添加新的元素 smembers 返回集合中的元素(未排序的, redis随意返回) sismember (Set key) 检测key是否是Set的成员. 返回1是,0不是 spop (key option\u0026amp; count) 删除count个随机的元素, 并返回给客户端 scard 返回集合中的元素个数 Sorted Set# 现根据score排序, score一致则根据key的字典值排序 zadd (ZSet key score val) 添加新的元素. 多了一个score的写入 zrange (ZSet index_b index_e option\u0026amp; withscores) 返回范围内的元素(正序的) zrevrange (ZSet index_b index_E option\u0026amp; withscores) 返回范围内的元素(倒序的) 额外参数withscores会输出元素的scorezrangebyscore (ZSet -inf score_val) 返回有序集合中的score \u0026lt;= score_val的元素 zremrangebyscore (ZSet score_b zsocre_e) 删除集合中所有score在b,e之间的元素 zrank (ZSet key) 返回元素在正序集合中的index zrevrank (ZSet key) 返回元素在倒叙集合中的index "},{"id":41,"href":"/blog/docs/tool/sql/","title":"数据库","section":"tools","content":"数据库开发 数据库开发# win下# 详细解释 原生接口 ODBC OLE ADO linux下# 原生接口 ODBC sqlserver# 优缺点# Docker安装sqlserver# 官方文档 搜索镜像 docker search mssql 安装镜像(这个是官网的) docker pull microsoft/mssql-server-linux 运行镜像, 创建容器 docker run -e \u0026ldquo;ACCEPT_EULA=Y\u0026rdquo; -e \u0026ldquo;SA_PASSWORD=hack@2020\u0026rdquo; -p 9988:1433 \u0026ndash;name mssql -d microsoft/mssql-server-linux 注: 如果不指定映射的端口, 则可能随机使用一个端口 密码必须8位数, 否则会创建失败 -p 第一个参数为主机端口, 第二参数为docker容器端口 进入容器 docker exec -it mssql bash 测试sql server命令 /opt/mssql-tools/bin/sqlcmd -S localhost -U SA -P \u0026ldquo;passwd\u0026rdquo; 如果启动失败 docker logs mssql 查看日志信息 sqlcmd用法# 登录 /opt/mssql-tools/bin/sqlcmd -S 127.0.0.1 -U SA -P \u0026#34;hack@2020\u0026#34; 执行语句查询 select * from sys.databeses go一定记得使用go unicode支持# 排序规则会影响字符集 服务器 排序规则 数据库 排序规则 表中的字段 排序规则 排序规则会影响字符集, 比如排序规则为xx_UTF8, 那么其默认的字符集为unicode nchar nvarchar类型会无视排序规则, 直接把改字段变为unicode编码 使用的时候 记得加N, exp: N\u0026#39;排序规则\u0026#39; client 与 server# 最理想的状态 server 是 unicode编码(只要nchar, nvarchar即可) client 是 unicode编码 unixodbc 编译的时候, 添加了 utf8的支持 ./configure --enable-iconv=yes --with-iconv-char-enc=UTF-8 总结: 数据库表字段的编码, 服务器程序运行环境的编码, unixodbc编译时候的字符编码 三者需要统一, 这样写入数据库的时候 才不会乱码 服务器运行环境 locale可以查看 locale -a显示系统支持的字符集遇到的奇怪的问题 \u0026amp;\u0026amp; 解决思路# 简述: 通过odbc 操作sqlserver, 插入中文错误 现象: 读取sqlserver中文正常 插入sqlserver中文乱码 思路: 查看sqlserver 的编码集(排序规则) 查看qy-server的运行环境 locale 编译unixodbc的时候是否加入了编码的支持 查看odbc的配置文件 odbcinst -j 这次的问题在于 odb的配置文件中 有重名的DSN mysql# 优点: 缺点: 没有存储过程 ODBC# 安装odbc驱动 建议使用官方源码安装 http://www.unixodbc.org下载源码之后 ./configure --enable-gui=no --enable-iconv=yes --with-iconv-char-enc=UTF-8 ./configure --enable-gui=no --enable-iconv=yes --with-iconv-char-enc=GB18030 这里需要添加中文支持, 不然会发生数据库读取中文正常, 写入中文时候乱码 安装对应的sql的驱动 这里sql的驱动是 odbc下的sql驱动以mssql为例. 在microsoft官网下载 查看sql的驱动信息 debin在 /usr/local/etc/odbcinst.ini[ODBC Driver 17 for SQL Server] Description=Microsoft ODBC Driver 17 for SQL Server Driver=/opt/microsoft/msodbcsql17/lib64/libmsodbcsql-17.6.so.1.1 UsageCount=1说明sql的驱动安装成功 编写DSN debin在 /usr/local/etc/odbc.ini[MssqlDB] Driver = ODBC Driver 17 for SQL Server Server = tcp:172.16.238.10,1433 测试安装 # 查看odbc是否已经安装 odbcinst -j # 查看驱动是否安装 odbcinst.ini odbcinst -q -d # 查看源是否安装 odbc.init odbcinst -q -s 测试连接 上面安装测试完成之后, 测试连接 isql MssqlDB user_name user_passwd -v 如果连接成功 +---------------------------------------+ | Connected! | | | | sql-statement | | help [tablename] | | quit | | | +---------------------------------------+连接失败的可能分析 先确认安装测试的3个命令执行正常 确认数据库的密码是否正确 在数据库的容器中查看$SA_PASSWORD, 与本地的密码比较 常用数据库语句# sql server 查询sql版本 select @@version go 查询支持的字符集 只有2019版本 才支付utf-8字符集select * from ::fn_helpcollations() go查询当前系统的排序规则 SELECT SERVERPROPERTY(\u0026#39;Collation\u0026#39;)查询排序规则的字符集 SELECT COLLATIONPROPERTY(\u0026#39;Chinese_PRC_Stroke_CI_AI_KS_WS\u0026#39;, \u0026#39;CodePage\u0026#39;)936 简体中文GBK 950 繁体中文BIG5 437 美国/加拿大英语 932 日文 949 韩文 866 俄文 65001 unicode UFT-8 查询所有的库 select * from sys.databeses order by name go有时候显示的数据太多, 我们可以只显示需要的比如 select name from sys.databeses order by name go 查询当前数据库所有表 方法一 select * from sys.objects where type=\u0026#39;U\u0026#39; go\u0026ndash;XType=\u0026lsquo;U\u0026rsquo;:表示所有用户表; \u0026ndash;XType=\u0026lsquo;S\u0026rsquo;:表示所有系统表; 方法二 select * from sys.tables go 查询表中所有的字段 SELECT * FROM SysColumns WHERE id=Object_Id(\u0026lsquo;TableName\u0026rsquo;); SELECT COLLATIONPROPERTY(\u0026lsquo;Chinese_PRC_CS_AS_WS\u0026rsquo;, \u0026lsquo;CodePage\u0026rsquo;) SELECT COLLATIONPROPERTY(\u0026lsquo;Chinese_PRC_90_CI_AS_SC_UTF8\u0026rsquo;, \u0026lsquo;CodePage\u0026rsquo;) SELECT COLLATIONPROPERTY(\u0026lsquo;Latin1_General_100_CI_AI_SC_UTF8\u0026rsquo;, \u0026lsquo;CodePage\u0026rsquo;) SELECT COLLATIONPROPERTY(\u0026lsquo;SQL_Latin1_General_CP1_CI_AS\u0026rsquo;, \u0026lsquo;CodePage\u0026rsquo;) SELECT COLLATIONPROPERTY(\u0026lsquo;Chinese_Simplified_Stroke_Order_100_CI_AI\u0026rsquo;, \u0026lsquo;CodePage\u0026rsquo;) "},{"id":42,"href":"/blog/docs/os/os/dll/","title":"library","section":"os","content":"linux下静态库 \u0026amp;\u0026amp; 动态库 差异区别# 静态库 动态库 format .a .so 编译连接 copy静态库到目标文件 no copy 运行 不再访问原静态库 需要访问动态库 生成方式 1. 源文件生成一系列.o, 每个.o都包含编译单元的符号表 1. gcc -fPIC file1.c -c 生成file1.o 2. ar指令把.os转为.a 2. gcc -shared file1.o -o libt.so Q % A# 运行时候找不到动态库 mov .so to /usr/lib或/lib. 不推荐 export LD_LIBRARY_PATH=/path/to/.so 在/etc/ld.so.conf文件里加入我们生成的库的目录，然后ldconfig 加载动态库 函数原型：void *dlopen(const char *libname,int flag); 参数中的libname一般是库的全路径，这样dlopen会直接装载该文件 如果只是指定了库名称，在dlopen在查找库的过程中会按照如下路径进行搜索： 根据环境变量LD_LIBRARY_PATH查找 根据/etc/ld.so.cache查找 查找依次在/lib和/usr/lib目录查找。 flag参数表示处理未定义函数的方式，可以使用RTLD_LAZY或RTLD_NOW RTLD_LAZY表示暂时不去处理未定义函数，先把库装载到内存，等用到没定义的函数再说； RTLD_NOW表示马上检查是否存在未定义的函数，若存在，则dlopen以失败告终。 动态库再认知# 结论# 动态库允许延迟定义, 但是在连接为可执行文件时, 所有动态库的声明必须有定义 测试# A 依赖libbase.so, B依赖libA A编译的时候, 不指定libbase.so(但是要include base的头文件), 可以编译成功. 表示满足延迟定义 B -lA 编译, 编译成功, 连接失败, 提示libA没有xxx的定义(在libbase中) 若B -lA -lbase, 则编译连接都成功 连接为执行文件的时候, 所有的声明都必须要有定义 而且这个定义可以是在A中-lbase, 也可以是在B中 -lbase 说明-lbase只是告之符合连接表而已 "},{"id":43,"href":"/blog/docs/tool/protocol/","title":"乱七八糟的协议合集","section":"tools","content":"协议太多, 不好分类, 真是乱七八糟 简单协议# 字符编码# 写入内存过程: 符号 \u0026ndash;\u0026gt; 根据符号表(编码表), 找到符号的value \u0026ndash;\u0026gt; 根据实现算法(utf-8等), 计算出在内存中的值 \u0026ndash;\u0026gt; 内存值 解析过程: 内存值 \u0026ndash;\u0026gt; 根据算法, 计算出符号的value \u0026ndash;\u0026gt; 根据符号表, 找到value对应的符号 \u0026ndash;\u0026gt; 符号 编码小知识# ios-8859-1 为http上所使用的编码 我在gitlab上面下载的代码虽然最原始是GBK编码（win下）， 下载到mac后 通过file -I 会被识别为iso-8859-1, 就是因为是http协议下载的。 所以转换为mac下可以使用的时候，做法应该是： iconv -f GBK -t UTF-8 file \u0026gt; file2 ASCII \u0026amp;\u0026amp; Unicode# 由来 ASCII码 \u0026ndash; 保存英文以及一些特殊控制字符 byte即2^8=256个符号 Unicode \u0026ndash; 1. ASCII符号表只能有256个符号, 不够其他国家使用, 比如汉字有10W+ 各个国家符号表(key)对应的value不同, 导致web通信困难(乱码), 为了统一, unicode出现 Unicode \u0026amp;\u0026amp; utf-8# Unicod只是符号表, 其内部类似于这样 符号 Value 严 4E25 即我们的汉字\u0026quot;严\u0026quot; 对应的Unicode Value就是 4E25 但Unicode只是规定了符号表的map(key, value), 并没有规定value在内存中的存储形式, 比如little endian中\u0026quot;严\u0026quot;是25 4E 第一个字节为25, 第二个字节为4E 而 big endian中则是 4E 25 除了大小字节序问题, 4E 25的如何实现也有非常多的方法 常见的有utf-8 utf-16等等 所以utf-8只是实现Unicode的一种方式 比较重要的一点是, 为了兼容ASCII, ASCII对应的符号value, 在ASCII与utf-8中一致(即英文与控制符号一致) ASCII \u0026amp;\u0026amp; Unicode转换# 这个转换确实纠结了我很久 转换的复杂性在于 字节长度问题 ASCII码的value是一个BYTE, 其value在内存中的实现也是一个byte Unicode的value是二个byte, 其Value在内存中的实现(utf-8)有1-5个byte 字节长度不同, 导致我们需要在char* 和 wchar_t*间转换 编码格式 注: 其实1应该也属于编码格式 因为ASCII 和 Unicode(自身)之间的实现方式差异很大, 在其中转换的时候要非常熟悉各种编码实现的原理 为了解决2个问题, 可以考虑一下2个函数, 虽然是windows下的: MultiByteToWideChar和WideCharToMultiByte 大小字节序# 对于多字节, 比如 AE FF Big—Endian 大字节 如果在内存中 0x 0000 0001 AE 0x 0000 0002 FF 即内存中的低位保存的是高字节 则为Big-Endian little-Endian 小字节 如果在内存中 0x 0000 0001 FF 0x 0000 0002 AE 即内存中的低位保存的是低字节 则为little-Endian 网络上的传输为大字节序 所以在host传入到internet时候, 比如socket, 应该将字节序转换 ip地址详解# 主机host的数量 决定了 选择 A类 B类 或者C类地址 hosts的划分, 即子网 决定了 掩码的值 掩码的值 决定了 ip地址的网络id 与 主机id A类的掩码 为 255.0.0.0 B类的掩码 为 255.255.0.0 C类的掩码 为 255.255.255.0 通过A类掩码 计算出 所能承载的host数量n, 按ip从0.0.0.0开始, 数到host数量n, 计算出A类ip地址范围 通过B类掩码 计算出 所能承载的host数量m 按A类广播地址+1开始, 数到m, 计算出B类ip地址范围 通过C类掩码 计算出 所能承载的host数量x 按B类广播地址+1开始, 数到x, 计算出C类ip地址范围 子网的第一个ip地址 和最后一个ip地址有特殊含义 第一个ip地址为 本机地址?????? 最后一个ip地址为广播地址 这2个地址 被设计用来做其他事情, 设计的时候不应该考虑吧进去 "},{"id":44,"href":"/blog/docs/prog_base/99_algorithm/","title":"数据结构","section":"prog base","content":"概述|总结# 什么是# 数据结构分为 物理结构 即在内存中的结构. 有顺序存储(内存连续) 和 链式存储(内存可不连续) 逻辑结构 线性关系, 一对一, 一对多, 多对多 逻辑结构# 线性关系# 数组, 链表 栈, 队列 一对一# hash table 一对多# tree 树 binary tree 二叉树 search binary tree 搜索二叉树 blance binary tree 平衡二叉树 complet binary tree 完全二叉树 堆 name 特征 备注 tree binary tree 1.任意节点 叶度 \u0026lt;=2 search bianry tree 1.binary tree 2.任意节点 left-child, root, right-child有序 blanced binary tree 1.search binary tree 2.任意节点的 \u0026lt;左树高度-右树高度\u0026gt; \u0026lt;=1 complet binary tree 1.search tree 2.节点依次从左到右 多对多# graph 图 数据结构# type type Access 查找 增加,删除 适用场景 c++类型 array 1.数组 O(1) O(n) O(n) 数据访问 std::array 2.动态数组 std::vector linked-list 1.单链表 O(n) O(n) O(1) 数据增删, 查找较少 std::list 2.双链表 3.循环链表 skip list O(n),Θ(logN) O(n),Θ(logN) O(n),Θ(logN) 介于array与linked list中间 stack O(n) O(n) O(1) LIFO 数据增删 std::stack queue 1.队列 O(n) O(n) O(1) FIFO 数据增删 std::queue 2.双端队列 std::deque 3.优先队列 hash N/A O(1) O(1) 数据查找 std::unordered_map tree 1.二叉查找树 O(n),Θ(logN) O(n),Θ(logN) O(n),Θ(logN) std::set std::map 2.平衡二叉树 3.红黑树 O(logN),Θ(logN) O(logN),Θ(logN) O(logN),Θ(logN) heap 1.最大堆 2.最小堆 graph trie "},{"id":45,"href":"/blog/docs/prog_base/91_algorithm/","title":"算法分析","section":"prog base","content":"搜索算法# 线性查找: 遍历. 线性查找可以进化为哈希查找来降低时间复杂度 二分查找: 数组, 有序 log(n) 哈希查找: 借助额外的hash table 排序算法# name 定义 T(n) θ T(n) O S(n) 稳定性 适用场景 适用结构 备注 bubble sort 循环n次 θ(n^2) O(n^2) O(1) yes 数据较少 1.数组 循环结束判定: 每第i次循环, 集合[0-i]中相邻元素按序交换 基本有序 2.链表 1.循环了size-1次 每第i次循环, 可确定n-i位置上的元素 2.上次循环中没有发生元素交换 就表示是已序的了 排序只用到指针 \u0026amp;\u0026amp; flag, 原地排序, 因此空间复杂度为O(1) 元素交换O(n^2) selection sort 循环n次 θ(n^2) O(n^2) O(1) no 数据较少 1.数组 元素交换O(n) 每第i次循环, 选择集合[i, n]中最小的元素,放在i位置 2.链表 每第i次循环, 可确定i位置上的元素 insertion sort 循环n次 θ(n^2) O(n^2) O(1) yes 元素交换O(n^2) 每第i次循环, 将i位置的元素放到集合[0-i]的有序位置 quick sort shell sort 循环gap()拆分数组, 对拆分后的数组们进行插入排序 Hibbard: θ(n^3/2) O(n^5/4) O(1) no 拆分后的数组们进行排序时没必要sort完A后再sort B, C Sedgewick: θ(n^7/6) O(n^4/3) 可以A, B, C的sort在同一个for循环进行 T(n)与gap的选择有关 merge sort 分而治之 θ(nlogN) O(nlogN) O(n) yes 递归 与 非递归两种实现 分: 分为有序集合A, B 治: 有序集合A, B =\u0026gt; C heap sort 循环n次 θ(nlogN) O(nlogN) O(1) no selection sort的优化版 每第i次循环, 最大堆root元素放到n-i位置 bucket sort counting sort radix sort "},{"id":46,"href":"/blog/docs/prog_base/95_solution_strategy/","title":"解题思路","section":"prog base","content":"解题思路# 分治 \u0026ndash; 有序数组 回溯 动态规划 \u0026ndash; 最优解 贪心 \u0026ndash; 最优解 *滑动窗口 TODO 滑动窗口# 整数反转# 获得反转后的数字 获得数字低位 - 高位 123 % 10 = 3; 123 / 10 = 12 12 % 10 = 2; 12/ 10 = 1 1 % 10 = 1; 1 / 10 = 0 可以看出终止条件为 x = 0 获得符号 \u0026gt; 0 ? + : - 范围判断 拿到反转后的数字之后, 就是判断范围 3*100 + 2*10 + 1 结果是否在[-2^31, 2^31 -1] 中 思路有了, 存储的结构体选择. 使用int[32] 即可. 但会导致浪费空间, 直接使用vector\u0026lt;int\u0026gt; 有必要获得符号吗? 获取反转后的数字的话, 没必要使用符号 -1 + -2*10 + -3*100 = -321 判断结果是否在[-2^31, 2^31-1] 之前如果是正的, 则判断max - 完后的结果是否 \u0026gt; 0 正 - 正: \u0026gt; 0,表示在里面 负 - 负 -20 - (-1) = -19 还在区间 -20 - (-30) = 10 不在区间了 看下来好像还是需要获取正负符号 遇到的新问题, vec[i] * dig 之后在int 中放不下了, 导致无法与INT_MAX 或 INT_MIN 进行比较 刚刚看了一下, 之前的提交记录, 真的是wtf 改进: 没必要使用vecor\u0026lt;int\u0026gt;进行存储, 因为每次循环中, 都可以继续累加 总结一下, 为什么思路差异这么大? 第一眼是想先获取反转后的数字, 再去进行范围比较 而实际上可以再获取的时候, 顺便进行比较 "},{"id":47,"href":"/blog/posts/rup/","title":"rup架构图","section":"Posts","content":"RUP4+1架构图 临时记录# 参考文章01 参考文章02 logic view# 逻辑视图. 逻辑视图关注功能. 在uml中由类图来表示 用户可见的功能 为实现用户功能而必须提供的\u0026quot;辅助功能模块\u0026quot; 它们可能是逻辑层、功能模块等 deployment view# 物理视图. 开发出的软件最终如何运行在物理或软件环境上. 在uml中通常使用部署图表示 \u0026ldquo;目标程序及其依赖的运行库和系统软件\u0026quot;最终如何安装或部署到物理机器 如何部署机器和网络来配合软件系统的可靠性、可伸缩性等要求 物理视图和处理视图的关系：\nprocess view特别关注目标程序的动态执行情况; 而deployment view重视目标程序的静态位置问题；deployment view是综合考虑软件系统和整个IT系统相互影响的架构视图。 implementation view# 开发视图. 关注软件开发环境下实际模块的组织, 反映系统开发实施过程. 在uml通常使用 ???TODO??? 表示. 关注程序包，不仅包括要编写的源程序，还包括可以直接使用的第三方SDK和现成框架、类库 以及开发的系统将运行于其上的系统软件或中间件 开发视图和逻辑视图之间可能存在一定的映射关系：比如逻辑层一般会映射到多个程序包等.\n一个设计良好的开发视图，应该能够满足以下要求：\n通过逻辑架构元素，能够找到它所有代码和所有的二进制交付件 每一个代码源文件，都能够找到它所属的逻辑架构元素 每一个二进制交付件，都能够找到它集成了哪些逻辑架构元素 process view# 处理视图. 在uml通常用时序图和流程图表示 关注进程、线程、对象等运行时概念 并发、同步、通信等问题 处理视图和开发视图的关系：\n开发视图一般偏重程序包在编译时期的静态依赖关系;\n而这些程序运行起来之后会表现为对象、线程、进程，处理视图比较关注的正是这些运行时单元的交互问题. use case viw# 场景视图，即4+1中的1.\n从前面的图可以看到，4+1中的4个视图都是围绕着场景视图为核心的. 它用于描述系统的参与者与功能用例间的关系，反映系统的最终需求和交互设计.\n在UML中通常由用例图表示 "},{"id":48,"href":"/blog/posts/readme/","title":"Readme","section":"Posts","content":"目录说明# path desc org blog org源码 static hugo静态文件 config.toml hugo配置文件 流程# push触发github action 下载 clay9/emacs.git 执行init-for-script.el, export org to md 执行hugo的编译, export md to html 执行hugo的发布 "}]