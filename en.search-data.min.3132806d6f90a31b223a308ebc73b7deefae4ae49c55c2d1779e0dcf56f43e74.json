[{"id":0,"href":"/docs/os/linux/","title":"linux","section":"os","content":"linux常用命令\u0026amp;\u0026amp;工具 查看系统信息 # desc key linux发行版信息 cat /etc/issue kernel信息 cat /proc/version uname -a debian系已安装的包 apt list \u0026ndash;installed cpu fd socket ss(socket statistics) 查看库的封装信息 readelf, nm, objdump linux发行版信息 cat /etc/issue kernel信息 cat /proc/version uname -a debian系 已安装的包 apt list \u0026ndash;installed cpu 详细命令 ... 总核数 = 物理CPU个数 X 每颗物理CPU的核数 \u0026lt;br/\u0026gt; 总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数 \u0026lt;br/\u0026gt; 查看物理CPU个数 \u0026lt;br/\u0026gt; cat /proc/cpuinfo| grep \u0026quot;physical id\u0026quot;| sort| uniq| wc -l \u0026lt;br/\u0026gt; 查看每个物理CPU中core的个数(即核数) \u0026lt;br/\u0026gt; cat /proc/cpuinfo| grep \u0026quot;cpu cores\u0026quot;| uniq \u0026lt;br/\u0026gt; 查看逻辑CPU的个数 \u0026lt;br/\u0026gt; cat /proc/cpuinfo| grep \u0026quot;processor\u0026quot;| wc -l \u0026lt;br/\u0026gt; 查看CPU信息（型号） \u0026lt;br/\u0026gt; cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c \u0026lt;br/\u0026gt; fd 查询命令 ... 所有进程允许打开的最大fd数量 : /proc/sys/fs/file-max \u0026lt;br/\u0026gt; 所有进程已经打开的fd数量及允许的最大数量 : /proc/sys/fs/file-nr \u0026lt;br/\u0026gt; 单个进程允许打开的最大fd数量 : ulimit -n \u0026lt;br/\u0026gt; 单个进程(例如pid为5454)已打开的fd : ls -l _proc/5454/fd_ \u0026lt;br/\u0026gt; 设置命令 ... ulimit -n xx \u0026lt;br/\u0026gt; echo '\\* soft nofile 1048576' \u0026amp;gt;\u0026amp;gt; /etc/security/limits.conf \u0026lt;br/\u0026gt; echo '\\* hard nofile 1048576' \u0026amp;gt;\u0026amp;gt; /etc/security/limits.conf \u0026lt;br/\u0026gt; sysctl -w fs.nr_open=xxx \u0026lt;br/\u0026gt; socket ss(socket statistics) 查看库的封装信息 readelf, nm, objdump 必备命令(软件) # top # top输出解释 ... top - 12:19:58 up 3:45, 1 user, load average: 0.00, 0.02, 0.05 Tasks: 27 total, 1 running, 26 sleeping, 0 stopped, 0 zombie %Cpu(s): 1.5 us, 1.1 sy, 0.0 ni, 97.2 id, 0.0 wa, 0.0 hi, 0.2 si, 0.0 st MiB Mem : 64348.3 total, 39305.2 free, 11285.5 used, 13757.6 buff/cache MiB Swap: 8192.0 total, 8192.0 free, 0.0 used. 52690.6 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 122 root 20 0 12936 7148 6648 S 1.0 0.0 2:32.20 cli 69 root 20 0 12928 7064 6572 S 0.7 0.0 2:07.64 svr top快捷键 ... 排序 \u0026lt; :: 左移sort-field; 进入top时候默认sort-field是%cpu \u0026gt; :: 右移sort-field R :: 反转排序 M :: (不推荐)根据%mem 排序 P :: (不推荐)根据%cpu 排序 T :: (不推荐)根据TIME+排序 高亮 b :: 是否高亮显示 \u0026lt;R进程 或者 sort-field\u0026gt;, 总开关 x :: 是否高亮 sort-field y :: 是否高亮 R进程 z :: (不推荐)高亮显示 B :: (不推荐)加粗 其他 1 :: 显示所有逻辑cpu k :: 关闭特定pid进程 s :: 设置刷新时间 内存 m :: 切换mem显示, 显示使用百分比\u0026amp;\u0026amp;总内存 ::\u0026gt; (*used/total)% / total t :: 切换cpu显示, 没看明白; 仍然推荐看%Cpu-\u0026gt;id 或者1查看所有核心的 free # 输出说明 ... total used free shared buff/cache available Mem: 62Gi 11Gi 38Gi 17Mi 13Gi 51Gi Swap: 8.0Gi 0B 8.0Gi ss # 查看socket 统计信息 这是system的统计信息, docker容器内外是一致的 输出说明 ... Every 100.0s: ss -s 851d60ae4404: Wed Oct 20 17:44:33 2021 Total: 3 TCP: 2101 (estab 0, closed 2100, orphaned 0, timewait 0) Transport Total IP IPv6 RAW 0 0 0 UDP 1 1 0 TCP 1 1 0 INET 2 2 0 FRAG 0 0 0 常用参数 ... ss -a #显示所有状态的 ss -t # 匹配tcp连接 ss dst 192.168.1.5 # 匹配远程地址 ss dst 192.168.1.5:443 # 匹配远程地址和端口 ss sport lt 50 # 匹配小于50的端口号 ss state listening # 匹配listen状态 netstat # s 统计信息 t tcp watch # 周期性的执行某个命令 watch ss -s # 定时刷新ss-s命令 crontab # 定时任务, 详见 man crontab tmux \u0026amp;\u0026amp; screen # 很少远程工作了, 不再使用 为什么使用tmux 和 screen :: 远程登录操作时候, 因网络不稳定, 总是掉线, 丢失环境 讲解它们之前必须要先了解nohup 与 \u0026amp; nohup 与 \u0026amp; # nohup与 \u0026amp;都是后台运行 nohup会占用标准输出, \u0026amp;则不会占用标准输出 它们的作用都是为了防止session关闭后, 程序无法运行 但每个程序都要加上nohup前缀或\u0026amp;后缀, 则会特别麻烦, 因此出现了screen与tmux screen # screen属于GNU计划 然其操作什么的并不友善, 个人更倾向于tmux 【基本指令】 screen | screen -S \u0026lt;name\u0026gt; 创建screen screen -d detach screen 只有deatch之后 其他人才能attach screen -r reatach screen 链接screen screen -ls | screen -list 列出所有的screen 【快捷键操作】 screen的一个弊端就是将太多功能放在了快捷键上 而不是放在CMD上 C-a 为screen指令的前缀 C-a k kill C-a w 列出所有的screen窗口 \u0026ndash; 亲测无效??? C-a p |C-a n 切换到上一个或下一个窗口 \u0026ndash; 亲测无效?? C-a z 类似于emacs的C-z 将程序放入后台 可以通过jobs 和fg操作 通过C-a z可以了解screen的工作原理 \u0026ndash; screen就是新开了一个shell, 在里面有不同的窗口windows 然后可以在windows间切换, 或者是回到原先的shell中 【为什么放弃screen】 虽然查看教程, 发现screen还有很多高级功能, 然而screen的窗口功能太不友好, 导致我经常不知道自己工作 在哪个窗口下, 而且因为C-a w的无效, 很难有一览全局, 所以最后选择放弃screen, 改投tmux tmux # 框架 server -\u0026gt; session 01 | -\u0026gt; session 02 | \u0026ndash;\u0026gt; socket 01(默认socket) -\u0026gt; session 03 \u0026ndash;\u0026gt; socket 02(通过-L | -S生成的新的socket) \u0026hellip; \u0026hellip; 即一个server 多个session, session又属于socket 基本指令 tmux tmux ls 列出所有的tmux session, 注意没有- \u0026ndash; tmux attach attch到上次的tmux session tmux attach -t session attch到指定的tmux session tmux kill-session -t 关闭session tmux kill-server -t 关闭server 注: 关闭server 将导致tmux关闭, tmux中的程序也会关闭 如果session退出之前, tmux是挂起状态stopped,那么下次session重新链接后, 将导致tmux关闭 tmux new -s $sessionName 创建一个新的session, 并指定其名称, 不然就是递增数字 快捷键操作 tmux以C-b作为快捷键的前缀 C-b ? 列出所有的命令 C-b 数字 | n | p 切换窗口 C-b C-z 挂起程序 C-b d deatach类似于screen中的deatch deatch之后就可以回到正常的shell, 并使tmux运行在后台 为什么选择tmux 友好的界面, 友好的C-b ?帮助提示, 简单的操作 遗留问题 如果运行 tmux\u0026amp; (\u0026amp;后台运行), 会导致莫名其妙的问题 如何使tmux在后台运行 使用bg命令无效, 这与进程的状态有关\u0026hellip;有时间再看 C-b d 使当前session deatch运行在后台 ffmpeg # 优秀的视频解码软件 ffmpeg -i https://××××××××/really.m3u8 -c copy xxx.mp4 sort # 根据ASCII进行排序, 默认为升序 u 去除重复行 r 降序 n 根据数值进行排序 有没有遇到过10比2小的情况。我反正遇到过。 出现这种情况是由于排序程序将这些数字按字符来排序了，排序程序会先比较1和2，显然1小，所以就将10放在2前面 -n可以告诉sort根据数值进行排序, 而非ASCII k, t k指定列数, t指定分隔符 f 会将小写字母都转换为大写字母来进行比较，亦即忽略大小写 wc -l # 统计行数 管道 # | \u0026amp;\u0026amp; xargs # 管道是实现将 前面的标准输出 作为 后面的标准输入 xargs是实现将 前面的标准输出 作为 后面命令的参数 "},{"id":1,"href":"/docs/emacs/org/org/","title":"org","section":"org \u0026\u0026 gtd","content":"org-mode一直被称为神器 主要有2大功能, 一是自身强大的文本模式(依赖 org-mode), 另一个则是 org-agenda 推荐阅读: org心得体会 配置 # org作为文本模式配置较少, 更多的是配置org-agenda为GTD管理工具. org文本模式下, 配置简单外观 以及 Babel-languages org-agenda的配置可参考init-org-agenda.el和一系列自定义函数 使用 # font format # key format normal = monospace ~ key-binding + strike-through _ underline 基本语法 # 语法: time-stamp选择 # 添加time-stamp时, 不要在calendar中移动,效率太低 使用以下2种方式即可: 使用简约的时间格式 17-1-1 =\u0026gt; 2017-01-01 使用时间间隔 now = [2016-12-28 Wed] +1d =\u0026gt; 2016-12-29 具体见(dir) - Org mode - Dates and times - Creating timestamps - The date/time promt 语法: 时间repeate # org-mode repeate格式 .+ ++区别 \u0026ldquo;+\u0026rdquo; backlog 可以积压的item \u0026ldquo;.+\u0026rdquo; specific date, no backlog 在特定日期完成的item ep: call mother 每周六给mother打电话, 不可积压(或者说现在的操作不会影响之前) \u0026ldquo;++\u0026rdquo; specific interval, no backlog 在特定间隔完成的item ep: change batteries 每隔1月更换电池, 不可积压 语法: table计算 # @ 表示行； $表示列 \u0026lt; 表示第一; \u0026gt; 表示最后； 例子: @\u0026lt; 第一行 $\u0026gt; 最后一列 @\u0026lt;\u0026lt; 第二行(更建议使用 @2) 对table使用C-c} 可以查看行列值 "},{"id":2,"href":"/docs/emacs/emacs/","title":"emacs","section":"emacs","content":" 简述 # emacs是什么 # emacs最原始,最纯粹的功能: text editor 也可以作为优秀的 program editor 优秀的文本 gtd 软件 良好的扩展性, 很多优秀插件, 比如org,magit,tramp,eshell等 综上, emacs其实更像一个大杂烩, 整合了大多数功能, 使其可以高效的完成任务. 同时, 因为良好的定制性, emacs可以增强个人使用体验, 但也增加了很多学习成本 日常使用功能 # 文本编辑 因为emacs跑在wsl中, 日常很少用来文本编辑了 代码编写 公司使用vs工程, 日常很少使用emacs编码了 gtd blog 现在使用emacs, 大部分是在使用 org-mode 写blog, 使用 org-agenda 作GTD管理 emacs-程序 # emacs作为程序最基本的配置. themes ui界面显示 frame window font file recentf files buffers sessions text editor # 文本编辑器是emacs最原始, 最纯粹, 最重要的功能. 大部分配置都是在处理该项, 使其更符合个人习惯. 配置繁琐, 但不复杂 show # text editor最基本的配置, 文本在buffer中显示的样子. 比如行号, break-line, column indicator等 move-and-kill # 即是text editor, 也是emacs最基础的操作. delete, kill, yank, select. 这是emacs中最基础的操作 hide-show # hide, show 方便控制sexp的显示隐藏 completion # text editor的配置使我们可以高效的编辑文本. 而completion则可以使emacs更聪明的理解我们的动作. emacs有非常多的completion前端和后端, 也有前后端大杂烩. 没必要都了解, 选一个常用的即可. completion流程: complete根据我们动作提供候选者 -\u0026gt; 前端显示候选者 -\u0026gt; 我们选择合适的候选 流程本身非常简单, 涉及到的package也很少, 比较复杂的是候选者的提供, 而这个不需要我们自己去做. 现在的方案 ([2023-11-01 Wed]): consult提供候选, vertico \u0026amp;\u0026amp; corfu作为前端显示, marginalia补充候选者信息, orderless过滤候选者. embark提供对候选者的操作. 几个package提供了功能的最小合集, 且与emacs兼容性良好. 因此不再建议使用helm等大杂烩包 其他一些package也是在提供候选, 比如yasnippet, eglot, copilot等. 因为针对的场景不同, 暂时不在这里介绍 prog editor # emacs可以配置为优秀的IDE. 而且因为定制性强, 配置的IDE更能符合个人的工作流程. 合格的IDE需要有以下功能: 编辑, 编译, 调试, 发布 emacs内置了lsp client: eglot. 而且eglot与错误处理flymake搭配良好. eglot可以把lsp server中的错误信息给到flymake, completion信息给到corfu(实际是给到emacs completion通用接口), symbol信息给到xerf 键位设置 # 原则 # 尽量保留默认常用快捷键 不同mode, 尽量使用相似的快捷键 思路 # 通用快捷键(比如search等与mode无关的)或者是所有mode都会使用的统一放到C-s中 mode自身的快捷键, 放到C-j中 项目相关的快捷键, 放到C-d中 其他插件|软件相关的快捷键, 放到C-r中 tty keys # step remap tty(console) 物理code =\u0026gt; Sequences Event code emacs: input-decode-map Sequences Event code =\u0026gt; 第一层转换 emacs: local-function-key-map 第一层转换 =\u0026gt; emacs可识别的 emacs : global-set-key等 eamcs可识别的 =\u0026gt; function 由于tty(console)对于有些key(比如C-backspace)等未作Sequences Event code. 所以其(C-backspace)的表现和backspace可能是一样的. 第一步, 先在console中对需要的key 设定Sequences Event code. 第二部, 在emacs的input-decode-map中将这些Sequences Event code映射为我们的按键 详见init-tty-keys.el 编译emacs # # --without-all 最小化编译 (但是包含了x) # --without-x 不使用x # --with-gnutls=ifavailable 移除configure警告 (实际并未编译) # --with-tree-sittter 开启tree-sitter # --with-xml2 package::devdocs依赖 # --with-native-compilation 之前的gccEmacs(据传可增加运行效率) (未使用) ./configure --without-all --without-x --with-gnutls=ifavailable --without-pop --with-tree-sitter --with-xml2 --with-native-compilation "},{"id":3,"href":"/docs/prog_base/algorithm/","title":"数据结构与算法分析","section":"prog base","content":" 概述|总结 # 什么是 # 数据结构分为 物理结构 即在内存中的结构. 有顺序存储(内存连续) 和 链式存储(内存可不连续) 逻辑结构 一对一的线性, 一对多的树, 多对多的图 逻辑结构 # 一对一 # stack (LIFO) 堆栈, 后进先出 queue (FIFO) 队列, 先进先出 一对多 # tree 树 binary tree 二叉树 search binary tree 搜索二叉树 blance binary tree 平衡二叉树 complet binary tree 完全二叉树 name 特征 备注 tree binary tree 1.任意节点 叶度 \u0026lt;=2 search bianry tree 1.binary tree 2.任意节点 left-child, root, right-child有序 blanced binary tree 1.search binary tree 2.任意节点的 \u0026lt;左树高度-右树高度\u0026gt; \u0026lt;=1 complet binary tree 1.search tree 2.节点依次从左到右 多对多 # graph 图 数据结构比较 # type type Access 查找 增加,删除 适用场景 c++类型 备注 array 1.数组 O(1) O(n) O(n) 数据访问 基础类型 1.Access快, 是因为内存连续, 寻址方便 2.动态数组 std::array std::vector linked-list 1.单链表 O(n) O(n) O(1) 数据增删, 查找较少 std::list 2.双链表 3.循环链表 skip list O(n),Θ(logN) O(n),Θ(logN) O(n),Θ(logN) 介于array与linked list中间 stack O(n) O(n) O(1) LIFO 数据增删 std::stack queue 1.队列 O(n) O(n) O(1) FIFO 数据增删 std::queue 2.双端队列 std::deque 3.优先队列 hash N/A O(1) O(1) 数据查找 std::unordered_map T(n) = O(1) + hash函数 + 冲突 tree 1.二叉查找树 O(n),Θ(logN) O(n),Θ(logN) O(n),Θ(logN) std::set std::map 2.平衡二叉树 3.红黑树 O(logN),Θ(logN) O(logN),Θ(logN) O(logN),Θ(logN) heap 1.最大堆 1.完全二叉树 存储 2.最小堆 2.最大(小)堆, 任意node \u0026gt; 其子树 3.实际是优先队列 graph trie 排序算法比较 # name type 定义 T(n) θ T(n) O S(n) 稳定性 适用场景 适用结构 备注 bubble sort 冒泡排序 循环n次 θ(n^2) O(n^2) O(1) yes 数据较少 1.数组 循环结束判定: 每第i次循环, 集合[0-i]中相邻元素按序交换 基本有序 2.链表 1.循环了size-1次 每第i次循环, 可确定n-i位置上的元素 2.上次循环中没有发生元素交换 就表示是已序的了 排序只用到指针 \u0026amp;\u0026amp; flag, 原地排序, 因此空间复杂度为O(1) 元素交换O(n^2) selection sort 选择排序 循环n次 θ(n^2) O(n^2) O(1) no 数据较少 1.数组 元素交换O(n) 每第i次循环, 选择集合[i, n]中最小的元素,放在i位置 2.链表 每第i次循环, 可确定i位置上的元素 insertion sort 插入排序 循环n次 θ(n^2) O(n^2) O(1) yes 元素交换O(n^2) 每第i次循环, 将i位置的元素放到集合[0-i]的有序位置 shell sort 希尔排序 循环gap()拆分数组, 对拆分后的数组们进行插入排序 Hibbard: θ(n^3/2) O(n^5/4) O(1) no 拆分后的数组们进行排序时没必要sort完A后再sort B, C Sedgewick: θ(n^7/6) O(n^4/3) 可以A, B, C的sort在同一个for循环进行 T(n)与gap的选择有关 merge sort 归并排序 分而治之 θ(nlogN) O(nlogN) O(n) yes 递归 与 非递归两种实现 分: 分为有序集合A, B 治: 有序集合A, B =\u0026gt; C heap sort 堆排序 循环n次 θ(nlogN) O(nlogN) O(1) no selection sort的优化版 每第i次循环, 最大堆root元素放到n-i位置 快速排序 计数排序 基数排序 桶排序 "},{"id":4,"href":"/docs/tool/docker/","title":"docker","section":"tools","content":"docker容器 功能 # 为什么需要docker # docker与虚拟机的对比 # 之前以为docker容器就是简约版本的虚拟机, 所以一直想把不同的软件融合到一个镜像中 现在2020.6.21 发现上面的想法是错误的 现在的认知: docker是对于app(单个软件)的封装 多个软件协同合作的正确方式, 应该是建立多个互相关联的容器, 而不是企图把所有的软件放到一个容器中 安装 # 安装docker 安装Kitmatic docker gui工具; 不推荐使用 配置 # 镜像配置 使用中国科技大学镜像加速, 无须注册, 直接使用即可 使用 # 推荐阅读教程 TODONOW 待补充 docker实际应用 web服务器 + php + laravel + 数据库 镜像操作 # 搜索镜像 docker search \u0026lt;image name\u0026gt; 下载镜像 docker pull \u0026lt;image name\u0026gt; 实例化镜像 镜像实例化为容器 (类比C++中的类\u0026ndash;镜像, 对象\u0026ndash;容器) docker run -e \u0026ldquo;参数\u0026rdquo; -P 端口映射 \u0026ndash;name 容器名字 -d(后台运行) image名字 -p 本机端口 : 容器端口 -v 本机路径 : 容器路径 镜像存储为文件 \u0026amp;\u0026amp; 加载 docker save image_name -o file_path docker load -i file_path 在网络不好的情况下, 可以直接使用文件的方式加载镜像 容器封装为镜像 docker commit [container_id] [image_name] image tag修改名字 docker tag [old_image_name] [new_image_name] 推送image到dockerhub 必须先登录dockerhub docker login 推送的时候image必须增加tag, tag的名字必须为 登录id/image名字 docker 官网速度太慢了, 建议存储为文件, 供别人使用 git push image 容器操作 # 查看容器 docker container ls -al 启动 关闭 重启容器 docker container start | stop | restart \u0026lt;container_id\u0026gt; 重定义容器输出 docker container attach \u0026lt;container_id\u0026gt; 进入到容器中 docker container exec -it \u0026lt;container_id\u0026gt; COMMAND -i interactive -t tty COMMAND 一般都是bash环境. 比如: docker container exec -it mysql bash 本机与docker容器交互 # 文件传输 docker cp test mssql:/home 查看镜像ip地址 TODONOW 因hexo原因, 下面的命令会导致hexo无法编译org为html, 所以详见 ~/bin/docker_ip.sh Dockerfile \u0026amp;\u0026amp; docker-compose # dockerfile \u0026ndash; 对镜像的管理, 可以安装并修改镜像 (类比C++中的class) docker-compose \u0026ndash; 对容器的管理, 可以指定使用哪个容器, 并能修改容器 (类比C++中的对象实例) docker-compose 是一个指令, docker-compose.yml是其配置文件 docker-compose -h查看用法 网桥 # 通过指令docker network可以查看 docker中的网桥信息 网桥可以使多个容器组件局域网 容器可以在创建之前选择网桥 docker create --name [容器名称] --network [网桥名称] [镜像名称] 容器也可以在运行状态时 选择网桥 docker network connect [网桥名称] [容器名称] 卷 volume # docker volume create 命令用于创建新卷。默认情况下，新卷创建使用 local 驱动，但是可以通过 -d 参数来指定不同的驱动。 docker volume ls 会列出本地 Docker 主机上的全部卷。 docker volume inspect 用于查看卷的详细信息。可以使用该命令查看卷在 Docker 主机文件系统中的具体位置。 docker volume prune 会删除未被容器或者服务副本使用的全部卷。 docker volume rm 删除未被使用的指定卷 docker-compose # dockerfile # COPY 注意事项 COPY src tag 如果tag不存在, 则会创建, 类似mkdir -p 如果src或tag为目录, 则必须以/结尾 src为目录, 复制的时候src自身不会被复制, 只会复制其里面所有子文件 小技巧 # 使用镜像的时候, 不一定要做成容器 可以使用 docker run -it image_name 镜像漏洞排查 # docker scan "},{"id":5,"href":"/docs/os/socket/socket/","title":"socket base","section":"socket","content":"socket相关网络编程 基本概念 # socket # socket是 [应用层] 与 [传输层, 网络层] 之间的一个抽象层 它的出现是为了简化网络进程通信 linux头文件 # usr/include/x86_64-linux-gnu/sys/socket.h 结构体 sockaddr 函数 socket() connect() send() recv() shutdown() socket() bind() lisent() accept() recv() send() shutdown() g++的默认目录中已经包含了sys/的上层目录 usr/include/netinet/in.h 结构体 AF_INET 中的 sockaddr_in AF_INET6 中的 sockaddr_in6 AF_UNIx 中的 sockaddr_un user/include/arpa/inet.h 函数 htons() inet_addr() unistd.h 函数 close() socket函数 # socket(domain, socket_type, protol) domain socket_type protol socket()本质是创建了一个进程文件表, 返回的值为指向进程文件表的指针的索引. bind(fd, sockaddr*, len) fd: socket()中的文件表指针的索引 sockaddr: 地址, 端口 len: sockaddr的长度 \u0026lt;1\u0026gt; 比较有意思的是sockaddr根据family的不同, 可以与不同的结构体互转 比如 AF_INET sockaddr_in AF_INET6 sockaddr_in6 AF_UNIX sockaddr_un 这几种结构体都与sockaddr可互转(字节对齐blabla) bind()本质是在补充socket()创建的文件表. socket()时候该文件表很多值都是空的, bind()来补充 因为client 在connect的时候, 系统会自动分配端口,以及绑定本机ip, 所以client的socket一般不必要 使用bind() connet(fd, sockaddr*, len) 连接到其他scokaddr listen(fd, iMaxNum) iMaxNum是队列中的最大数, 并不是指可连接的socket数目 一般只在server开启listen(), 监听指定的端口信息 accept() accept()会造成阻塞. 它会将listen()中的sockaddr进行处理 处理流程是 accept()会创建一个新的fd_connet, 此fd_connet公用server socket() fd的端口和地址 但是fd_connect仅仅是用来传输数据的 recv(fd, msg) send(fd, msg) 至accetp()时候, 一切操作就和在本地上操作一样, 所以这里的recv() 和 send()操作与本机上的文件操作是一样的 close(fd) shutdown(fd, type) linux一切皆是file原则, fd可以关闭 [ip, port]相关函数 # 点分十进制ip 是以字符串形式存储的 网络字节序 即 32位的二进制 //in_addr struct in_addr { in_addr_t s_addr; }; //in_addr_t typedef unsigned long in_addr_t 函数原型: in_addr_t inet_addr(const char* strptr); 若字符串有效, 则将点分十进制IP字符串转换为网络字节序地址，否则为INADDR_NONE 函数原型：int inet_aton(const char *IP, struct in_addr *addr); 将点分十进制IP地址转换为网络字节序存储在addr中，并且返回该网络字节序表示的无符号整数 函数原型：char *inet_ntoa(struct in_addr in); 将网络字节序的IP地址（也就是结构体in_addr类型变量）转化为点分十进制的IP地址（字符串) socket fd本质 # socket本质是维护了fd进程文件表, 如下: 名称 说明 备注 fd 文件描述符, 表的索引 host 1. 域名(DNS /etc/hosts) 2. ip地址 兼容Ipv4 Ipv6是难点 服务 1. 服务名称(/etc/services) 2. 端口 协议 1. 传输层(/etc/protol) 2. 网络层 链路层用到的比较少 网络 1. 网络名称?(DNS /etc/networks) 2. ip地址 谁会使用到这些信息?? 期间用到的函数主要有 尽量使用ipv4, ipv6通用的函数 流程函数 socket() bind() listen() connect() accept()等 字节处理函数 处理大小字节序 htons() htonl() ntohs() ntohl() 处理域名与十分数字 getaddrinfo() getnameinfo() 处理sockaddr结构体的函数 getsockname() 返回local fd getpeername() 返回remote fd socket问题 # 阻塞 影响并发, 多路复用 解决方案: 使用非阻塞模型, 比如select, poll, epoll(linux下特有), IOCP(windows下特有) 多线程 \u0026ndash; 不推荐使用 多进程 \u0026ndash; 不推荐使用 粘包 解决方案: 限制发送大小 每个消息增加长度标识 I/O模型 # 强烈建议阅读 (链接过期, 直接搜狗搜索epoll, \u0026ldquo;epoll本质\u0026quot;即是) 阻塞式 非阻塞 select poll epoll (linux特有) IOCP (windows特有) epoll使用 # epoll本身为我们处理了什么 # 之前socket::recv()时, 导致我们的进程阻塞 现在socket::recv()时, 使epoll阻塞; epoll中断时, 告之进程 有了epoll我们还需要处理什么 # 创建epoll对象 添加检视的fd对象 \u0026ndash; op, epoll_event 检测是否有中断, 然后处理 socket属性 # keep live机制 # 当socket服务端开启keep live之后, 服务器检测到 一定时间内 socket不活动的时候, 就会每隔 固定时间 向该sockt发送 固定次数 的查询. 如果一直没有回应, 服务端则关闭该socket 对应的字段为: tcp_keepalive_time（开启keepalive的闲置时长） tcp_keepalive_intvl（keepalive探测包的发送间隔） tcp_keepalive_probes （如果对方不予应答，探测包的发送次数） 编程实例 # 原始socket模型, recv()中处理分包粘包 # 原始socket模型, 考虑到tcp分包 //网络读取 -- 系统检测到网络I/O事件时, 调用该函数 LRESULT CTCPSocketService::OnSocketNotifyRead(WPARAM wParam, LPARAM lParam) { //读取数据 //使用中间量m+cbRecvbuf来当做缓冲区 //使用中间量m_wRecvsize来记录当前缓冲区中已读数据大小 int iRetCode = recv(m_hSocket, (char *)m_cbRecvBuf + m_wRecvSize, sizeof(m_cbRecvBuf) - m_wRecvSize, 0); //读取失败, 则返回SOCKET_ERROR if (iRetCode == SOCKET_ERROR) { ZeroMemory(m_cbRecvBuf, sizeof(m_cbRecvBuf)); m_wRecvSize = 0; return 1;//\u0026quot;网络连接关闭，读取数据失败\u0026quot;; } //读取成功, 则返回读取到的数据的大小 m_wRecvSize += iRetCode; //在tcp数据中, 增加包的大小, 用来校验是否读取完毕; TCP_Head * pHead = (TCP_Head *)m_cbRecvBuf; WORD wPacketSize = pHead-\u0026gt;TCPInfo.wPacketSize; // //数据包大小校验 if (wPacketSize \u0026gt; (SOCKET_TCP_BUFFER + sizeof(TCP_Head))) { //当发生错误时候, 缓冲区置位 ZeroMemory(m_cbRecvBuf, sizeof(m_cbRecvBuf)); m_wRecvSize = 0; return 3;//\u0026quot;数据包太大\u0026quot;; } //解析数据 if (m_wRecvSize == wPacketSize) //数据全部接受完毕之后 再解析 {\t//拷贝数据 BYTE cbDataBuffer[SOCKET_TCP_BUFFER+sizeof(TCP_Head)];\tCopyMemory(cbDataBuffer, m_cbRecvBuf, wPacketSize); //置位缓冲信息 -- 缓冲区中只保存一条tcp信息 m_wRecvSize = 0; ZeroMemory(m_cbRecvBuf, sizeof(m_cbRecvBuf));\t//解密数据 WORD wRealySize = CrevasseBuffer(cbDataBuffer, wPacketSize); if(wRealySize \u0026lt; sizeof(TCP_Head)) return 4; //解析后的数据错误 //获得TCP_Head TCP_Command Command = ((TCP_Head *)cbDataBuffer)-\u0026gt;CommandInfo; //获得实际的数据 void * pDataBuffer = cbDataBuffer + sizeof(TCP_Head); //实际的数据 WORD wRealDataSize = wRealySize - sizeof(TCP_Head); //实际的数据大小 //内核命令 if (Command.wMainCmdID == MDM_KN_COMMAND) { switch (Command.wSubCmdID) { case SUB_KN_DETECT_SOCKET:\t//网络检测 { //发送数据 SendData(MDM_KN_COMMAND, SUB_KN_DETECT_SOCKET, pDataBuffer, wRealDataSize); break; } } continue; } //处理数据 bool bSuccess = m_QueueServiceEvent.PostTCPSocketReadEvent(m_wServiceID, Command, pDataBuffer, wRealDataSize); if (bSuccess == false) return 5;//\u0026quot;网络数据包处理失败\u0026quot;; }; return 0; } ipv4 # 系统文件在/proc/sys/net/ipv4下面 ip_local_port_range # 用户端口范围, [n, m) tcp_timestamp # 针对TIME_WAIT状态的tcp连接; 0关闭,1开启 tcp_tw_recycle # 是否快速回收+ linux内核已删除该字段 tcp_tw_reuse # TIME_WAIT状态的tcp的port是否可以复用;0关闭,1开启 # 需要开启tcp_timestamp; # 这是针对cli的设计,而非svr tcp_rmem # tcp read缓冲区 tcp_wmem # tcp write缓冲区 ip_forward 0禁止ip转发, 1打开; ip_default_ttl 数据报的生存周期(time to live), 即最多经过多少路由器 ip_no_pmtu_disc 关闭路径MTU探测 min_pmtu 最小路径MTU的大小 mtu_expires PMTU信息缓存多长时间 "},{"id":6,"href":"/docs/prog_vc/git/","title":"git","section":"prog vc","content":"git简易指导, 个人使用心得 git使用流程 # git原理 # git特性 # tag # 获取最近的tag git describe --abbrev=0 --tags 查看2个tag(或HEAD, 或branch)之间的距离, A与B之间的距离(或B与A之间的距离) 如果未branch_name, 实际为branch上的HEAD节点 git log --pretty=oneline tagA...tagB 查看从A到B的距离, 而不是从B到A的距离 If you just wanted commits reachable from tagB but not tagA: git log --pretty=oneline tagA..tagB #或者 git log --pretty=oneline ^tagA tagB 简化SHA信息 \u0026ndash;abbrev-commit # 一般--pretty=oneline 后面都会加 --abbrev-commit git log --pretty=oneline --abbrev-commit git高级特性 # git hooks # 参考文档 删除大文件 # 寻找大文件 git rev-list --objects --all | grep \u0026quot;$(git verify-pack -v .git/objects/pack/*.idx | sort -k 3 -n | tail -5 | awk '{print$1}')\u0026quot; 删除大文件 git filter-branch -f --prune-empty --index-filter 'git rm -rf --cached --ignore-unmatch your-file-name' --tag-name-filter cat -- --all 删除之后 git gc --prune=now git lfs # 把大文件排除在git仓库之外, git仓库中只有一个指针指向该大文件 安装lfs # curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash \u0026amp;\u0026amp; sudo apt-get install git-lfs \u0026amp;\u0026amp; git lfs install 初始化 # git lfs install 使用 # 过滤大文件 git lfs track file_path 过滤之后, 会生成.gitattributes 提交到远端 git push \u0026ndash; 提交普通文件 git lfs push \u0026ndash; 提交lfs文件 下载大文件 git lfs clone url git submodule # 参考文档 https://www.cnblogs.com/nicksheng/p/6201711.html 当项目越来越庞大之后，不可避免的要拆分成多个子模块， 我们希望各个子模块有独立的版本管理，并且由专门的人去维护，这时候我们就要用到git的submodule功能 submodule 管理的不是分支, 而是一个commit #递归的方式克隆整个项目 git clone \u0026lt;repository\u0026gt; --recursive #添加子模块 git submodule add --branch branch_name \u0026lt;repository\u0026gt; \u0026lt;path\u0026gt; #初始化子模块 -- 根据.gitmodule文件clone子模块 git submodule init # 更新子模块 参数remote表示拉取远端最新的而非仓库对应的; init同上 git submodule update --remote --init # 拉取所有子模块 git submodule foreach git pull 拉取子模块 # 方法1 先clone父项目 更新子模块 git submodule update --init 方法2 clone 父项目时 加 \u0026ndash;recursive git clone url path --recursive F\u0026amp;Q # 问: 命令行下的git status如何显示中文 答：git config --global core.quotepath false 问：在命令行下(gnu-bash)中git不能补全git的命令 1) 首先获得源码 git clone git://git.kernel.org/pub/scm/git/git.git 1) 从源码中拷贝git-completion.bash到用户主目录下. git-completion.bash cp git/contrib/completion/git-completion.bash ~/.git-completion.bash 2) 在 .bashrc 中加入 source ~/.git-completion.bash 3) 在shell下执行 . ~/.bashrc 问: 如何取消对文件的跟踪 答: 分情况而定 1) 对于从没有追踪过的文件, 只需要设置.gitignore即可 2) 对于已经追踪过的文件, 需要git rm --cached (-r) file 然后再加入到.gitignoe中即可 git对大小写不敏感问题, 可以通过下面命令修改 git config core.ignorecase false 修改git默认的编辑器 git config --global core.editor \u0026quot;'D:/notepad++/notepad++.exe' -multiInst -notabbar -nosession -noPlugin\u0026quot; "},{"id":7,"href":"/docs/prog_lsp/global/","title":"global","section":"prog lsp","content":"在project中生成TAGS文件, 方便索引 建议使用lsp代替, global响应虽然快速, 但是不如lsp实时定位方便 安装 # sudo apt install global 使用 # # step1 make tag-files (GPATH, GRTAGS, GTAGS) gtags # *step2 maybe make htlm htags # step3 find global X #find tag global -r X #find rtag global -s X #find symbol GPATH, GRTAGS, GTAGS # GTAGS 中包含了定义 GRTAGS中包含了引用 GPATH 中是路径名字 对于C++来说 tag包含了class, struct, global-function \u0026amp;\u0026amp; class-function 但是不包含class-symbol(成员变量), 局部变量, 全局变量 rtags中包含了tag中内容的引用 和 非tag中内容的引用(比如成员变量) 所以使用global来查找的时候, 参数非常有必要. 比如 global X 是在GTAGS中查找, 所以是查找不到成员变量的, 因为成员变量没有在GTAGS中 global -r X 是在GRTAGS中查找GTAGS中定义的内容的引用, 所以也是查找不到成员变量的 global -s X 与-r相反, 是在GRTAGS中查找没有在GTAGS中定义内容的引用, 所以可以查找成员变量, 局部变量, 全局变量等 对于C++的.h文件 # 通过gtags \u0026ndash;config可以查看gtags生成tags-file的配置 wangruoxudeMacBook-Pro:~ clay$ gtags --config :skip=HTML/,HTML.pub/,tags,TAGS,ID,y.tab.c,y.tab.h,gtags.files,cscope.files,cscope.out,cscope.po.out,cscope.in.out,SCCS/,RCS/,CVS/,CVSROOT/,{arch}/,autom4te.cache/,*.orig,*.rej,*.bak,*~,#*#,*.swp,*.tmp,*_flymake.*,*_flymake,*.o,*.a,*.so,*.lo,*.zip,*.gz,*.bz2,*.xz,*.lzh,*.Z,*.tgz,*.min.js,*min.css:langmap=c\\:.c.h,yacc\\:.y,asm\\:.s.S,java\\:.java,cpp\\:.c++.cc.hh.cpp.cxx.hxx.hpp.C.H,php\\:.php.php3.phtml 很明显上面会把.h当作c来处理, 而非C++, 因此我们需要修改其默认行为 # GTAGSFORCECPP 设置为非nil, 表示把.h当作C++来处理 export GTAGSFORCECPP=1 参考资料 # 官方文档 "},{"id":8,"href":"/docs/prog_language/c++/c++/","title":"c++历史","section":"c++","content":"通过C++历史, 更好的了解C++特性 演变 # 1979 诞生 # 刚开始叫做New C, 后改名C with Classes 诞生目的: 便于大型软件开发 \u0026amp;\u0026amp; 运行效率 过 程: 增强C语言特性 (选C原因: C用途广, 快速, 可移植性) 新增特性: 类别 衍生类别 存储类型检查 内联 缺省参数 1983 改名C++ # 新增特性: 虚拟函数 函数名 运算子多载 参考 ??? 常数 使用者可控制的自由空间存储区控制 改良的型别检查 单行注释 // 1985 发布第一版 # 非官方发布 ?? 这时候有官方了??? 1989 发布Release 2.0 # 新增特性: 多重继承 抽象类别 静态成员函数 常数成员函数 成员保护 1990 出版了 标准化基础 # ??哪一年??稍后还引入了模板例外处理、命名空间、新的强制类型转换，以及布林类型 1998 C++98 第一个C++标准 # 标准分为 核心语言 \u0026amp;\u0026amp; C++标准程序库 C++标准程序库主要包含 STL \u0026amp;\u0026amp; C标准库的稍加修改版 语言特性: classes 相关 构造 \u0026amp;\u0026amp; 析构 friend 继承 多态 静态成员 new delete 高级概念 ?? 高级在哪?? 需要对比当时的环境 模板 命名空间 异常 类型转换 隐式转换 \u0026amp;\u0026amp; 显式转换 stl: 异常 \u0026lt;exception\u0026gt; 类型检查 \u0026lt;typeinfo\u0026gt; 输入输出 \u0026lt;iostream\u0026gt; 2003 C++03 第二个C++标准 # C++03 主要是在C++98基础上针对实现方的一些问题进行了修复，从而在各个实现间达到一致、保持了可移植性。 该版本共涉及 92 项核心语言缺陷报告、125 项库缺陷报告，所提供的新特性只有一项：值初始化（value initialization） 实现方是指编译器 ??需要重点看一下当时的编译器有哪些?? 对于使用者(程序员)来说, C++03与C++98差异不大(只有一条 值初始化) 2006 C++性能技术报告 # 2007 C++技术报告: 库扩展 # 2010 数学函数扩展 # 2011 C++11 第三个C++标准 # 先前被称作C++0x, 本预计2000-2009间会发布, 结果一直拖到了2011年. 因此改名C++11. 参考资料 相比于C++03，C++11标准包含核心语言的新机能， 而且扩展C++标准程序库，并入了大部分的C++ Technical Report 1程序库（数学的特殊函数除外) 设计原则 # 维持稳定性和与C++98，可能的话还有C之间的兼容性； 尽可能不透过核心语言的扩展，而是透过标准程序库来引进新的特性； 能够演进编程技术的变更优先； 改进C++以帮助系统以及库设计，而不是引进只针对特别应用的新特性； 增进类别安全，提供对现行不安全的技术更安全的替代方案； 增进直接对硬件工作的能力与表现； 提供现实世界中问题的适当解决方案； 实行“zero-overhead”原则（某些功能要求的额外支持只有在该功能被使用时才能使用）； 使C++易于教授与学习 语言变更 # C++委员会的主要作用之一是改善语言核心。核心语言将被大幅改善的领域包括 多线程支持 泛型编程 统一的初始化 以及性能表现的加强 在此分成4个区块来讨论核心语言的特色以及变更: 执行期表现强化、构造期表现强化、可用性强化，还有新的功能。 某些特性可能会同时属于多个区块，但在此仅于其最具代表性的区块描述 执行期表现强化\n提升某些性能表现, 像是内存或者速度上的提升 右值引用 \u0026amp;\u0026amp; std::move \u0026amp;\u0026amp; std::forward\n右值引用是语言特性, std::move \u0026amp;\u0026amp; std::forward是stl中新增的函数 (头文件\u0026lt;utility\u0026gt;) 符合设计原则2, 使用stl补充语言特性 右值引用的本质是为了解决C++之前版本的深度copy问题. wiki参考资料 template \u0026lt;typename T, typename Arg\u0026gt; shared_ptr\u0026lt;T\u0026gt; factory(Arg arg) { return shared_ptr\u0026lt;T\u0026gt;( new T(arg)); } template \u0026lt;typename T, typename Arg\u0026gt; shared_ptr\u0026lt;T\u0026gt; factory(Arg\u0026amp; arg) { return shared_ptr\u0026lt;T\u0026gt;( new T(arg)); } template\u0026lt; typename T, typename Arg\u0026gt; shared_ptr\u0026lt;T\u0026gt; factory(const Arg\u0026amp; arg) { //无法修改arg对象 return shared_ptr\u0026lt;T\u0026gt;( new T(arg)); } template\u0026lt;typename T, typename Arg\u0026gt; shared_ptr\u0026lt;T\u0026gt; factory(Arg\u0026amp;\u0026amp; arg) { return shared_ptr\u0026lt;T\u0026gt;(new T(std::forward\u0026lt;Arg\u0026gt;(arg))); } /* 调用时候, 参数如果是左值, 只需要std::move()获取对应的右值 */ //两者都在\u0026lt;utility\u0026gt;头文件 //std::move(arg) 可以获取左值的右值引用 // 因为右值引用是将原对象的内容移动到新对象, 所以原对象移动后不应再使用 //std::forward\u0026lt;T\u0026gt;(arg) 可以获取arg的T属性. // T如果为int, 则使用arg的右值 // T若果为int\u0026amp;, 则使用arg的左值 右值引用使用场景: 上面的exp所展示的 就是在以传值方式传递对象时隐式发生的耗时且不必要的深度拷贝。 举例而言，std::vector\u0026lt;T\u0026gt;本质上是一个C-style数组及其大小的封装， 如果一个std::vector\u0026lt;T\u0026gt;的临时对象是在函数内部或者函数返回时创建， 要将其存储就只能透过生成新的std::vector\u0026lt;T\u0026gt;并且把该临时对象所有的资料复制过去 然后该临时对象会被析构，其使用的内存会被释放 std::vector\u0026lt;int\u0026gt; test(){ std::vector\u0026lt;int\u0026gt; vec_data; //一些操作 //... //返回vec_data实际是 //1.创建了一个新的std::vector\u0026lt;int\u0026gt; 临时对象 //2.把vec_data对象深度copy给 临时对象 //3.返回临时对象 //4.销毁vec_data对象 // // 其中深度copy会造成非常大的开销, 导致性能低下 return vec_data; } std::vector\u0026lt;int\u0026gt; test(){ std::vector\u0026lt;int\u0026gt; vec_data; //一些操作 //... // //1.创建一个新的std::vector\u0026lt;int\u0026gt; 临时对象 //2.把vec_data对象移动到 临时对象 //3.返回临时对象 //4.销毁vec_data对象 // //对比旧版本, 这里少了深度copy这一层 return std::vector\u0026lt;int\u0026gt; (std::move(vec_data) ); } 注意事项 对象被右值引用后, 再操作会导致不可预知的问题(内存相关信息已被置为null) 并非所有情形都合适. 应该使用在避免深度copy的场合 constexpr 泛化的常量表达式\nconstexpr确保对象在编译期完成初始化操作, 因此加快运行期的效率 //const 与 constexpr 均表示该表达式(对象或函数)被声明为常量 //const 不保证对象经历哪种类型的初始化, 可能是编译器初始化, 也可能是运行期初始化 //constexpr 保证对象使用编译器初始化 //const演示 int get_number(){ return 5; } const int mx = get_number(); //mx是常量对象, 但在运行期获得初始化 int arr[mx] ; //错误. 因为mx是在运行期获得初始化; 而int[]需要编译器的常量 //constexpr演示 constexpr int get_number(){ return 5; } int arr[get_number()]; //正确. 因为constexpr保证函数get_number调用在编译器初始化 //修饰函数表达式 //函数主体必须是非虚拟的，并且除了 typedef 和静态断言之外，仅包含一个 return 语句 constexpr int max() { return 4; } // ok constexpr long long_max() { return 23423424; } //ok constexpr bool get_val(){ bool res = false; return res; } //error: body只能有一个return statement //修饰变量 //与const类似 //修饰构造函数 //构造函数可以有一个成员初始化列表, 但body必须是空的 //constexpr构造函数 允许编译器在编译时初始化对象, 前提是构造函数的参数都是常量表达式 struct complex { constexpr complex(double r, double i) : re(r), im(i) { } // ok double re; double im; } constexpr complex cx0(0.0, 1.0); //ok. 编译期初始化 double x = 1.0; constexpr complex cx1(x, 0); //error: x不是常量表达式 const complex cx2(x, 0); //ok. 运行期初始化 constexpr double xx = 1.0; constexpr complex cx3(xx, 0); //ok 编译期初始化 complex cx4(1.0, 2.0); //ok 运行期初始化 对POD定义的修正\n?? 这是什么, 完全没有看懂 ?? 构造期表现强化\n外部模版\n在标准C++中，只要在编译单元内遇到被完整定义的模板，编译器都必须将其实例化（instantiate） 这会大大增加编译时间，特别是模板在许多编译单元内使用相同的参数实例化。 C++11之前, 可以告诉编译器在特定位置开始实例化, 但无法告诉编译器不要引发模板实例化 template class std::vector\u0026lt;MyClass\u0026gt;; C++11增加了 阻止编译器在编译期间引发模板实例化 extern template class std::vector\u0026lt;MyClass\u0026gt;; 可用性的加强\n初始化列表\n初始化列表的构想是 结构(或数组)的成员依据定义的顺序 由一串形参产生. struct Test{ int a; double b; int c; } //给予 Test一串形参, Test的成员根据位置,自动获得初始化 //Test成员a, b, c根据自己在Test结构中定义的顺序, 自动与形参1, 2.0, 3获得匹配的初始化 //即a=1, b=2.0, c=3 Test t1{1, 2.0, 3}; //C++11 增加了初始化列表构造函数 std::initializer_list\u0026lt;\u0026gt; class Test{ public: Test(std::initializer_list\u0026lt;int\u0026gt; list); //初始化列表构造函数 } Test test{1, 2, 3, 4}; //允许Test对象可以像这样初始化 //初始化列表构造函数的优先级大于普通的构造函数 class Test{ public: Test(std::initializer_list\u0026lt;int\u0026gt; list); //初始化列表构造函数 Test(int i): m_i(i) { }; //普通构造函数 private: int m_i; } //当初始化列表构造函数 与 普通构造函数形参一致的时候, //如果使用{}初始化, 将调用的是初始化列表构造函数 //比如下面调用的是 Test(std::initializer_list\u0026lt;int\u0026gt; list); Test test{1}; //如果想调用普通构造函数, 应该使用标准的构造函数语法 //调用的是 Test(init i); Test test(1); //std::initializer_list除了可以在构造函数中使用, 也可用于普通函数 void Fun(std::initializer_list\u0026lt;int\u0026gt; list); Fun(1, 2, 3); 统一的初始化\nstruct BasicStruct{ int x; float y; } struct AltStruct{ AltStruct(int _x, float _y): x(_x), y(_y) {} private: int x; float y; } //两者都可以采用一样的初始化样式 BasicStruct val1 {5, 2.1f}; AltStruct val2 {2, 2.1f}; auto \u0026amp;\u0026amp; decltype\nC++03使用参数必须明确的指出其类别. 然而随着模板类别的出现以及模板元编程的技巧, 某物的类别, 特被是函数定义明确的返回类别, 不容易表示. C++11提供了auto 自动类别推导, 来解决该问题 有被明确初始化的参数可以使用auto. 对于指针类型, 使用auto 和 auto*是一样的. 对于引用类型, 必须使用auto\u0026amp;. 因为auto总是推断出非引用类型 基于范围的for循环\n简化了for循环. 可以使用在C型数组, 初始化列表, 和任何定义了begin(), end()的类型 int my_array[5] {1, 2, 3, 4, 5}; //每个元素 * 2 //注意这里是auto\u0026amp;, 而非auto for (auto\u0026amp; x : my_array){ x *= 2; } lambda函数表达式 返回类别后置的函数声明\n?? 看样子, 主要用于模板中函数的返回类别 ?? class对象构造改良\n//C++11之前, 构造函数不允许调用其他构造函数 //C++11, 取消了该限制, 允许构造函数调用其他构造函数, 这种做法称为委托构造 class SomeType{ public: SomeType() : SomeType(0, \u0026quot;hahah\u0026quot;) {} SomeType(int i) : SomeType(i, \u0026quot;haha222\u0026quot;) {} SomeType(string\u0026amp; s) : SomeType(1, s) { test(); } private: SomeType(int i, string\u0026amp; s): m_i(i), m_s(s) {} int m_i; string m_s; }; //C++03 基类的构造函数不能直接作为派生类的构造函数, 每个派生类必须实现自己的构造函数 //C++11 取消了该限制. 编译器可以使用基类的构造函数完成派生类的构造 //而将基类的构造函数带入派生类的动作. 无法选择性的部分带入. //要么全部带入, 要么一个都不带入 class BaseClass{ public: BaseClass(int v); }; class DerivedClass :public BaseClass { public: using BaseClass::BaseClass; //使用基类的构造函数 }; //C++03 class 成员变量只能在构造函数中被初始化 //C++11 取消了该限制, 使其可以在声明的地方初始化 class SomeClass{ public: SomeClass() {} //当构造函数中未初始化m_val时, 使用定义的值45 SomeClass(int i) : m_val(i) {} //如果构造函数中初始化了m_val, 则使用构造函数中的值 private: int m_val = 45; int m_test {45}; //也可以使用列表初始化的样式 }; 显示虚函数重载\nstruct Base{ virtual void func(int); }; struct Derived : Base{ virtual void func(int) override; //ok 显示重载 virtual void func(float) override; //error: struct Base中没有对应的虚函数 }; struct Base{ virtual void func(int) final; }; struct Derived : Base{ virtual void func(int); //error: struct Base:func 禁止重载 }; 空指针\n//C++11之前, 使用NULL来表示0和空指针 ( C的做法 ) //但是在函数重载时候, 就容易引发歧义 void foo (char*); void foo (int); void foo (nullptr_t); //调用的实际是 void foo(int); 而非void foo(nullptr_t) foo(NULL) //C++11引入了nullptr 用来表示指针 //这样调用的就是 void foo(nullptr_t) foo(nullptr) 强类型枚举\n?? 不是很明白 这个的意义在哪 ?? ?? 枚举不和int比较, 不会很限制使用场景吗 ?? 角括号\nC++03的分析器一律把 \u0026gt;\u0026gt; 视为右移运算符. 为了避免, 编码时候不能把\u0026gt;\u0026gt;连着写. 尤其在模板编码中 C++11变更了分析器规则, 使其更加智能 显式类别转换 explicit\n?? 完全没有印象 ?? 模板的别名\n?? 对模板 完全不熟悉 ?? 模板参数的缺省值 无限制的unions\n?? 需要详细了解一下 ?? 能力的提升\n这些特性让C++语言能够做一些以前做不到的，或者极其复杂的，或者需求一些不可移植的库的事情。 可变参数模板\n?? 又是模板\u0026hellip; ?? 字符串字面值\n//C++03 提供了两种字符串字面值 \u0026quot;abc\u0026quot; //产生以空字符\\0结尾的 const char 数组 L\u0026quot;abc\u0026quot; //产生以空字符\\0结尾的 const wchat_t数组 //C++11加强了对Unicode的支持, //类别char的定义被修改为其大小至少能够存储UTF-8的8位编码, 并且能够容纳编译器的基本字符集的任何成员 //新增char16_t, char32_t, 分别对应UTF-16, UTF-32 u8\u0026quot;I'm a UTF-8 string.\u0026quot; u\u0026quot;I'm a UTF-16 string.\u0026quot; U\u0026quot;I'm a UTF-32 string.\u0026quot; //并且允许直接在字符串内插入unicode codepoints // \\u之后的是16 bits的十六进制数值; // \\U之后的是32 bits的十六进制数值 u8\u0026quot;This is a Unicode Character: \\u2018.\u0026quot; u\u0026quot;This is a bigger Unicode Character: \\u2018.\u0026quot; u8\u0026quot;This is a Unicode Character: \\U00002018.\u0026quot; R\u0026quot;(The String Data \\ Stuff \u0026quot; )\u0026quot; //()中的内容不会被转义 //R 可以和 u8/u/U组合使用 u8R\u0026quot;(I'm a \u0026quot;raw UTF-8\u0026quot; string.)\u0026quot; 用户定义字面值\nC++11开放用户定义新的字面修饰符（literal modifier），利用自定义的修饰符完成由字面值构造对象。 字面值转换可以定义为两个阶段：原始与转换后（raw与cooked) 原始字面值指特定类型的字符序列，而转换后的字面值则代表另一种类别。 如字面值1234，原始字面值是'1\u0026rsquo;, \u0026lsquo;2\u0026rsquo;, \u0026lsquo;3\u0026rsquo;, \u0026lsquo;4\u0026rsquo;的字符序列； 而转换后的字面值是整数值1234。另外，字面值0xA转换前是序列'0\u0026rsquo;, \u0026lsquo;x\u0026rsquo;, \u0026lsquo;A\u0026rsquo;；转换后代表整数值10。 ?? 如何使用 ?? 多线程编程支持\nC++标准委员会计划统一对多线程编程的支持. 这将涉及两个部分： 设计一个可以使多个线程在一个进程中共存的内存模型； 为线程之间的交互提供支持. 这部分将由程序库提供支持 在多个线程可能会访问相同内存的情形下，由一个内存模型对它们进行调度是非常有必要的。 遵守模型规则的程序是被保证正确运行的， 但违反规则的程序会发生不可预料的行为，这些行为依赖于编译器的优化和内存一致性的问题。 虽然C++11会在语言的定义上提供一个内存模型以支持线程，但线程的使用主要将以C++11标准库的方式呈现。 C++11标准库会提供类别thread（std::thread）。若要执行一个线程，可以创建一个类别thread的实体，其初始参数为一个函数对象，以及该函数对象所需要的参数。透过成员函数std::thread::join()对线程会合的支持，一个线程可以暂停直到其它线程执行完毕。若有底层平台支持，成员函数std::thread::native_handle()将可提供对原生线程对象执行平台特定的操作。 对于线程间的同步，标准库将会提供适当的互斥锁（像是std::mutex，std::recursive_mutex等等）和条件参数（std::condition_variable和std::condition_variable_any）。前述同步机制将会以RAII锁（std::lock_guard和std::unique_lock）和锁相关算法的方式呈现，以方便程序员使用。 对于要求高性能，或是极底层的工作，有时或甚至是必须的，我们希望线程间的通信能避免互斥锁使用上的开销。以原子操作来访问内存可以达成此目的。针对不同情况，我们可以透过显性的内存屏障改变该访问内存动作的可见性。 对于线程间异步的传输，C++11标准库加入了以及std::packaged_task用来包装一个会传回异步结果的函数调用。因为缺少结合数个future的功能，和无法判定一组promise集合中的某一个promise是否完成，futures此一提案因此而受到了批评。 更高级的线程支持，如线程池，已经决定留待在未来的Technical Report加入此类支持。更高级的线程支持不会是C++11的一部分，但设想是其最终实现将创建在目前已有的线程支持之上。 std::async提供了一个简便方法以用来执行线程，并将线程绑定在std::future。用户可以选择一个工作是要多个线程上异步的执行，或是在一个线程上执行并等待其所需要的资料。默认的情况，实现可以根据底层硬件选择前面两个选项的其中之一。另外在较简单的使用情形下，实现也可以利用线程池提供支持。 ?? 后期重点查看 ?? thread-local的存储期限 使用或禁用对象的默认函数\n//C++03中, 用户无法精确控制class的默认函数, 比如默认构造函数, 默认复制构造函数, 默认赋值运算符等 //比方说, 要让class不能被copy, 必须将复制构造函数 与 赋值运算符声明为private, 并不去定义他们. // 这样尝试使用这些为定义的函数会导致编译期或连接器错误 // 但这种手法一点也不理想 // //C++11允许显示的声明采用或禁用编译器提供的内置函数 // struct SomeType{ SomeType() = default; //使用默认的构造函数 }; // struct NonCopyable{ //禁用复制构造函数 \u0026amp;\u0026amp; 赋值运算符 NonCopyable \u0026amp; operator=(const NonCopyable\u0026amp; ) = delete; NonCopyable (const NonCopyable\u0026amp; ) = delete; NonCopyable () = default; } long long int类型\n在32位系统上，一个long long int是保有至少64个有效比特的整数类别。 C99将这个类别引入了标准C中，目前大多数的C++编译器也支持这种类别。 C++11将把这种类别添加到标准C++中。 静态assertion sizeof运算符可以作用于class的所有成员\n//C++11之前, sizeof运算符只能用于class的静态成员 //C++11修改为均可使用 struct SomeType{ OtherType member; }; sizeof(SomeType::member); //传回OtherType的大小 //?? 如果成员是vector数组, 会是什么样 ?? 垃圾回收机制\n?? 没明白\u0026hellip; ?? stl变更 # stl组件上的升级\n基于C++11新特性, 实现stl的更优 右值引用和其相关的move支持 支持UTF-16编码，和UTF-32字符集 变长参数模板（与右值引用搭配可以达成完美转发（perfect forwarding）） 编译期常量表达式 Decltype 显式类别转换子 使用或禁用对象的默认函数 线程支持 多元组类别 散列表 正则表达式 通用智能指针 可扩展的随机数功能\n?? C++版本的 也太麻烦了把 \u0026hellip; ?? 包装引用\n?? 与模板有关 ?? 对函数对象的包装 用于元编程的类别属性\n?? ?? ?? 用于计算函数对象返回类型的统一方法 itoa函数\niota 函数可将给定区间的值设定为从某值开始的连续值， 例如将连续十个整数设定为从 1 开始的连续整数（即 1、2、3、4、5、6、7、8、9、10）。 #include \u0026lt;iostream\u0026gt; #include \u0026lt;array\u0026gt; #include \u0026lt;numeric\u0026gt; std::array\u0026lt;int, 10\u0026gt; ai; std::iota(ai.begin(), ai.end(), 1); for(int i: ai){ std::cout\u0026lt;\u0026lt;i\u0026lt;\u0026lt;\u0026quot; \u0026quot;;//1 2 3 4 5 6 7 8 9 10 } ?? 貌似 作用不大呀 ?? 2011 十进制浮点数扩展 # 2014 C++14 第四个C++标准 # C++14旨在作为C++11的一个小扩展, 主要提供漏洞修复和小的改进. 参考资料 语言特性变更 # 泛型的lambda\n?? 这是什么玩意 ?? //C++11中, lambda函数的形参必须被声明为具体的类型 //C++14 放宽了这个要求 auto lambda = [](auto x, auto y) { return x + y; } lambda捕获部分中使用表达式\nC++11的lambda函数允许通过 [值copy 或 引用] 捕获已在外层作用域声明的变量. C++14允许lambda成员用任意的被捕获表达式初始化.意味着: 允许 capture by value-move 允许任意声明的lambda成员, 而不需要外层作用域有一个具有相应名字的变量.这称为广义捕获. 即使在闭包区域中存在相同的变量也会被新变量覆盖(只是在lambda中被覆盖). 新变量类型由他的初始化表达式推导, 类似与auto //val新变量不需要特意声明类型, 会根据auto自动推导 //lambda的返回值为1, 说明新变量val成功被初始化 auto lambda = [val = 1]{ return val; } //另一个例子 auto x = 1; //lambda捕获中, r是x(外部x)的引用; x是新变量(会在lambda中覆盖外部变量x) //此处的新变量r为1; 新变量x为10 auto f = [\u0026amp;r=x, x=x*10]{ ++ r; return r + x; } //结果是外部变量x被设置为2; f()返回12 f(); 函数返回类型推导\nC++11允许lambda函数根据return语句的表达式类型推断返回类型; C++14为一般的函数也提供了这个功能. ?? 真的完全想不通这种不易阅读的特性 到底有什么用 ?? decltype(auto)\nconst int x = 0; auto x1 = x; //x1为int类型 decltype(auto) x2 = x; //x2为const int类型 int y =0; int\u0026amp; y1 = y; auto y2 = y1; //int类型 decltype(auto) y3=y1; //int\u0026amp; int\u0026amp;\u0026amp; z =0; auto z1 = std::move(z); //int decltype(auto) z2 = std::move(z); //int\u0026amp;\u0026amp; //函数返回类型为int auto f (const int\u0026amp; i) { return i; } //函数返回类型为const int\u0026amp; decltype(auto) g (const int\u0026amp; i) { return i; } constexpr函数放宽限制\nC++11对constexpr函数做了严格的限制, 允许的语句非常少(基本就是一条return语句\u0026hellip;) C++14放宽了该限制. 允许constexpr有以下内容: 任何声明, 除了 static 或 thread_local变量 没有初始化的变量声明 条件分支语句 if \u0026amp;\u0026amp; switch 所有的循环语句, 包含range for 循环 表达式可以改变一个对象的值 需要该对象的生命期在声明为constexpr的函数内部开始, 包括对有constexpr声明的任何非const非静态成员函数的调用. 此外，C++11指出，所有被声明为constexpr的非静态成员函数也隐含声明为const（即函数不能修改*this的值） C++14中这点已经被删除，非静态成员函数可以为非const 变量模板\nC++14之前模板可以是函数模板或类模板 C++14中引入了变量模板 class对象构造优化 (聚合类的成员初始化)\nC++11中class的成员变量可以在声明的地方初始化. 但是如果构造函数中未定义该变量, 那么该class就不允许使用聚合初始化; C++14中放松了这一限制 struct Test{ int m_x; int m_y = 40; Test(int x) : m_x(x) {} }; Test t1{1}; //在C++11中是不允许的, 因为Test的构造函数Test(int x)中未初始化m_y Test t2{1}; //在C++14中是合法的. m_y会使用默认值40 二进制字面量\nC++14的数字允许使用二进制形式指定.使用前缀0b或0B. 数字分位符\nC++14引入单引号 \u0026rsquo; 作为数字分位符号, 使得数值型的字母量更好的可读性. auto integer_literal = 100'0000; auto floating_point_literal = 1.797'693'134'862'315'7E+308; auto binary_literal = 0b0100'1100'0110; auto silly_example = 1'0'0'000'00; deprecated属性\ndeprecated属性允许标记不推荐使用的实体，该实体仍然能合法使用， 但会让用户注意到使用它是不受欢迎的，并且可能会导致在编译期间输出警告消息。 deprecated可以有一个可选的字符串文字作为参数，以解释弃用的原因和/或建议替代者。 [[deprecated]] void f(); [[deprecated(\u0026quot;g() is unsafe, use h() instead\u0026quot;)]] void g(); void test(){ f(); //warnning: f()已被弃用 g(); //warnning: g() is unsafe, use h() instead } stl变更 # 共享的互斥体和锁\nC++14增加了一类共享的互斥体和相应的共享锁 起初选择的名字是std::shared_mutex，但由于后来增加了与std::timed_mutex相似的特性，std::shared_timed_mutex成为了更适合的名字 元函数的别名 关联容器中的异构查找\nC++标准库定义了四个关联容器类。 set和multiset允许用户根据一个值在容器中查找对应的的同类型的值。 map和multimap容器允许用户指定键（key）和值（value）的类型，根据键进行查找并返回对应的值。 然而，查找只能接受指定类型的参数，在map和multimap中是键的类型，而在set和multiset容器中就是值本身的类型。 C++14允许通过其他类型进行查找，只需要这个类型和实际的键类型之间可以进行比较操作。[ 这允许std::set\u0026lt;std::string\u0026gt;使用const char*，或任何可以通过operator\u0026lt; 与std::string比较的类型作为查找的参数。 为保证向后兼容性，这种异构查找只在提供给关联容器的比较器允许的情况下有效。 标准库的泛型比较器，如std::less\u0026lt;\u0026gt;与std::greater\u0026lt;\u0026gt;允许异构查找 stl自定义字面量\nC++11增加了自定义字面量的语言特性. C++14的stl中利用了这个特性 C++14 stl定义了如下字面量后缀 s 创建各种std::basic_string类型 h, min, s, ms, us, ns 创建相应的std::chrono::duration时间间隔 if, i, il 创建std::complex\u0026lt;float\u0026gt;, std::complex\u0026lt;double\u0026gt;, std::complex\u0026lt;long double\u0026gt;复数类型 这些字面量可以用于编译时的constexpr //两个s互补干扰, 表示std::basic_string的s只能对字符串字面量操作, 而表示秒的只针对数字. auto str = \u0026quot;hello world\u0026quot;s; auto dur = 60s; auto z = 99i; 通过类型寻址多元组\nC++11引入的std::tuple类型允许不同类型的值的聚合体用编译期整型常数索引。 C++14还允许使用类型代替常数索引，从多元组中获取对象。 若多元组含有多于一个这个类型的对象，将会产生一个编译错误 tuple\u0026lt;string, string, int\u0026gt; t(\u0026quot;foo\u0026quot;, \u0026quot;bar\u0026quot;, 7); int i = get\u0026lt;2\u0026gt;(t); //i = 7; C++11 int j = get\u0026lt;int\u0026gt;(t); //j = 7; C++14新增 string s = get\u0026lt;string\u0026gt;(t); //编译错误, 歧义 较小的标准库特性\nstd::make_unique可以像std::make_shared一样使用, 用于产生std::unique_str对象 std::is_finale用于识别一个class类型是否禁止被继承 std::integral_constant增加了一个返回常量值的operator() 全局std::begin/std::end函数之外, 增加了std::cbegin/std::cend函数, 用于返回常量迭代器 constant iterators 2015 文件系统 # 2015 用于并行计算的扩展 # 2015 事务性内存操作 # 2015 概念库, 用于优化编译期信息 # 2016 用于并行计算的扩展 # 2017 标准库扩展 # 2017 提供范围机制 # 2017 协程库扩展 # 2017 C++17 第五个C++标准 # C++17旨在作为大型扩展. 参考资料 ?? 新功能 ?? # static_assert无需提供出错信息 具有模板形式的模板参数允许使用typename (之前只能使用class) std::uncaught_excepitions取代std::uncaught_exception 变长参数模板的Folding运算 容器访问操作表示方法的统一化 连续迭代器 新增特殊数学函数 语言特性 # u8字面量\n//C++11的时候, u8可以修饰字符串 //C++17新增了u8可以修饰单个字符 char x = u8'x'; 使noexcept成为系统的一部分\n?? 需要再仔细的查看 ?? noexcept在C++11中首次加入, 作用是抛出异常, 取代throw ?? 为什么取代throw ?? C++17中使其成为了系统的一部分 ??什么意思?? {}列表初始化的自动推导规则\n具体详见C++11中的说明 初始化列表 //C++11中会被推导为 std::initializer_list\u0026lt;int\u0026gt; //C++17中推导为 int auto x {3}; lambda函数按值捕获this指针\nC++17之前, lambda只能按引用捕获this指针 C++17允许使用*this捕获对象的副本 class 构造函数\n?? 完全没有概念 ?? 编译时 if constexpr 构造函数lambda 内联变量 inline\n过去inline用于函数声明, 现在也可以用于变量声明, 表示函数或定义可定义多次(内容必须完全相同) 这允许在头文件中定义一个内联变量 结构化绑定\n变量定义初始化时, 允许形如auto [x,y,z] = expr; 其中expr的 元组类似的对象包括 std::tuple, std::pair, std::array等聚合结构 //例子1 using Coordinate = std::pair\u0026lt;int, int\u0026gt;; Coordinate origin() { return Coordinate{1,2}; } const auto [x, y] = origin(); //x=1; y=2 //例子2 std::unordered_map\u0026lt;std::string, int\u0026gt; mapping{ {\u0026quot;a\u0026quot;, 1}, {\u0026quot;b\u0026quot;, 2}, {\u0026quot;c\u0026quot;, 3}, }; for (const auto\u0026amp; [key, value] : mapping:){ //do something } if/switch选择语句可以带初始化\n//例子1 //之前需要放到语句块中限制锁的范围 { std::lock_guard\u0026lt;std::mutex\u0026gt; lk(mx); if (v.empty()) v.push_back(val); } //现在可以直接放到if中 if (std::lock_guard\u0026lt;std::mutex\u0026gt; lk(mx); v.empty()) { v.push_back(val); } //例子2 //更好的限制了变量的作用域 Foo gadget(args); switch (auto s = gadget.status()) { case OK: gadget.zip(); break; case Bad: throw BadFoo(s.message()); } //vs.现在 switch (Foo gadget(args); auto s = gadget.status()) { case OK: gadget.zip(); break; case Bad: throw BadFoo(s.message()); } 嵌套的namespace\n//C++17以前 namespace A{ namespace B{ namespace C{ int i; } } } //C++17简化了 namespace A::B::C{ int i; } fallthrough, nodiscard, maybe_unused特性\nC++17中新增 stl # std::variant std::optional std::any std::string_view std::filesystem std::invoke std::apply std::byte maps \u0026amp;\u0026amp; sets更优效率的移动节点 并行算法\n许多stl算法, 如copy, find和sort支持并行执行策略 2018 网络库 # 2018 并行扩展 # 2018 模块 # 2020 C++20 第五个C++标准 # C++20是一项非常大的改动. 参考资料 语言特性 # 新增关键字\nconcept requires constinit consteval co_await co_return co_yield char8_t 新增标识符\nimport module modules 模块\n优点: 没有头文件 声明实现仍然可以分离, 但非必要 可以显示指定哪些导出(类, 函数等) 不需要头文件重复引入宏 include 模块之间名称可以相同 不会冲突 模块只处理一次, 编译更快 (头文件每次引入都需要处理) 预处理宏只在模块内有效 模块引入顺序无关紧要 (头文件引入顺序不同,可能发生不同结果) //创建模块 //export导出模块; 模块的名字是cppcon export module cppcon; namespace CppCon{ auto GetWelcomeHelper() { return \u0026quot;Hello World\u0026quot;; } export auto GetWelcome() { return GetWelcomehelper(); } } //引用模块 import cppcon; int main(){ std::cout \u0026lt;\u0026lt; CppCon::GetWelcome(); } import头文件\n//隐式的将 iostream 转换为模块 //加速构建, 因为iosteam只会处理一次 //和预编译PCH具有相似的效果 ?? PCH是什么 ?? import \u0026lt;iostream\u0026gt; Ranges\nRange代表一串元素或者一串元素中的一段 意义: 简化语法, 方便使用 防止begin/end不配对 使变换/过滤等串联操作成为可能 vector\u0026lt;int\u0026gt; data{11, 22, 33}; sort(begin(data), end(data)); sort(data); //使用Ranges //View: 延迟计算, 不持有, 不改写 //Actions: 即时处理, 改写 //Algorithms: 所有接受begin/end对的算法都可以使用 //View和Ations使用管道符 | 串联 //例子1 串联view vector\u0026lt;int\u0026gt; data{1,2,3,4,5,6,7,8,9,10}; auto result = data | views::remove_if([] (int i) { return i % 2 == 1;}) | views::transform([])(int i) { return to_string(i);}); //result = {\u0026quot;2\u0026quot;,\u0026quot;4\u0026quot;,\u0026quot;6\u0026quot;,\u0026quot;8\u0026quot;,\u0026quot;10\u0026quot;}; //注意 以上操作被延迟, 只有便利result的时候才触发 //例子2 串联actions //排序然后去重 //操作会原地对data进行更改, 然后返回 vector\u0026lt;int\u0026gt; data{4, 3, 4, 1, 8, 0, 8}; vector\u0026lt;int\u0026gt; result = data| actions::sort | actions::unique; //例子3 过滤和变换 //所有的计算延迟到accumulate累加遍历的时候发生 int total = accumulate( view::ints(1) | //产生一个无限对整型数列 view::transform([] (int i) { return i * i;}) | //平方 view::take(10), //取前10个元素 0); //累加 协程\n意义: 异步I/O 延迟计算 事件驱动的程序 generator //co_wait 挂起协程, 等待其他计算完成 //co_return 从协程返回 (协程禁用return) //co_yield 弹出一个值, 挂起协程, 下一次调用继续协程的运行 //for co_await 循环体 Concepts\n?? 模板相关 ?? lambda\n需要显示捕获this变量 C++20之前 [=] 隐式捕获this C++20开始 需要显示捕获this [=, this] 模板形式的lambda表达式 lambda表达式捕获 支持打包展开 constexpr 更新 原子智能指针 Atomic\n智能指针对于数据读写并非线程安全. C++20之前, 多线程中使用智能指针, 需要使用mutex控制访问. C++20新增 atomic\u0026lt;shared_ptr\u0026lt;T\u0026gt;\u0026gt;, atomic\u0026lt;weak_ptr\u0026lt;T\u0026gt;\u0026gt; class 指定初始化\nstruct Data{ int m_x = 0; std::string m_s; }; Data d{.m_s = \u0026quot;Hellow\u0026quot;}; \u0026lt;=\u0026gt; 运算符\n三路比较运算符 //类似C的strcmp函数返回-1, 0, 1 //但实际\u0026lt;=\u0026gt;返回的并非int类型, 而是\u0026lt;compare\u0026gt;头中的对象 (a \u0026lt;=\u0026gt; b ) \u0026lt; 0 //如果a\u0026lt;b为true (a \u0026lt;=\u0026gt; b ) == 0 //如果a==b为true (a \u0026lt;=\u0026gt; b ) \u0026gt; 0 //如果a\u0026gt;b为true 范围for循环语句 支持初始化语句\nC++17 if, switch语句支持了初始化语句 C++20 新增for循环语句的支持 for (auto data = GetData(); auto\u0026amp; value : data){ //do something } 特性测试宏\n__has_cpp_attribute(fallthrough) __cpp_binary_literals __cpp_chart_t __cpp_coroutines consteval\nconstexpr函数可能编译期执行, 也可以在运行期执行; consteval只能在编译期执行 constinit\n强制指定以常量方式初始化 const char* GetStringDyn() { return \u0026quot;dynamic init\u0026quot;; } constexpr const char* GetString(bool constInit) { return constInit ? \u0026quot;constant init\u0026quot; : GetStringDyn(); } constinit const char* a = GetString(true); // ✔ constinit const char* b = GetString(false); // ❌ 用using引用enum类型\nenum class CardTypeSuit { Clubs, Diamonds, Hearts, Spades }; //C++20之前 std::string_view GetString(const CardTypeSuit cardTypeSuit) { switch (cardTypeSuit) { case CardTypeSuit::Clubs: return \u0026quot;Clubs\u0026quot;; case CardTypeSuit::Diamonds: return \u0026quot;Diamonds\u0026quot;; case CardTypeSuit::Hearts: return \u0026quot;Hearts\u0026quot;; case CardTypeSuit::Spades: return \u0026quot;Spades\u0026quot;; } } //C++20 std::string_view GetString(const CardTypeSuit cardTypeSuit) { switch (cardTypeSuit) { using enum CardTypeSuit; // 这里 case Clubs: return \u0026quot;Clubs\u0026quot;; case Diamonds: return \u0026quot;Diamonds\u0026quot;; case Hearts: return \u0026quot;Hearts\u0026quot;; case Spades: return \u0026quot;Spades\u0026quot;; } } stl # choron 增加日历和时区的支持 std::span\n某段连续数据的视图 不持有数据, 不分配和销毁数据 copy非常快 不支持数据跨步 可通过运行期确定长度, 也可编译期确定长度 特性测试宏\n__cpp_lib_conceps __cpp_lib_ranges __cpp_lib_scoped_lock \u0026lt;version\u0026gt;\n包含c++标准库版本, 发布日期, 版权证书, 特性宏等 std::format\n?? C++ 也有format了 \u0026hellip;. ?? 设计原则 # C++设计成直接的和广泛的支援多种程式设计风格（过程化程式设计、数据抽象、物件导向程式设计、泛型程式设计）。 C++设计成给程式设计者更多的选择，即使可能导致程式设计者选择错误。 C++设计成尽可能与C相容，借此提供一个从C到C++的平滑过渡。 C++避免平台限定或没有普遍用途的特性。 C++不使用会带来额外开销的特性。 C++设计成无需复杂的程式设计环境。 待学习 # stl C++中很重要的功能, 必须要尽快了解常用的 新的概念 C++20中增加了很多新概念 新的语言特性 只需要学习常用的特性, 有些特性是为了配合模板而来的, 暂时不需要学习 其他常用的库 比如网络库Asio, 格式库protobuf 模板 模板的作用 更多的是用在stl的编写上, 日常开发使用的比较少, 可以暂时先不学习 "},{"id":9,"href":"/docs/prog_debug/gdb/","title":"gdb","section":"prog debug","content":" process view # memory # info process mapping thread # PCB | TCB # 调试命令 # bt (backtrace) 查看函数栈 bt full 查看更加详细的信息 f (frame) 查看栈信息 f 0 表示查看栈顶; f n查看第n+1层 down 查看下一栈 up 查看上一栈 i (info) i program 查看当前进程运行信息 i threads 查看当前线程运行信息 i f 查看当前栈所在层的具体信息 i args 当前函数的参数名及其值 i locals 当前函数中所有局部变量及其值 i catch 异常处理信息 i b 查看断点 i proc mappings 查看程序的内存分布 i reg 查看寄存器 l (list) 查看源码 p (print) 查看变量的值 调试方法 # 以调试core文件为例 gdb ./a.out core bt 先查看堆栈 如果2没有有用信息, bt full 查看更加详细的堆栈 有时候遇到一些奇怪问题, 可以尝试make clean 整个工程, 再重新生成 gcore # gcore #进程pid 执行命令后，会在当前目录下生成一个该进程的core dump文件了 Q \u0026amp; A # gdb 需不需要可视化? "},{"id":10,"href":"/docs/prog_compile/autotools/","title":"autotools","section":"prog compile","content":"初学autotools 为什么需要autotools # Makefile固然可以帮助make完成它的使命，但要承认的是，编写Makefile确实不是一件轻松的事，尤其对于一个较大的项目而言更是如此。 那么，有没有一种轻松的手段生成Makefile而同时又能让我们享受make的优越性呢？ 本节要讲autotools系列工具正是为此而设的， autotools只需用户输入简单的目标文件、依赖文件、文件目录等就可以轻松地生成Makefile autotools还可以完成系统配置信息的收集，从而可以方便地处理各种移植性的问题。 也正是基于此，现在Linux上的软件开发一般都用autotools来制作Makefile。 什么是autotools # 综上所述, autotools主要就是利用各个工具的脚本文件以生成最后的Makefile. autotools并不是一个工具, 而是一系列工具合集. 主要有: autoscan aclocal autoconf autoheader automake autotools怎么使用 # autotools安装 # mac下包管理习惯使用homebrew 安装autoscan \u0026amp;\u0026amp; autoconf brew install autoconf 安装aclocal \u0026amp;\u0026amp; automake \u0026amp;\u0026amp; autoheader brew install automake autotools # 在代码当前目录下执行autoscan, 生成configure.scan. configure.scan重命名为configure.ac. 并做以下修改: 初始化AC_INIT 初始化AM_INIT_AUTOMAKE 设定AC_CONFIG_FILES # -*- Autoconf -*- # Process this file with autoconf to produce a configure script. AC_PREREQ([2.69]) #1. _初始化AC_INIT 和 初始化AM_INIT_AUTOMAKE_ AC_INIT(hello,1.0,377133665@qq.com) AM_INIT_AUTOMAKE(hello,1.0) #AC_CONFIG_SCRDIR来侦测源码文件是否存在, 来确定源码目录的有效性 AC_CONFIG_SRCDIR([main.cpp]) AC_CONFIG_HEADERS([config.h]) # Checks for programs. AC_PROG_CXX # Checks for libraries. # Checks for header files. AC_CHECK_HEADERS([stdlib.h unistd.h]) # Checks for typedefs, structures, and compiler characteristics. # Checks for library functions. #2. _生成makefile_ AC_CONFIG_FILES([Makefile]) AC_OUTPUT 执行aclocal命令. 扫描configure.ac文件生成aclocal.m4文件. 该文件主要处理本地宏定义. 它根据已经安装的宏、用户定义宏和 acinclude.m4 文件中的宏将 configure.ac 文件需要的宏集中定义到文件 aclocal.m4 中. 执行autoconf.这个命令将 configure.ac 文件中的宏展开，生成 configure 脚本。 这个过程要用到aclocal.m4中定义的宏. 如果configure.ac宏定义改变了, 需要重新执行aclocal命令 执行autoheader.该命令生成 config.h.in 文件。该命令通常会从 \u0026ldquo;acconfig.h” 文件中复制用户附加的符号定义。该例子中没有附加的符号定义, 所以不需要创建 \u0026ldquo;acconfig.h” 文件。 创建Makefile.am文件.Automake工具会根据 configure.in 中的参量把 Makefile.am 转换成 Makefile.in 文件。最终通过Makefile.in生成Makefile文件，所以Makefile.am这个文件非常重要，定义了一些生成Makefile的规则 AUTOMARK_OPTIONS = foreign bin_PROGRAMS = hello hello_SOURCES = main.cpp 执行automake \u0026ndash;add-missing命令。该命令生成 Makefile.in 文件。使用选项 \u0026ldquo;\u0026ndash;add-missing\u0026rdquo; 可以让 Automake 自动添加一些必需的脚本文件。如果发现一些文件不存在，可以通过手工 touch命令创建 执行./configure。大部分linux软件安装都先需要执行./congigure，然后执行make和make install命令。 ./congigure主要把 Makefile.in 变成最终的 Makefile 文件。configure会把一些配置参数配置到Makefile文件里面。 执行make mac系统gcc与g++默认下都是clang的别名. 所以有可能会在此处产生错误. 实际上并没有发现不同 执行make install autotools流程图 # dot流程图源码 推荐文章 # autotools使用详解 Makefile中文手册 "},{"id":11,"href":"/docs/emacs/lisp/eshell/","title":"eshell","section":"常用扩展","content":"emacs自带的shell解释器, 正在尝试使用, 期望可以取代其他shell解析器(比如bash, zsh) 官方文档 优势: emacs自带, 不同os环境统一 语法支持tramp cd /method:user@host#22:/path\reshell \u0026amp;\u0026amp; elisp # defun为 eshell/xxx的函数, 可以在eshell中直接调用xxx eshell script # 官方不建议在eshell中写shell脚本, eshell脚本也是以.sh结尾 变量赋值 # eshell 脚本中使用elisp语法给变量赋值 (setq remote_temp \u0026quot;/ssh:clay@192.168.0.97:~/temp\u0026quot;)\r变量使用 $ # 基本与shell相同, 具体可以详见官方说明 eshell/rm -r $remote_temp\r"},{"id":12,"href":"/docs/emacs/org/gtd/","title":"gtd","section":"org \u0026\u0026 gtd","content":" 为什么要用GTD # 每天或每周需要处理的事情非常之多, 小到晚上要洗衣服, 大到明天项目交付. 这些事情如果都存储在脑中, 轻则焦虑不堪, 重则脑子爆炸. 而且脑中一旦塞满了这类事情, 非常不利于思考. 大脑应该是拿来思考的, 而不是用来存储的. 假设一种情形, 大脑只用来思考, 而存储则放在大脑之外, 那么我们就不必因当下之外的事情而焦虑, 能够更专一的处理当下的问题. 同时, 如果外在存储能够提醒我们何时该思考何问题, 那么我们也不会因错过了某事而悔恨, 比如女友生日. 而这也是GTD的目的所在, 大脑只用来思考, 存储在脑外. GTD是什么 # 人生5楼 # 了解GTD之前, 必须了解 人生5楼. 楼数 功能 说明 备注 5楼 人生规划 4楼 3年目标 3楼 1年目标 2楼 职责范围 1楼 项目 GTD管理 地面 行动清单 归属1楼 GTD管理 把人生(或部分人生)比喻成一座大厦, 1楼是我们当下要做的事情, 2楼是我们的职责范围, 3楼是我们1年后的样子, 4楼是我们3年后的样子, 5楼是我们人生(10年, 20年或一辈子)的规划. 我们的人生是高层决定了低层 比如, 如果想成为计算机专家(5楼), 那么3年后要先成为工程师(4楼), 1年后要先成为程序员(3楼), 为了要成为程序员, 也许我们需要去报班学习(2楼 职责为学习),或者成为程序员助理(2楼 职责为搬砖), 而1楼则是我们当下要确确实实需要处理的事情, 比如看书, 工作, 交流等, 所有一切能对我们有提升的事情. 大厦是由低到高建造的 千里之行, 始于足下. 1楼的行为直接决定了能否达到后面的楼层. 大厦最难的地方不在于 _实现_ 5楼的规划, 而在于 _制定_ 5楼的规划. 不过这也正是人生的魅力所在吧. GTD是什么 # GTD全名Getting things done, 它只是一种思想, 所能管理的是大厦的1楼. 它的核心目的: 事物存储在脑外, 大脑用来思考. GTD的工作流程(算法)甚至文件(结构)都是可以自定义的. 适合的才是最好的. 吐槽: 中文译本《Getting things done》满篇废话. GTD怎么实现 # GTD的实现方式非常之多, 有很多软件工具. 最喜欢的还是org-mode. "},{"id":13,"href":"/docs/tool/k8s/","title":"k8s","section":"tools","content":"kubernetes, 简称k8s k8s概念 # namespace 在所有抽象层之前 kubectl delete namespace \u0026lt;namespace-name\u0026gt; 删除namespace会删除namespace下面所有的资源, 比如deployment,pods,svc等等 -n xx \u0026ndash; 使用xx命名空间 \u0026ndash;all-namespaces \u0026ndash; 显示所有的命名空间 kubectl get namespaces kubectl delete pod \u0026lt;pod-name\u0026gt; --force -n xx 各种概念 cluster 即k8s集群 master 控制节点 node 工作节点 Namespace CustomResourceDefinition 自定义类型资源crd service deployment \u0026ndash; rc \u0026ndash; pods ingress kubernetes 创建集群 # 安装 # # 大多数 Pod 网络都需要 CNI_VERSION=\u0026quot;v0.8.2\u0026quot; ARCH=\u0026quot;amd64\u0026quot; sudo mkdir -p /opt/cni/bin curl -L \u0026quot;https://github.com/containernetworking/plugins/releases/download/${CNI_VERSION}/cni-plugins-linux-${ARCH}-${CNI_VERSION}.tgz\u0026quot; | sudo tar -C /opt/cni/bin -xz # kubeadm/kubelet 容器运行时接口（CRI）所需 DOWNLOAD_DIR=/usr/local/bin sudo mkdir -p $DOWNLOAD_DIR CRICTL_VERSION=\u0026quot;v1.17.0\u0026quot; ARCH=\u0026quot;amd64\u0026quot; curl -L \u0026quot;https://github.com/kubernetes-sigs/cri-tools/releases/download/${CRICTL_VERSION}/crictl-${CRICTL_VERSION}-linux-${ARCH}.tar.gz\u0026quot; | sudo tar -C $DOWNLOAD_DIR -xz #RELEASE=\u0026quot;$(curl -sSL https://dl.k8s.io/release/stable.txt)\u0026quot; RELEASE=v1.22.3 ARCH=\u0026quot;amd64\u0026quot; cd $DOWNLOAD_DIR sudo curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/${RELEASE}/bin/linux/${ARCH}/{kubeadm,kubelet,kubectl} sudo chmod +x {kubeadm,kubelet,kubectl} # 添加kubelet系统服务 RELEASE_VERSION=\u0026quot;v0.4.0\u0026quot; curl -sSL \u0026quot;https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubelet/lib/systemd/system/kubelet.service\u0026quot; | sed \u0026quot;s:/usr/bin:${DOWNLOAD_DIR}:g\u0026quot; | sudo tee /etc/systemd/system/kubelet.service sudo mkdir -p /etc/systemd/system/kubelet.service.d curl -sSL \u0026quot;https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubeadm/10-kubeadm.conf\u0026quot; | sed \u0026quot;s:/usr/bin:${DOWNLOAD_DIR}:g\u0026quot; | sudo tee /etc/systemd/system/kubelet.service.d/10-kubeadm.conf # 激活并启动kubelet systemctl enable --now kubelet 环境配置 # # 加载模块 sudo modprobe br_netfilter # cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system 控制平面节点 协议\t方向\t端口范围\t作用\t使用者 TCP\t入站\t6443\tKubernetes API 服务器\t所有组件 TCP\t入站\t2379-2380\tetcd 服务器客户端 API\tkube-apiserver, etcd TCP\t入站\t10250\tKubelet API\tkubelet 自身、控制平面组件 TCP\t入站\t10251\tkube-scheduler\tkube-scheduler 自身 TCP\t入站\t10252\tkube-controller-manager\tkube-controller-manager 自身 工作节点 协议\t方向\t端口范围\t作用\t使用者 TCP\t入站\t10250\tKubelet API\tkubelet 自身、控制平面组件 TCP\t入站\t30000-32767\tNodePort 服务†\t所有组件 # 查看需要下载哪些 kubeadm config images list # 替换为mirror-images kubeadm config images list |grep -v 'coredns' |sed -e 's/^/docker pull /g' -e 's#k8s.gcr.io#docker.io/clay2019#g' |sh -x kubeadm config images list |grep 'coredns' |sed -e 's/^/docker pull /g' -e 's#k8s.gcr.io#docker.io#g' -e 's#:v#:#g' |sh -x kubeadm config images list |grep -v 'coredns' |sed -e 's/^/docker pull /g' -e 's#k8s.gcr.io#docker.io/clay2019#g' |sh -x docker images |grep clay2019 |awk '{print \u0026quot;docker tag \u0026quot;,$1\u0026quot;:\u0026quot;$2,$1\u0026quot;:\u0026quot;$2}' |sed -e 's#clay2019#k8s.gcr.io#2' |sh -x docker images |grep clay2019 |awk '{print \u0026quot;docker rmi \u0026quot;, $1\u0026quot;:\u0026quot;$2}' |sh -x kubeadm init 配置 # kubeadm的配置文件 kubeadm --config中指定的那个, 会覆盖kubelet等组件的默认行为!!! # 查看kubeadm init-defaults kubeadm config print init-defaults --component-configs KubeProxyConfiguration,KubeletConfiguration \u0026gt; kubeadm.yaml # 有时候 kubeadm init 与 kubeadm init --config kubeadm.yaml 使用的镜像并不相同 # 比如我遇到的kubeadm init使用的是v1.22.3, 但是其init-defaults输出的kubeadm.yaml中的images为v1.22.0!! 需要注意 配置完成之后, 使用 kubeadm init \u0026ndash;config xx.yaml来创建master 也可以使用kubeadm init默认安装 如果kubelet没有启动, 修改下kubelet的配置文件, 重新启动即可 网络插件安装 # kubectl get nodes中发现Node的STATUS为NotReady, 需要安装网络插件. 如果没有安装网络插件, pods/coredns的状态为pending 这里选的是calico, 详见calico安装 kubernetes 配置集群的 # 主要配置deployment 与 service deployment会创建rc, rc会创建pod # 1.写deployment kubectl create deployment alpine --image=alpine # 2.执行 kubectl expose deployment/alpine --name=apine-svc --port=80 --type=NodePort # 3.查看是否成功 kubectl get pods #视情况 加namespace # 4.如果报错, 查看具体错误 kubectl describe pods \u0026lt;pod-name\u0026gt; 工具 - kubeadm # 集群创建工具 kubeadm init kubeadm reset 需要重新init的时候, 先执行reset kubeadm config print init-default kubeadm config print init-defaults --component-configs KubeProxyConfiguration,KubeletConfiguration \u0026gt; kubeadm.yaml 工具 - kubectl # 集群管理工具 使用kubectl必须配置kubeconfig文件 放到~/.kube/config中 或者 使用 --kubeconfig来指定 ## kubectl 在 $HOME/.kube 目录中查找一个名为 config 的配置文件 ## 你可以通过设置 KUBECONFIG 环境变量或设置 --kubeconfig 参数来指定其它 kubeconfig 文件 cp -i /etc/kubernetes/admin.conf ~/.kube/config # 检查是否正常 kubectl cluster-info 常用命令 # kubectl cmd type cmd: get describe type: node namespace deployment pod 常用命令2 # # 转发monitoring/svc=prometheus-k8s的端口9090到 localhost的9000 # 如果不写9000:9090, 只写9090, 表示转发svc的9090到 localhost的9090 kubectl -n monitoring port-forward svc/prometheus-k8s 9000:9090 # 其输出如下 Forwarding from 127.0.0.1:9000 -\u0026gt; 9090 Forwarding from [::1]:9000 -\u0026gt; 9090 # 看上面的输出, 我们知道, 这个端口转发只对localhost生效, 外部网络无法访问 # 如果想从外部可以访问, 我们可以使用nginx反向代理, 转发remote-port到9000 # ingress同样的道理 工具 - kubelet # work-node 运行需要, master不建议运行 配置文件在/var/lib/kubelet/config.yaml 如果遇到cgroup错误, 可以修改\u0026ndash;cgroup-driver=cgroupfs, 然后重新启动kubelet systemctl daemon-reload systemctl enable kubelet systemctl status kubelet root@ubt:/home/dev_wangchengqing# kubectl get nodes NAME STATUS ROLES AGE VERSION ubt NotReady \u0026lt;none\u0026gt; 3h21m v1.22.3 # NotReady 是因为还没有部署网络插件 插件 - calico # # 1.node节点数小于50的配置文件; 如果node节点数大于50, 请参考官网 curl https://docs.projectcalico.org/manifests/calico.yaml -O # 2.如果本地地址在192.168.0.0/16, 需要设置calico的ip地址 # 修改 CALICO_IPV4POOL_CIDR的value的值即可 # 3.执行插件的安装 kubectl apply -f calico.yaml # 4. 确认是否安装成功 kubectl get pods --all-namespaces # coredns 会在网络插件安装成功之后启动 Pending -\u0026gt; Running # 同时kubectl get nodes中的 STATUS会变为Ready 插件 - ingress-nginx # # 下载yaml curl -L https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.0.4/deploy/static/provider/cloud/deploy.yaml \u0026gt; ingress-nginx.yaml # 修改yaml中的mirror sed -i 's#k8s.gcr.io/ingress-nginx#docker.io/clay2019#g' ingress-nginx.yaml # 部署ingress-nginx kubectl apply -f ${ingress-n-yaml} # 查看是否安装成功 kubectl get pods -n ingress-nginx # 1. 查看已有的ingress kubectl get ingress # 不确定是否有用的时候, 可以 kubectl describe ingress \u0026lt;ingress-name\u0026gt; # 2. 编写ingress.yaml ## 编写的时候注意 backend的命名空间 # 3. apply kubectl apply -f ingress.yaml # 4. check 查看是否正常 kubectl describe ingress \u0026lt;ingress-name\u0026gt; apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: test namespace: monitoring # 需要增加annotations字段的内容, 否则会提示404, 不知道为什么 annotations: ingress.kubernetes.io/rewrite-target: / kubernetes.io/ingress.class: nginx spec: rules: - http: paths: - path: / pathType: Prefix backend: service: name: prometheus-k8s port: number: 9090 # 当ingress-controller与ingress-rule正确部署之后 # 查看一下ingess-controller命名空间下的svc, 获取到port kubectl get svr -n ingress-nginx # 输出如下 root@ubt:/home/dev_wangchengqing# kubectl get svc -n ingress-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.108.147.62 \u0026lt;pending\u0026gt; 80:31468/TCP,443:31055/TCP 61m ingress-nginx-controller-admission ClusterIP 10.107.83.233 \u0026lt;none\u0026gt; 443/TCP 61m # A为ingress-controller所在的机器的ip地址 # 从输出中可以看到, ingress-controller的svc把自身80端口映射到了31468端口 (31468端口由kube-proxy监听) # 因此我们访问A:31468, 会访问到ingress-controller的10.108.147.62:80 # 然后ingress-controller 会根据 ingress-rule把我们的转发, 下发到不同的backends service 命名空间问题 # Now, Ingress Controller can be deployed in any namespace and is, in fact, usually deployed in a namespace separate from your app services. It can out-of-the-box see Ingress rules in all namespaces in the cluster and will pick them up. The Ingress rules, however, must reside in the namespace where the app that they configure reside. ingress-controller常常有独立的namespace. 其可以获取所有namespaces中的ingress-rule ingress-rule, 需要与backend保持同一个namespace TODO ingress-rule配置问题 # apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: test namespace: monitoring annotations: kubernetes.io/ingress.class: nginx nginx.ingress.kubernetes.io/rewrite-target: / spec: rules: - http: paths: - path: / pathType: Prefix backend: service: name: grafana port: number: 3000 如果path配置了/app, curl ip:port/app的时候确实可以拉取到\u0026lt;herf/\u0026gt; 但是进不去 如果path配置了/ , crul ip:port 的时候就是正常的 猜测原因 当配置为/app的时候, 访问ip:port/app时候, 会被重定向为 backend:port/xxx xxx一般为backend service对外提供的, 比如 prometheus的为http://mytest.com/login 这时候url在client被修改为ip:port/login 但是在ingress-rule中并没有对ip:port/login的处理规则, 因此提示404 解决方法 暂时回避了该问题, 使用多个host 取代 \u0026lt;单host+ 多path\u0026gt;的方式 apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: test namespace: monitoring annotations: kubernetes.io/ingress.class: nginx nginx.ingress.kubernetes.io/rewrite-target: / spec: rules: - host: g.mytest.com http: paths: - path: / pathType: Prefix backend: service: name: grafana port: number: 3000 - host: p.mytest.com http: paths: - path: / pathType: Prefix backend: service: name: prometheus-k8s port: number: 9090 监控 # 使用grafana + prometheus来监控k8s 使用kube-prometheus来配置监控系统 安装 # 替换被墙的镜像的源 *-deployment.yaml中搜索image关键字, 可以看到需要下载那些镜像 具体的文件有 blackbox-exporter-deployment.yaml grafana-deployment.yaml kube-state-metrics-deployment.yaml 包含k8s.gcr.io中的镜像, 需要提前替换 prometheus-adapter-deployment.yaml 包含k8s.gcr.io中的镜像, 需要提前替换 prometheus-prometheus.yaml prometheus镜像 修改kubelet configuration cat /var/lib/kubelet/config.yaml查看 set config.yaml authentication.webhook.enabled to true. 或者 kubelet \u0026ndash;authentication-token-webhook=true set config.yaml authorization.mode to Webhook. 或者 kubelet \u0026ndash;authorization-mode=Webhook kubectl create -f manifests/setup 等待下面的镜像下载完成 quay.io/brancz/kube-rbac-proxy quay.io/prometheus-operator/prometheus-operator until kubectl get servicemonitors \u0026ndash;all-namespaces ; do date; sleep 1; echo \u0026ldquo;\u0026rdquo;; done 官方该命令只是确保 kubectl create -f manifests/setup执行完毕, 没有实际意义 kubectl create -f manifests/ 查看images镜像 和 kubectl get pods -n monitoring查看安装进度 卸载kube-prometheus kubectl delete --ignore-not-found=true -f manifests/ -f manifests/setup # 对于某些无法卸载的, 可以使用强制卸载 kubectl delete pod -n monitoring \u0026lt;pod-name\u0026gt; --force grafana dashboard配置 # 使用kube-prometheus安装完成之后, 默认的dashboards在defalut目录下, 包含了alertmanager, kubenets,node-export, prometheus等各种dashboard信息, 以及足够使用 报警配置 # kubernetes 错误排查 # 首先确认master节点是否安装成功 # 查看kube-apiserver, kube-controller-manager, kube-scheduler, etcd, pause服务 #kubectl get pods -n kube-system # -n表示namespace kubectl get pods --all-namespaces # 查看所有namespace的pods信息 # coredns为pending是正常的, 其在等待CNI网络插件 再确认node节点是否成功 kubectl get nodes kubectl get nodes -o wide #获取更详细信息 # Node状态为NotReady是正常的, 其在等待CNI网络插件 Q\u0026amp;A # node的状态显示为NotReady # kubectl get nodes # 显示STATUS为notReady # 1. 先查看node上的kubelet是否启动 systemctl status kubelet #如果未启动或者报错, 重启kubelet, systemctl restart kubelet # 2. 再看网络插件(CNI插件)是否安装 kubectl get pods --all-namespaces kubelet 找不到node journalctl -xeu kubelet Nov 05 17:22:16 ubt kubelet[775493]: E1105 17:22:16.246230 775493 kubelet.go:2412] \u0026quot;Error getting node\u0026quot; err=\u0026quot;node \\\u0026quot;node\\\u0026quot; not found\u0026quot; # kubeadm init --config kubeadm.yaml的 kubeadm.yaml中修改nodeRegistration.name为 执行机的hostname nodeRegistration: criSocket: /var/run/dockershim.sock imagePullPolicy: IfNotPresent name: k8s-m1 # 修改为执行节点的hostname，不然会提示找不到node taints: null localAPIEndpoint: advertiseAddress: 1.2.3.4 #修改为master机器的ip bindPort: 6443 kubelet 提示cgroup错误 # kubeadm init --config kubeadm.yaml的 kubeadm.yaml中修改nodeRegistration.name为 执行机的hostname # cgroupDriver: systemd -- 这里暂时不知道什么意思, 修改为cgroupfs cgroupDriver: cgroupfs pod启动失败: had taint {node-role.kubernetes.io/master: }, that the pod didn\u0026rsquo;t tolerate. root@ubt:/home/dev_wangchengqing# kubectl describe pods alpine-6b967c77f7-9rvv2 Name: alpine-6b967c77f7-9rvv2 Namespace: default Priority: 0 Node: \u0026lt;none\u0026gt; Labels: app=alpine pod-template-hash=6b967c77f7 Annotations: \u0026lt;none\u0026gt; Status: Pending IP: IPs: \u0026lt;none\u0026gt; Controlled By: ReplicaSet/alpine-6b967c77f7 Containers: alpine: Image: alpine Port: \u0026lt;none\u0026gt; Host Port: \u0026lt;none\u0026gt; Environment: \u0026lt;none\u0026gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-kwqhc (ro) Conditions: Type Status PodScheduled False Volumes: kube-api-access-kwqhc: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: \u0026lt;nil\u0026gt; DownwardAPI: true QoS Class: BestEffort Node-Selectors: \u0026lt;none\u0026gt; Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 29s (x3 over 2m51s) default-scheduler 0/1 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn't tolerate. # 因为 master 节点同时当 node 节点用，需要把 master 标签和污点去掉，默认 master 无法调度 # 去除master标签 kubectl label node ubt node-role.kubernetes.io/master- # 去除污点(无法调用schedule) kubectl taint node ubt node-role.kubernetes.io/master:NoSchedule- ingress-nginx提示404 确定ingress-controler启动 kubectl get svc -n ingress-nginx 确定ingress-rule配置正确 kubectl describe ingress -n ingress-nginx \u0026lt;ingress-name\u0026gt; 重点查看annotations的配置 必须配置kubernetes.io/ingress.class: nginx 必须配置ingress.kubernetes.io/rewrite-target: / 确定访问的方式正确 确定backend的pod-ip:port可以访问 此处的port为backend自己的port(即backend所在的svc的port, backend pod是没有端口的?? TODONOW待确定) 确定backend的svc-ip:port可以访问 此处的port为backend自己的port 确定ingress-nginx的pod-ip:port可以访问 此处的port为ingress-nginxd的port 确定ingress-nginx的svc-ip:port可以访问 此处的port为ingress-nginx的port 确定本地 localhost:port 可以访问 需要添加http标志, ingress-controler是对http的转发 此处的port为ingress-nginx映射的port 比如下方的话, 该port就是31468 root@ubt:/home/dev_wangchengqing# kubectl get svc -n ingress-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.108.147.62 \u0026lt;pending\u0026gt; 80:31468/TCP,443:31055/TCP 22h ingress-nginx-controller-admission ClusterIP 10.107.83.233 \u0026lt;none\u0026gt; 443/TCP 22h 确定网络内其他主机可以访问 A-ip:port A-ip是ingress-nginx所在的机器的ip port是ingress-nginx隐射出来的port ingress-nginx svc 一直pending root@ubt:/home/dev_wangchengqing# kubectl get svc -n ingress-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.108.147.62 \u0026lt;pending\u0026gt; 80:31468/TCP,443:31055/TCP 23h ingress-nginx-controller-admission ClusterIP 10.107.83.233 \u0026lt;none\u0026gt; 443/TCP 23h # 1. 确认所在环境是否支持LB(LoadBalancer), 本地以及大部分云服务器商 都不支持 # 如果是使用ingress-controller, 使用NodePort更好 # 2. 确认ingress-nginx/pod是否正常 pod处于ImagePullBackOff状态 kubectl get pods -n monitoring # 通过下面的命令查看是哪个镜像没有拉取到, 然后使用mirror-image拉取即可 kubectl describe pods -n monitoring \u0026lt;pod-name\u0026gt; pod处于pending状态 kubectl get pods -n monitoring # 先查看pod状态 kubectl describe pods -n \u0026lt;pod-name\u0026gt; Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 134m default-scheduler 0/1 nodes are available: 1 Insufficient cpu. # 查看node状态 kubectl describe nodes Allocated resources: (Total limits may be over 100 percent, i.e., overcommitted.) Resource Requests Limits -------- -------- ------ cpu 1906m (95%) 1760m (88%) memory 1580Mi (41%) 2080Mi (54%) ephemeral-storage 0 (0%) 0 (0%) hugepages-1Gi 0 (0%) 0 (0%) hugepages-2Mi 0 (0%) 0 (0%) Events: \u0026lt;none\u0026gt; # 通过输出可以看到, cpu已经被占用到95%了, 所以导致有的pod无法启动, 对于这种情况, 可以通过增加node节点来解决 # k8s实际是对资源的管理, 资源包括cpu, 内存等等 "},{"id":14,"href":"/docs/os/socket/asio/","title":"asio","section":"socket","content":" 参考文档 # https://mmoaay.gitbooks.io/boost-asio-cpp-network-programming-chinese/content/ http://blog.jqian.net/post/boost-asio.html https://www.limerence2017.com/2023/06/07/asio20/ "},{"id":15,"href":"/docs/prog_language/c++/stl/","title":"C \u0026\u0026 C++ 常见库","section":"c++","content":"C++ 常见库 \u0026lt;format\u0026gt; # 用法: 主要使用std::format() 意义: std::format之前, C++格式化字符要么使用C的format, 要么使用std::iostream C的format非类型安全; std::iostream效率低下 而std::fromat类型安全, 效率也高 备注: C++20中首次加入 template\u0026lt;typename... Args\u0026gt; std::string fromat(string_view fmt, const Args\u0026amp;... args); //例子1 //format()返回类型或值的字符串表示形式 //{}作为类型安全的占位符 string who{\u0026quot;lilei\u0026quot;}; int val{12}; double pi{std::numbers::pi}; format(\u0026quot;Hello, {}!\\n\u0026quot;, who); //Hello, lilei! format(\u0026quot;Val: {}\\n\u0026quot;, who); //Val: 12 format(\u0026quot;v: {}\\n\u0026quot;, who); //v: 3.141592652589793 //例子2 //左对齐\u0026lt;, 右对齐\u0026gt;, 中心对齐^ //{:.\u0026lt;10} 左对齐, 10占位, 不足使用.代替 //.是填充字符 //10表示占位大小 format(\u0026quot;{:.\u0026lt;10}\u0026quot;, 12); //12........ format(\u0026quot;{:.\u0026gt;10}\u0026quot;, 12); //........12 format(\u0026quot;{:.^10}\u0026quot;, 12); //....12.... //例子3 //设置数值的精读 format(\u0026quot;{:.5}\u0026quot;, std::number::pi); //3.1416 * # 下面的都是待整理 # * # 转换函数 # c++11 支持 std::to_string(XX) XX 为int, short, long, longlong数值类型 std::stoi() 同类型的有std::stol(), std::stoll() 文件操作: fstream类 # C++类, 头文件: #include \u0026lt;fstream\u0026gt; 流程函数 构造fstream对象 fstream file; 打开文件 file.open(file_name, mode) mode: fstream::out 写: 内存-\u0026gt;文件 fstream::in 读: 文件-\u0026gt;内存 当带有此模式的时候, 会默认认为文件存在, 即使文件不存在, 也不会创建文件; 所以对于需要创建文件的场景, 应该不带此mode 读文件 file \u0026gt;\u0026gt; string file_val \u0026gt;\u0026gt; 遇到 空格 \\n \\r \\t时候停止 \u0026ndash; 待确认TODONOW file.get(char ch) 每次读取一个字符 getline(file, string \u0026amp;file_val) 读取一行, 遇到\\n停止 file.read(char*buf, length) 在读指针位置读取length长度到buf中, 一般用于二进制文件 写文件 file \u0026lt;\u0026lt; file_val 待确认TODONOW file.put(ch) 写入一个字符 file.write(char*buf, length) 在写指针位置写入length长度的buf, 一般用户二进制文件 关闭文件 file.close 读写指针函数 获得读写指针位置 TODONOW 待确认 设置读写指针函数 读: seekg(postion) //postion绝对位置 一般用户文本文件 读: seekg(offset, ios::beg|ios::end::ios::cur) //offset相对位置 一般用户二进制文件, 最好勿在文本文件中使用 写: seekp(positon) 一般用户文本文件 写: seekp(offset, ios::beg|ios::end|ios::cur) 一般用户二进制文件, 最好勿在文本文件中使用 fstream状态函数 if(file) 检验流是否有效 这个需要重点查看下, 什么时候流会失效 已知: file.eof()时候, file则会变为无效 file.is_open() 流是否打开了文件 file.eof() 是否到了文件尾 file.clear() TODONOW 这个也需要再看下 如果file.eof(), 调用clear可以重置标志; 重置标识后, file重新变为有效流 字符串: string类 # 构造 比较 查找 插入 删除 curses使用 # 官方地址: http://www.tldp.org/HOWTO/NCURSES-Programming-HOWTO/windows.html * # FILE # FILE是C的文件操作 \u0026ndash; C++的为fstream 问: 为什么有了fstream 还需要FILE? 答: 很多系统函数,都是对C的支持, 比如popen()函数等 fopen fread fwrite fclose * # C++ 与 shell的互相调用,传参,获取运行输出 # 左值, 右值, 左值引用, 右值引用 # 左值 lvalue(loactor value) \u0026ndash; 地址 右值 rvalue(read value) \u0026ndash; value lvalue 是“loactor value”的缩写，可意为存储在内存中、有明确存储地址（可寻址）的数 rvalue 译为 \u0026quot;read value\u0026quot;，指的是那些可以提供数据值的数据（不一定可以寻址，例如存储于寄存器中的数据） 有名称的, 可以获取到存储地址的 变量或表达式为左值, 其余为右值 引用 \u0026amp; \u0026ndash; 只能操作左值, 称为左值引用 \u0026amp;\u0026amp; \u0026ndash; 只能操作右值,称为右值引用 std::move(arg) \u0026ndash; 可以把左值引用转换为右值引用 左值引用, 对于类来说, 会使用copy 构造函数 右值引用, 对于类来说, 会使用移动构造函数 "},{"id":16,"href":"/docs/prog_debug/valgrind/","title":"valgrind","section":"prog debug","content":"程序检测工具 valgrind # 程序性能查看工具,号称程序员的瑞士军刀 可以查看内存信息, 函数调用, cache信息等等 "},{"id":17,"href":"/docs/os/mac/","title":"mac","section":"os","content":"mac 记录 mac系统怎么样 # 之前是为了学习linux命令行, 后来是开发环境使用到了xcode, 现在是emacs+alfred. mac是一款很稳定的系统, 但是稳定的代价是, 对于大部分游戏都不支持. 所以如果有游戏需求, 非常不建议使用mac. 17年开始使用mac, 缺点很明显, 对游戏的支持差. 优点也不少: 稳定 广告少! 广告少! 广告少! 命令行学习使用方便 原生软件xcode alfred mac初步整理 # 笔者有严重的强迫症, 新上手的东西必须整理一遍才去使用. 习惯性由大到小, 由外而内的整理方式. os系统选择 # 不是最新的os系统就是最好的!!! 应该根据不同的mac机型选择不同的os 比如mbp2017 intel处理器可以选择Mojave 界面的整理 # launchpad图标大小整理 每一列图标数量 defaults write com.apple.dock springboard-rows -int 7 每一行图标数量 defaults write com.apple.dock springboard-columns -int 7 重启Launchpad defaults write com.apple.dock ResetLaunchPad -bool TRUE;killall Dock 慎用: 该指令重启launchpad的时候, 也会使launchpad的排序恢复默认值!!! 添加空白到Dock栏 空白能使Dock中的程序更好的归类. 按住Option可以拖动 defaults write com.apple.dock persistent-apps -array-add '{\u0026quot;tile-type\u0026quot;=\u0026quot;spacer-tile\u0026quot;;}'; killall Dock 状态栏调整 # 按住Command之后, 鼠标可以拖动状态栏图标 mac自带输入法 \u0026ndash; 简体拼音 # 记录一下常用快捷键 \u0026amp;\u0026amp; 配置 TAB \u0026ndash; 短按切换ABC与简体中文, 长按大小写 建议设置选词为竖屏, 横屏容易遮挡输入 不舒服的地方 输入的时候无法使用shift来切换为英文, 必须使用Enter或者Ctrl+任意健 候选词为横屏的时候, 会遮挡住输入区域 关闭内置键盘 # 苹果内置键盘不好用, 但是触控板非常好用. 习惯把HHKB放在苹果键盘上, 这样可以使用HHKB+苹果触控版 # For newer versions on MacOS / alternative solution: # List loaded kexts for keyboard kextstat | grep Keyboard # It's going to output something like: # 81 0 0xffffff7f833c5000 0xb000 0xb000 com.apple.driver.AppleHIDKeyboard (208) 96DDE905-9D31-38A9-96B7-FB28573587C8 \u0026lt;43 6 5 3\u0026gt; # com.apple.driver.AppleHIDKeyboard is loaded kext identifier. # If you want to plug-in Apple Magic Keyboard / some other Bluetooth keyboard, turn it off first. Then follow the instruction below. # To disable keyboard: sudo kextunload -b com.apple.driver.AppleHIDKeyboard # To enable it back: sudo kextload -b com.apple.driver.AppleHIDKeyboard 开机启动 # mac没有像linux使用init作为系统管理, 而是使用Launchd launchd # 定义一个由Launchd管理服务, 首先要有一个适用于该运行环境的程序, 比如在系统启动过程中不能使用图形交互API, 那么与用户交互的程序就不能在系统启动过程中被调用. 其次就是定制一个launchd规则的plist文件. 它是让launchd知道哪里以及如何运行一个程序,什么时候运行, 运行的规则等等等配置文件. 最后根据运行的方式, 把这个Plist文件存放到指定的位置, 并设置好文件属性等 级别 目录 操作系统级别的服务程序 /System/Library/LaunchDaemons /System/Library/LaunchAgents 本机全局 /Library/LaunchDaemons /Library/LaunchAgents 用户级别 ~/Library/LaunchAgents Daemons是一种无用户交互的服务程序, 而Agents是用户交互 当系统启动时, 依次执行/System/Library/LaunchDaemons 和 /Library/LaunchDaemons 当用户登陆时, 依次执行/System/Library/LaunchAgents, /Library/LaunchAgents 和 ~/Library/LaunchAgents 操作流程 # 编写自己的脚本, 并添加可执行权限 如果是Daemons调用, 需要给于777权限 编写plist文件 \u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE plist PUBLIC \u0026quot;-//Apple Computer//DTD PLIST 1.0//EN\u0026quot; \u0026quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd\u0026quot;\u0026gt; \u0026lt;plist version=\u0026quot;1.0\u0026quot;\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;Label\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;com.user.loginscript\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;ProgramArguments\u0026lt;/key\u0026gt; \u0026lt;array\u0026gt; \u0026lt;string\u0026gt;/path/to/my/script.sh\u0026lt;/string\u0026gt; \u0026lt;/array\u0026gt; \u0026lt;key\u0026gt;RunAtLoad\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/plist\u0026gt; 根据功能, plist文件放到不同的目录 load plist sudo launchctl load -w ~/Library/LaunchAgents/com.service.name.plist test launchctl start com.user.loginscript 实例 # 功能: 苹果开机时候 禁用内置键盘 创建mac_startup.sh \u0026amp;\u0026amp; 设置权限为777 #!/bin/bash ## disable mac internal keyboard sudo -S kextunload -b com.apple.driver.AppleHIDKeyboard \u0026gt; /dev/null 创建mac_startup.plist \u0026amp;\u0026amp; 放到/Library/LaunchDaemons \u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE plist PUBLIC \u0026quot;-//Apple Computer//DTD PLIST 1.0//EN\u0026quot; \u0026quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd\u0026quot;\u0026gt; \u0026lt;plist version=\u0026quot;1.0\u0026quot;\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;Label\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;com.mac.startup\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;ProgramArguments\u0026lt;/key\u0026gt; \u0026lt;array\u0026gt; \u0026lt;string\u0026gt;/Users/clay/mac_startup.sh\u0026lt;/string\u0026gt; \u0026lt;/array\u0026gt; \u0026lt;key\u0026gt;RunAtLoad\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/plist\u0026gt; load plist sudo launchctl load -w /Library/LaunchDaemons/mac_startup.plist 登陆测试 mac好用的软件 # Alfred # Alfred 是加强版的聚焦搜索, 支持自定义编程, 非常强大 之前先买了Manico, paster 发现这些功能Alfred都可以更好的完成... Karabiner 不推荐的原因是会导致部分电脑发热严重 # Karabiner 是一款好用的键位映射软件 HomeBrew # HomeBrew 是一款包管理软件, 类似于ubuntu下的apt Oh My Zsh # Oh My Zsh让终端显示更加丰富多彩 Annotate # Annotate (App Store下载) 是非常好用的截屏软件, 同时支持gif IINA # IINA 是mac下最好用的视频软件 Better Display # 更好的控制显示器. 尤其是对于2K显示器 https://github.com/waydabber/BetterDisplay mac实用技巧 # Dock上隐藏运行的程序 # 进入要隐藏的程序的Contents目录 cd App_Path/Contents 编辑info.plist文件 sudo vim info.plist 添加下面的代码 \u0026lt;key\u0026gt;LSUIElement\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; 上面的方法并不是万能的，有些软件并不能这么设置，设置了会导致打不开，例如teamview，应该还要修改其他设置，但是大多数软件都可以通过此方法进行修改，如果出错了按此方法修改回去就可以了 关于teamviewer的隐藏，需要在终端执行下面的命令 sudo bash -c 'killall TeamViewer_Service; killall TeamViewer; killall TeamViewer_Desktop; perl -i -0pe \u0026quot;s/\u0026lt;\\/dict\u0026gt;\\n\u0026lt;\\/plist\u0026gt;/\\t\u0026lt;key\u0026gt;LSUIElement\u0026lt;\\/key\u0026gt;\\n\\t\u0026lt;string\u0026gt;1\u0026lt;\\/string\u0026gt;\\n\u0026lt;\\/dict\u0026gt;\\n\u0026lt;\\/plist\u0026gt;/g\u0026quot; /Applications/TeamViewer.app/Contents/Info.plist; codesign -f -s - /Applications/TeamViewer.app; launchctl unload /Library/LaunchDaemons/com.teamviewer.teamviewer_service.plist; launchctl load /Library/LaunchDaemons/com.teamviewer.teamviewer_service.plist' mac卡顿处理 # 删除Macintosh HD/系统/资源库/Caches中的文件 删除Macintosh HD/资源库/Caches中的文件 如果以上无效, 建议更换操作系统版本, 比如从macOS high sierra更换为macOS Mojave 快捷键 # 系统偏好 \u0026ndash; 键盘 \u0026ndash; 快捷键 中修改快捷键 无用程序关闭 # 聚焦 作用: Command+空格的 聚焦搜索 影响进程: mds、mds_stores、mdworker 关闭原因: 实际没必要, 追求效率的, 可以关掉 #关闭 sudo mdutil -a -i off #打开 sudo mdutil -a -i on ssh远程连接mac os, 中文乱码 # 这种情况一般是终端和服务器的字符集不匹配，MacOSX下默认的是utf8字符集。输入locale可以查看字符编码设置情况，而我的对应值是空的。因为我在本地和服务器都用zsh替代了bash，而且使用了oh-my-zsh，而默认的.zshrc没有设置为utf-8编码，所以本地和服务器端都要在.zshrc设置，步骤如下，bash对应.bash_profile或.bashrc文件。 在.bash_profile中增加 export LC_ALL=en_US.UTF-8 export LANG=en_US.UTF-8 source .bash_profile locale 查看下是否设置成功 完成 查找错误 # mac崩溃原因查找 # 会打印mac 24小时崩溃的原因 # 常见原因 # 5 -- 正常关机 # 3 -- 硬件关机 (holding the power button) log show --predicate 'eventMessage contains \u0026quot;Previous shutdown cause\u0026quot;' --last 24h "},{"id":18,"href":"/docs/prog_language/elisp/","title":"elisp","section":"prog language","content":"参考文档 水木社区Emacs版 lisp的本质 基础语法 # 函数重载 # elisp没有重载的概念, 直接覆盖原定义即可. 相关函数: advice-add 根据key来决定old_fun 与 new_fun的关系 key desc filter-return 先执行old. new对old的结果再处理 before 先执行new, 过滤一下数据, 再把结果给old arround 先执行new, 并在new中主动调用old(也可以不调用) 使用defune 覆盖原函数定义 如果只是重载, 应该使用这种方法. advice-add的本意不是用来override elisp \u0026amp;\u0026amp; shell # bash调用elisp # elisp代码写入el文件(eshell script) bash调用emacs执行el文件 # 实际还是emacs 执行的elisp代码\remacs -u clay --script /Users/clay/.emacs.d/lisp/fun/init-hexo-fun.el\relisp 调用bashe # (setq my-command\r(concat \u0026quot;IFS=: read -ra dirs \u0026lt;\u0026lt;\u0026lt;\\\u0026quot;$PATH\\\u0026quot;\\n\u0026quot;\r\u0026quot;for dir in ${dirs[@]}; do\\n\u0026quot;\r\u0026quot; echo got dir \\\u0026quot;$dir\\\u0026quot;\\n\u0026quot;\r\u0026quot;done\\n\u0026quot;))\r(shell-command (format \u0026quot;bash -c %s\u0026quot; (shell-quote-argument my-command)))\r"},{"id":19,"href":"/docs/emacs/org/org_gtd/","title":"org \u0026\u0026 gtd","section":"org \u0026\u0026 gtd","content":" 需求分析 # 所有的设计都是基于需求的, 应该先有需求, 再去设计. 当前的需求: 有哪些task 他们归属于哪个PROJECT 他们的四象限: 紧急\u0026amp;\u0026amp;重要 工作量预估 关联性 A task可能与B, C相关联 TODO 该任务并未完成 当前正在处理的任务 尽可能的关注当前, 忽略其他 当某个task进行时, 快速capture我的想法, 并且自动refile 看到自己花费的时间 一天,一周都做了什么 某个PROJECT总共花费的时间 流程的设计 # -------------------------+------------------------\r|\r| capture (easy)\r|\r|\rv\rarchive +---------+\r+-------------------| inbox |\r| +----+----+\r| |\r| | refile (auto)\r| |\r| |\r| |----------------+--------------------|\r| | | |\r| | v v\r| v +---------+ +---------+\r| +---------+ | my/emacs| | work/qy |\r| | task | | * emacs| | * ker |\r| +----+----+ | * org | | * frame|\r| | | * ccIDE| | * sub |\r| | +---------+ +---------+\r| |\r| | archive (auto)\r| |\r| v\r| +---------+\r+-\u0026gt;| archive |\r+----+----+\r文件的设计 # 区分目录是为了更好的给PROJECT做分类处理, 使后续的统计查看更方便. 比如org-agenda `R统计时间 gtd\r\\_ gtd_common 通用gtd流程文件\r\\_ inbox 收集箱\r\\_ task 任务清单\r\\_ archive 归档文件\r\\_ gtd_emacs emacs project file\r\\_ gtd_qygame qygame project file\rgtd_common中保存的是一些通用的, 可能暂时不好归类的PROJECT以及TODO inbox.org 不区分时间,场景, 灵光一闪即可扔进去 task.org 任务清单 TODO: priority标签 四象限约束 PROEJCT: step\u0026gt;1都属于项目 archive.org 归档文件 gtd_emacs与gtd_qygame则是已经明确分类的PROJECT. 比如gtd_emacs/emacs.org明确的是与emacs有关的任务. 但即使都是emacs相关, 也可分为是emacs自身, org, 还是IDE. 所以emacs.org中实际包含了三个PROJECT: emacs, org, IDE TODO的设计 # TODO 等待自己处理 WAITTING 等待他人完成 PROJECT 项目 DONE 完成 CANCEL 取消 TAGS的设计 # 四象限使用proirity来区分; TAGS为之后快速查找使用 PROPERTY的设计 # 暂未使用 Effort的设计 # effort是自己对某个task工作量的预估. 与task完成时的clock-sum-time比对, 可以更好的进行分析. 为了方便的effort, 这里只在两处设计了提示: capture的时候, 可以输入effort. 当然为了快速capture, 这里允许输入0跳过 clock-in的时候, 如果item effort还是0, 则会要求进入工作预估 clock的设计 # org的clock已经非常好用了. 这里只是做了一点点修改: 快捷键快速clock-in, clock-out 如果当前处在clock, 会显示在frame的title中 capture设计 # 经常是在工作的时候, 突然有了某个想法. 这个想法也许值得记录, 但不要打断当前的思路. 所以capture应该是快速的, 但又要明确的(归属要明确) 为了快速capture, 所以不应该考虑这个想法应该放到哪个file. 统一放到inbox即可. 为了后面的auto refile, 这个想法或item 应该携带足够的信息, 可以完成auto refile. 这里的办法是给item一个tag. 比如 capture了一个item, 再给其增加对应的tag * org应该快速capture :org:\r这样就表明了这是一个与org PROJECT有关的task refile的设计 # refile应该是自动完成的, 不应该手动 为了自动完成, item已经给了相关信息(tag) 在gtd_my或gtd_work的PROJECT中, 也应该携带足够的信息去与该tag匹配. 只有匹配成功了, 就可以auto-refile 这里的办法是匹配PROJECT ITEM的heading, 比如: * PROJECT org\r当capute-item的tag 与 PROJECT-item的heading(org)相匹配的时候, 会自动refile archive的设计 # archive的目的: 在org file中隐藏已 DONE 的task 后期统计 归档 现在方案: 对于gtd_my, gtd_work中的task, archive到PROEJCT/archive下面 对于gtd_common中的task, archive到archive.org Agent的设计 # agent的目的有2个: 查看各种代办事项 今天的, 未来的, TODO的, inbox中的 统计信息 一是以time为视角的统计, 比如今天或这周做了哪些TODO或PROJECT 二是以PROJECT为视角的统计. 比如统计emacs PROJECT花费的时间 查看代办事项, 主要是org-agenda-view, org-next-view, org-inbox-view 查看 查看统计信息, 主要是org-project-view, org-archive-view 以及在特定PROJECT file中的org-colmun-view查看具体 org-next-view 显示todo|waiting items \u0026amp;\u0026amp; tuck project org-project-view中没必要包含gtd_common中的item org-archive-view中包含gtd_common中的TODO, PROJECT items 使用流程 # |\r| capture with add timestamp \u0026amp;\u0026amp; | template +---------+ auto refile +---------+ auto refile +---------+ archive +---------+\r+---------------\u0026gt;| inbxo |--------------\u0026gt;|next step|------------------\u0026gt;| agenda |--------------\u0026gt;| archive |\r| C-s C-s +---+-----+ +---------+ C-j s +---------+ C-j d +---------+\r| | ^\r| | archiv |\r| +----------------------------------------------------------------------------------+\r| C-j d\rcapture -\u0026gt; inbox 当打开org-agenda或者在org-agenda中按\u0026rsquo;r\u0026rsquo;, 会自动把inbox中的文件refile到指定位置 在org-agenda界面操控 C-j d调用archive, 完成archive动作 其实还有最后一步, 即把archive中的内容输出到blog中 "},{"id":20,"href":"/docs/tool/monitor/","title":"monitor","section":"tools","content":"cadvisor, influxdb, grafana 组成的监控系统 cadvisor 负责docker容器数据的收集 默认只显示2分钟的数据, 而且还没有保存, 因此需要数据库保存数据 influxdb 负责数据的保存 grafana 负责数据的展示, 其图表做的非常好 influxdb2.0 # 记录 创建流程 创建的时候需要先创建超级用户与组织org 这里的超级用户有web的权限, 貌似是web管理员 再创建bucket bucket = db + rp + ... 再创建数据库\u0026lt;db,rp\u0026gt;, 需要关联到bucket与org 再创建数据库用户 关联到bucket与org 这里的用户只是数据库的, 没有web的权限 常用命令 # 查看用户 influx user list \u0026ndash; 这里看到的是上面的超级用户, 有web权限的 influx v1 auth list \u0026ndash; 这里是查看数据库的, v1是1.0的接口 查看数据库 influx v1 dbrp list \u0026ndash; 可以看到db及其相关联的bucket等map信息 cadvisor # 写入influxdb中的数据格式 # _measurement \u0026ndash; 表 cpu_usage_per_cpu cpu_usage_system cpu_usage_total cpu_usage_user fs_limit fs_usage load_average memory_cache memory_failcnt memory_failure memory_mapped_file memory_max_usage memory_rss memory_swap memory_usage memory_working_set referenced_momory rx_bytes rx_erros tx_bytes tx_erros _field \u0026ndash; key value instance \u0026ndash; per_cpu的编号(cpu核) machine \u0026ndash; 物理机器名字 container_name \u0026ndash; 容器名字 device failure_type pgmajfault scope hierarchical type limit usage //确认 Group下面有: _start _stop _time _measurement grafana # 使用Flux查询influxdb注意事项 # from 前面不能加data =, 否则数据会流向data 不能加yield(), 否则数据不显示 from(bucket: \u0026quot;qybucket\u0026quot;) |\u0026gt; range(start: v.timeRangeStart, stop:v.timeRangeStop) |\u0026gt; filter(fn: (r) =\u0026gt; r._measurement == \u0026quot;cpu_usage_total\u0026quot; and r._field == \u0026quot;value\u0026quot; ) dashboard # 一个dashboard 由1个多个panel面板组成, 可以有多个dashboard 每个dashboard对应一个xx.yaml 每个面板对应一个配置文件xx.json dashboard的配置文件xx.yaml中有个特殊的字段, 可以把指定目录下的 子目录变为dashboard, 子目录下的xx.json变为面板 path: $GF_PATHS_PROVISIONING/dashboards foldersFromFilesStructure: true 当 foldersFromFilesStructure设置为true的时候, path下的子目录名字会变为dashboard的名字 子目录下的xx.json会变为该dashboard下的panel面板 这样我们只需要配置一个总的yaml, 然后规划path下的目录层级即可, 方便进行统一的管理 prometheus # "},{"id":21,"href":"/docs/prog_language/shell/","title":"shell","section":"prog language","content":"shell 记录 记录 # exit 与 return return 退出函数; 在非函数地方, 无效 exit 在任何地方, 都代表推出sh $# 代表入参 sh脚本的入参在非函数地方调用 函数的入参在调用函数的地方传递 $@ 可以传递所有的参数到下一层 数组使用echo打印的话 只会显示第一个 与 区别 更高级, 识别与或非等; 而[ ] 不识别 \u0026rsquo; \u0026rsquo; 与 \u0026quot; \u0026ldquo;区别 在 \u0026rsquo; \u0026lsquo;中的变量不会被展开; \u0026lsquo;$a\u0026rsquo;显示出来是字面值$a 空语句 是 : 数组 ${name[@]} ${name[*]} 获取函数返回值 return的返回值 可以通过 $?获取 但是该返回值返回的只能是0-255的数字 fun_check $? # 获取fun_check的返回值 echo的返回值 可以通过$()调用获取 ret=$(fun_check) 获取文件名 和 扩展名 file=\u0026quot;1.2.3.4.5\u0026quot; ${file%%.*} # =\u0026gt;1 ${file%.*} # =\u0026gt;1.2.3.4 ${file#*.} # =\u0026gt;2.3.4.5 ${file##*.} # =\u0026gt;5 "},{"id":22,"href":"/docs/emacs/lisp/tramp/","title":"tramp","section":"常用扩展","content":"全称 transparent remote access multiple protocol tramp是用来编辑远端文件的模块, 支持多种协议 ssh, ftp, smb, adb等, 常用method ssh su | sudo # 这种并不连接到远程主机, 而是允许使用另一个用户身份打开本地文件\r/su:root:path/\r用法 # basic # /method:user@host#port:/path/to/file\r# example 1\r/ssh:clay@192.1.1.1#22:~\r# example 2 windows下可以使用putty作为ssh的client\r/plink:clay@192.1.1.1:~\rset default method # (setq tramp-default-method \u0026quot;plink\u0026quot;)\r; 设置之后的例子\r; 可以设置linux和windows下默认的method，之后就无需考虑操作系统\r/-:clay@192.1.1.1:~\rmultiple hop # # 在本机上, 通过clay用户登录到host1\r# 再在host1上, 通过admin登录到host2\r/ssh:clay@host1|ssh:admin@host2:/path\rsu | sudo # # 使用sudo打开远程文件\r/-:clay@192.1.1.1|sudo::/path\r# 使用sudo打开本地文件\r# su::默认的是 su:root@localhost. 配置在tramp-default-method-alist\r/su::local-path\r/su:user@localhost:/local-path\r/sudo:root@localhost:/local-path\ruse with bookmarks # tramp使用的时候 需要使用到method user host path的组合，一般较长 我们更希望使用较短的shortcut去远程打开某个file 这里推荐的方法是bookmark. 理由: bookmark emacs内置, 而且非常方便 bookmark 的配置信息 可以方便git管理 使用方法: # 1.远程连接\rC-x f /ssh:clay@192.1.1.1:~\r# 2.添加到bookmark\rC-x C-f BOOK-NAME RET\r# 3.查看bookmark\rC-x C-f\r# 4.管理bookmark配置文件\r~/.emacs.d/bookmarks\r# 5.管理auth信息文件\r~/.emacs.d/authinfo\r"},{"id":23,"href":"/docs/emacs/lisp/graph/","title":"artist \u0026\u0026 plantuml","section":"常用扩展","content":" what # artist-mode和graphviz-mode都可以完成绘图的功能. 但artist-mode提供的功能过于基础, 使用的时候, 最好进行进一步封装. 可参考笔者自用的线和矩形, 提升artist-mode的使用体验 mode 简述 优点 缺点 artist-mode ASCII绘图 1.ASCII代码表示图形 1.功能少 2.短小精悍 2.需要手动绘制图形 graphviz-mode dot绘图 1.只关注逻辑设计,布局自动生成 1.生成的为图片文件, 而非可嵌入的ASCII代码 2.需要学习dot语言 "},{"id":24,"href":"/docs/tool/hugo/","title":"hugo","section":"tools","content":"使用hugo + github搭建blog 前言 # 记录blog好处很多, 却也增加了使用者的难度, 比如要理解html,css等. 同时,外在的表现往往会导致重心偏移, 过多追求外在的东西, 忽略了记录blog的初衷. 因此, 需要一个能让我们专注于文章知识本身, 而无需去关心其他的工具, 来帮助我们搭建blog. 当下, 一个不错的选择是hugo. hugo不拘束文章语言(markdown, org等), 自动将语言转化为html, 并且提供不错的主题外观, 使我们可以专注文章本身. hugo是什么 # 如上所言, hugo是一款不错的blog框架 主要优点: 不限制前端语言 自动化生成html 丰富便捷的themes 与github action无缝结合, 无须在本地搭建hugo运行环境 迅速上手, 学习时间短 对org-mode的支持可以忍受 hugo使用 # 安装 # 不建议在本地搭建hugo环境. 如果blog托管在github, 强烈推荐使用github action来部署. 配置 # hugo配置非常简单, 可以参考hugo.toml github action的配置, 可以参考yml 使用 # hugo官方guthub action是把content目录下的md文件, 转换为静态的html文件. 所以我们只要把自己的blog文件在官方之前, 转换为md文件放到content目录下面即可. 同样的, 我们也可以把自己生成的html文件直接放到content目录 虽然github action做了很多动作, 但我们需要做的只是维护自己的blog文件, 并git push即可. blog的更新流程由github action完成, 我们无须关心. hugo高级用法 # section \u0026amp;\u0026amp; bundle \u0026amp;\u0026amp; menu # key desc menu top navigation (所有文章|分类|标签|关于) section post|docs|menu等 bundle 文件资源的管理方式 bundle 只能是index.md 或者_index.md. 其他后缀名无效 TODO 增加bundle的详细解释 module # hugo module可以代替主题 使用步骤: 把自身仓库变为hugo module 实际就是增加了一个go.mod文件 在config.toml中增加module import 代替了theme, 所以这里的theme要删除, 否则hugo执行的时候会提示找不到theme 调用hugo时, hugo会主动下载module, 并且把它认定为theme文件 vs gitsubmodule 优势 gitsubmodule还需要管理使用的theme的信息, module完全不需要管理 gitsubmodule 可以使用 update \u0026ndash;remote来指定使用远程仓库信息, 但是繁琐, 不如go.mod方便 highlight # 代码高亮风格: hightlight style shortcode # TODO 待补充 简单理解, 每个hugo theme可以定义自己的shortcode 这样可以充分扩展 markdown的语法 自定义域名 # 实现子域名www.wcq.life 与 顶域名 wcq.life均可访问 hugo配置 # 修改配置文件 baseURL = \u0026quot;https://www.wcq.life\u0026quot; github配置 # 在blog/static目录下新增CNAME文件, 其内容为域名, 比如 www.wcq.life static目录下的内容, 会由hugo action自动放到网站根结点. 这符合github的要求 域名服务商配置 # wcq.life绑定教程 建议创建 wcq.life指向 github的A记录 www.wcq.life绑定教程 创建www.wcq.life指向clay9.github.io的CNAME即可 blank-line # hugo 默认使用goldmark作为md的解析器 设置markup.goldmark.renderer.hardWraps为true, goldmark 会把 \\n =\u0026gt; \u0026lt;br /\u0026gt; 如果在emacs中设置(setq org-export-preserve-breaks t), ox-hugo也会把 \\n =\u0026gt; \u0026lt;br /\u0026gt; 所以两者只需要设置一个, 这里建议设置emacs中的 hugo book theme # 基本概念 # hugo-book-theme 的file-tree-menu (这里的file-tree-menu 不是上面的menu) server \\_ _index \\_ view \\_ _index \\_ page_3 \\_ page_4 \\_ page_1 \\_ page_2 server/_index 是server的信息显示 server/view/_index是server/view的信息显示 (也可以没有) page_1, page_2的weight只影响自身节点(server节点)下的排序, 不会影响server/view节点 hugo_book 简介的显示, 需要放到content/_index.md中 参考文档 # 可以参考官方的例子去做 官方deamon对应的web展示 官方github网址 Q \u0026amp; A # buildFuture: hugo无法正常发布DATE等于今天的blog date导致的发布时间问题. 与github(美国时间)有时差, 导致发布的贴子无法立刻查看. date的本意是 创作时间. 但是publishData为空的时候, 猜测使用了date时间. 而date又有时差, 导致帖子无法立刻被查看. 解决方案: 在gh-pages.yml中为hugo增加参数 hugo \u0026ndash;minify \u0026ndash;buildFuture "},{"id":25,"href":"/docs/prog_compile/make/","title":"make","section":"prog compile","content":"make记录 常用 # make make clean make install \u0026ndash; 编译成功的文件安装到系统目录 make dist 产生发布软件包文件（即distribution package 这个命令将会将可执行文件及相关文件打包成一个tar.gz压缩的文件用来作为发布软件的软件包。 它会在当前目录下生成一个名字类似“PACKAGE-VERSION.tar.gz”的文件 PACKAGE和VERSION，是我们在configure.in中定义的AM_INIT_AUTOMAKE(PACKAGE, VERSION) make distcheck 生成发布软件包并对其进行测试检查，以确定发布包的正确性 这个操作将自动把压缩包文件解开，然后执行configure命令，并且执行make，来确认编译不出现错误 最后提示你软件包已经准备好，可以发布了 make # -j num 同时启动多少个jobs一起编译, 一般为系统内核数的2倍 make打印信息 不显示目录 make --no-print-directory make打印信息优化 SHOW_COMPILE=@echo -e \u0026quot;\\033[36mCompling \\033[35m==\u0026gt; \\033[33m$\u0026lt;\\033[0m\u0026quot; SHOW_LINK=@echo -e \u0026quot;\\033[31mLINKING \\033[35m==\u0026gt; \\033[33m$(EXEFILE)\\033[0m\u0026quot; SHOW_DEBUG_BUILD=@echo -e \u0026quot;\\033[31mBuilding Debug...\\033[0m\u0026quot; SHOW_RELEASE_BUILD=@echo -e \u0026quot;\\033[31mBuilding Release...\\033[0m\u0026quot; makefile 中的 \u0026ldquo;+ - @\u0026rdquo; 实际为shell中的规则, 不是makefile中的 符号 作用 @ 使命令被执行前不回显 - 使任何命令行的非0退出状态都被忽略 + 使命令行可以通过制定-n -q或-t选项来执行 内置函数 patsubst 格式：$(patsubst \u0026lt;pattern\u0026gt;,\u0026lt;replacement\u0026gt;,\u0026lt;text\u0026gt; ) 名称：模式字符串替换函数——patsubst。 功能：查找\u0026lt;text\u0026gt;中的单词（单词以“空格”、“Tab”或“回车”“换行”分隔）是否符合模式\u0026lt;pattern\u0026gt;，如果匹配的话，则以\u0026lt;replacement\u0026gt;替换。 这里，\u0026lt;pattern\u0026gt;可以包括通配符“%”，表示任意长度的字串。如果\u0026lt;replacement\u0026gt;中也包含“%”，那么，\u0026lt;replacement\u0026gt;中的这个“%”将是\u0026lt;pattern\u0026gt;中的那个“%”所代表的字串。 （可以用“\\”来转义，以“\\%”来表示真实含义的“%”字符） 返回：函数返回被替换过后的字符串。 示例： $(patsubst %.c,%.o, a.c b.c) 把字串“a.c b.c”符合模式[%.c]的单词替换成[%.o]，返回结果是“a.o b.o” $@ $^ $ $\u0026lt; $? $@ 表示目标文件 $^ 表示所有的依赖文件 $\u0026lt; 表示第一个依赖文件 $? 表示比目标还要新的依赖文件列表 gcc编译过程 预处理 -E .cpp -\u0026gt; .i 汇编 -S .i -\u0026gt; .s 编译 -c .s -\u0026gt; .o -o 仅仅是输出目标的file_name, 不一定是连接后的file_name, 比如 gcc -S hello.i -o hello.s gcc 不带参数可以 跟随.cpp .i .s .o类型的文件, 会自动执行预处理, 汇编, 编译, 连接的动作 所以连接不需要指定参数 wildcard Makefile规则中，通配符会被自动展开。但在变量的定义和函数引用时，通配符将失效。 这种情况下如果需要通配符有效，就需要使用函数“wildcard”，它的用法是：$(wildcard PATTERN\u0026hellip;) 。 在Makefile中，它被展开为已经存在的、使用空格分开的、匹配此模式的所有文件列表。 如果不存在任何符合此模式的文件，函数会忽略模式字符并返回空。 需要注意的是：这种情况下规则中通配符的展开和上一小节匹配通配符的区别。 makefile只能在taget的地方调用shell, 其他地方无效 其他地方调用需要使用 $(shell cmd) "},{"id":26,"href":"/docs/emacs/lisp/mail/","title":"mail","section":"常用扩展","content":"不建议使用, 没啥意义 简述 # emacs 流行的email client 有mu4e, notmuch, gnus等 因为对email不是刚需, 只是轻度使用, 所以这里选了内置对gnus. 理由如下: emacs 内置 顺便尝试 newsgroup 轻度使用email 反而发现gnus非常难配置, 因为可定制的选项太多了, 所以不是很友好\rgnus的缺点: 配置复杂, 花了24h才看完官方文档. 发现实际用到的也就5% ? gnus是单线程, 所以如果网络不好, 非常容易把emacs卡住, 比如访问gmail 基本概念 # gnus概念划分比较友好, server, group, summary, article 各司其职, 又互相联系, 比较方便, 具体可以参考官方文档 操作流程 # 设置server subscribe group enter group. show summary read article group level # group在gnus中是比较重要的概念. 而group level 可以更好的理解group 官方描述中: subscribe : 1 - guns-level-subscribed (5) unsubscribe: gnus-level-unsubscribed (7) zommbie: 8 killed: 9 level越高越不重要\r可以发现killed group有最高的level, 而unsubscribe level 和 subscribe level实际在gnus中处理差异不大. 所以如果不想看到某个组, 直接kill. 因为Gnus 不会向server询问zoomibe \u0026amp;\u0026amp; killed group的数据 gnus-group-list-group 显示 unread subscribe gnus-group-list-all-group 显示 subscribe \u0026amp;\u0026amp; unsubscribe mail # mail 在gnus中是一种特殊的group. 特殊在哪\u0026hellip;TODO 待补充 mail的设置非常简单, 因为我的需求只是阅读邮件, 所以使用了nnimap作为backend. 实际上gnus支持的mail back非常的多, 功能也非常强大 gmail 或者 国外的mail # 不建议使用国外mail, 网络不好会卡住emacs 如果一定要用, 推荐使用代理. 代理可以在emacs中配置, 也可以在代理软件中配置. 比如gmail: imap.gmail.com:993 smtp.gmail.com:587 下面的为个人猜测, 未验证\r如果设置了代理, 还是无法连接, 有可能是短时间连接次数过多, 被gamil服务器暂时拦截了 等一段时间再试即可 "},{"id":27,"href":"/docs/prog_compile/cmake/","title":"cmake","section":"prog compile","content":"cmake 参数 # -S path_to_source -B path_to_build -G generator-name cmake . -LH F\u0026amp;Q # err: Tell CMake where to find the compiler by setting either the environment variable \u0026quot;CXX\u0026quot; or the CMake cache entry CMAKE_CXX_COMPILER to the full path to the compiler, or to the compiler name if it is in the PATH. sln: sudo apt install gcc sudo apt install g++ "},{"id":28,"href":"/docs/emacs/lisp/gdb/","title":"gdb \u0026\u0026 gud","section":"常用扩展","content":" 简述 # emacs使用gud来绘制gdb的调试信息. gud可以认为是gdb的ui client. 具体可以参考github的init-gdb.el和一些自定义gud函数 gdb使用 # 指令 简写 描述 attach 附加到已经运行的程序 run r 运行程序，当遇到断点后，程序会在断点处停止运行，等待用户输入下一步命令 continue c 继续执行，到下一个断点停止（或运行结束） next n 单步跟踪程序，当遇到函数调用时，也不进入此函数体 step s 单步调试如果有函数调用，则进入函数；与命令n不同，n是不进入调用的函数的 until u 当你厌倦了在一个循环体内单步跟踪时，这个命令可以运行程序直到退出循环 until+行号 运行至某行，不仅仅用来跳出循环 finish 运行程序，直到当前函数完成返回，并打印函数返回时的堆栈地址和返回值及参数值等信息 quit q 退出gdb up 上个stack down 下个stack watch 变量监控 breakpoint b file :line_num 文件:行号 \u0026lt;fun_name\u0026gt; 函数名字 run相当于重新启动程序, 但是由于某些原因(找不到库? 怀疑是变量不同), 容易导致程序启动失败 continue 相当于继续执行, 一般在接attach和gdb Server之后使用, 使程序继续执行 gud使用 # buffer名字 简述 备注 gud gdb命令输入窗口 source 调试时自动显示源码 不要edit, 否则导致source自动关联失效 breakpoint 断点 不会命中的断点显示为pending threads 线程 stack 堆栈 local local变量 register 寄存器 assembler 显示汇编 memory 内存查看 为了显示方便, breakpoint与threads buffer同在一个frame; local与register buffer同在一个frame; 可以按\u0026quot;TAB\u0026quot;快速切换 例子 # emacs: M-x gdb RET gud: attch \u0026lt;program pid\u0026gt; 设置breakpoint gud: b source: gud-break; gud-tbreak breakpoint: D 删除断点 设置watch gud: watch souce: gud-watch 问题 # gud中在continue之后, 程序运行; 此时输入, gud并没有反应; 但是在程序运行到断点的时候, 之前的输入全部变成了命令. 简单来说, gud没有舍弃之前的无效输入, 而是等待机会, 使之生效 gdb continue之后 如何退出 gdb进程中可以使用C-c, 退出attach所关联的进程 emacs-gdb中如何退出 ?? TODONOW "},{"id":29,"href":"/docs/emacs/lisp/ai/","title":"AI","section":"常用扩展","content":" 简述 # 之前的IDE大多是基于语法的分析, AI代码助手提供了基于自然语义的分析. 效果非常的惊艳, 能更好的帮助编写文档与程序 当下流行的(2023-6)主要有: Github Copilot, Tabnine, Replit Ghostwriter, Amazon CodeWhisperer 和 Codeium 具体可以参考 测评文章 基于以下原因, 暂时使用了github copilot: 配置方便, emacs使用体验良好 github copilot # 使用 # github copilot 没有emacs的官方插件, 使用的是第三方package copilot. 安装与配置均比较简单, 可以参考copilot官方文档 其中需要开通github copilot, 建议在某宝购买github学生包, 便宜又方便, 但是容易被封, 千万不要使用自己的github账号\r;;国内可能无法访问github copilot, 可以配置一下代理\r(setq copilot-network-proxy '(:host \u0026quot;127.0.0.1\u0026quot; :port \u0026quot;10887\u0026quot;))\r快捷键配置 # copilot 与company-mode的一些快捷键容易冲突, 可以参考init-local-shortkey.el 使用体验 # github copilot自身还好, 但是github学生包账号非常容易被封, 略微影响使用体验 "},{"id":30,"href":"/docs/os/os/memory_01/","title":"memory 01","section":"os","content":"os中内存段页发展 参考文章 # 强烈推荐: x86段寄存器和分段机制 cpu发展历史 # x86(8086)之前 处理器4bits TODO 也许补充一下 x86 处理器变为16bits, 地址总线变为20根 为了能访问到所有的地址空间, 引入了 段寄存器 (CS,DS,SS,ES) 32bits 处理器变为32bits, 地址总线变为32根 为了能访问到所有的地址空间, 同时又要兼容x86, 同时os越来越普遍 引入了 段描述表寄存器 (GDTR, LDTR) 64bits 处理器变为64bits, 地址总线在40-48根 段寄存器 # 根据发展史, 知道段寄存器的引入是为了解决 cpu bits \u0026lt; 地址总线 的问题 x86把物理内存分割成一段段的, 段寄存器记录段的高16bits, 剩下的4bits放在IP寄存器. 因此, 进程要访问的线性地址 = (段reigster \u0026lt;\u0026lt; 4) + IP偏移 段描述表寄存器 # 32bits cpu时候, os越来越普遍(cpu 16bits时, os还不普及). 32bits cpu为了能完整的使用32地址总线, 同时也要满足os的各种需求(比如用户态, 内存态权限等), 需要对段进行详细的控制, 不仅仅是知道段基址. 在这种情形下, DTR (describe table register)被引入了. 进程在段register拿到index, 在DTR中找到index所在的内存地址(DTR只是表, describe info放在内存中). 去该内存地址中获取describe info. 这其中就包含了段基址 因此, 此时进程访问的线性地址 = [段基址] + IP偏移(这里IP寄存器出了32bits版 EIP) 此时根据硬件(EIP)发展进度, os对 段基址 使用不同的处理模式 有EIP的一般都会直接把 段基址 置为0. 因为不需要再对物理内存切段, 也可以完全访问了. 当出现64bit cpu时, 段基址 基本都被设置为了0. 线性地址 -\u0026gt; 物理地址 # 在32bits cpu之前, 线性地址即是物理地址 32bits cpu出现后(或是os出现后?), 需要翻译线性地址与物理地址. 这个翻译动作是硬件MMU做的 为什么需要 # 未考证, 不一定对 os中引入了进程, 不同进程的逻辑地址可能相同, 所以其线性地址也可能相同. 这将导致不同的进程访问了同一个物理内存地址. 而逻辑地址到线性地址是根据GDTR (global)获得的, 全局相同. 所以在线性地址到物理地址上做功夫 所以需要一个与进程关联的DTR(实际就是LDTR)来处理这个翻译动作. LDTR就是进程的段表. 线性地址(?待验证)在LDTR中找到describe info. 根据describe info 再找到物理内存即可. 但是这么处理, 对物理内存的利用率不高. 为了更好的利用物理内存, 使用分页. 分页 # 分页就是把物理内存切割成一页一页的, 即方便管理, 也方便使用. 为了与物理内存的一页页内存对应, 进程中每个段也是一页页的使用内存. 所以LDTR中应该保存 进程段页 与 物理页 之间的映射关系(即页表) 所以进程中线性地址到物理地址, 除了查段表, 也要看页表 根据段表, 在内存中找到页表, 根据页表, 找到真实的物理页. 这个动作是由MMU做的 多级页表 # 为了减少内存, 引入了多级页表. 缺点是导致内存查询次数增多. 每引入一层, 就需要额外查询一次内存 快表 TLB # 为了减少内存的查询次数, 引入的缓存表. 快表保存在寄存器中, 所以如果快表命中, 访问速度要比多级页表快很多 "},{"id":31,"href":"/docs/emacs/org/org_export/","title":"org exprot \u0026\u0026 ox-hugo","section":"org \u0026\u0026 gtd","content":"org自带强大的export功能. 但更多的是使用ox-hugo导出hugo样式的md, 再使用hugo生成html. ox-hugo # 常用样式 # basic # key format normal = monospace ~ key-binding + strike-through _ underline literal # org 自带, literal相关 example center quote html # org 自带, html或html5 基本不怎么使用, 容易影响hugo theme的布局 (存疑) hugo shortcode # 使用的是 hugo book theme, 所以这里只列出与之相关的 官方具体例子 columns expand hints 图片导出逻辑 # "},{"id":32,"href":"/docs/prog_compile/gcc/","title":"gcc","section":"prog compile","content":"gcc gcc # 查看搜索路径 g++ | gcc -print-serach-dirs (可通过\u0026ndash;help查看) 头文件搜索路径 gcc C_INCLUDE_PATH g++ CPLUS_INCLUDE_PATH ep: export CPLUS_INCLUDE_PATH=/usr/lib/ 扩展1 输出 echo $C_INCLUDE_PATH 调用 $C_INCLUDE_PATH 赋值 export C_INCLUDE_PATH 删除变量 unset C_INCLUDE_PATH C++调用 string strValue(getenv(\u0026ldquo;C_INCLUDE_PATH\u0026rdquo;) 库文件搜索路径 LIBRARY_PATH gcc编译时候需要 LD_LIBRARY_PATH 程序运行时候需要 g++ 编译参数 -rdynamic 与 -g # 总览 # g++ 编译的支持. -g可以增加调试信息(实际增加的为行号和函数符号等) g++ 编译的支持. -rdynamic. 增加符号信息(只有符号信息) g++ 中的-DDEBUG和-DNDEBUG只是增加了宏定义, 并不表示releas和debug版本. 实际的优化还是-O0 -O3 g++ 实际没有release和debug. -g是增加调试信息, -O3是程序编译优化, -DDEBUG是宏定义 如果加了-rdynamic, 不增加-g # 那么崩溃信息中, 崩溃地址 会使用符号名称+偏移地址 E20220104 18:16:43.152771 1127 qysignal.cpp:38] ./qy_gate(main+0x235) [0x408c33] 可以看到是main函数崩溃的, 具体位置在main函数偏移0x235, 即0x408c33 所以需要先计算main函数的位置, 然后加上+0x235 nm qy_gate |grep main 得到main的位置 假设偏移后的位置为0x1213, 那么通过下面的命令查看具体信息 addr2line -e qy_gate 0x1213 -sfC 实际上[0x408c33]中既是偏移后的地址, 不需要手动计算 会发现, 显示的信息为 main ??? : ? ???:? 是因为缺少调试信息,即g++编译时候无-g 如果不加-rdynamic # 日志会直接显示地址, 而不是符号+偏移地址 E20220104 18:16:43.152771 1127 qysignal.cpp:38] ./qy_gate(0x235) [0x408c33] 如果加-g # 通过addr2line -e qy_gate 0x1213 -sfC可以显示出具体的行号 main main.cpp : 12 总结 # 建议去掉-rdynamic, 增加-g 指定静态库 # -static 所有的-l都指定静态库, 找不到则报错 -Bstatic 对跟在后面的所有库执行静态链接 -l:\u0026lt;filename\u0026gt; -l:libmylib.a 只针对于-l的参数 "},{"id":33,"href":"/docs/os/dll/","title":"静态库 \u0026\u0026 动态库","section":"os","content":"linux下静态库 \u0026amp;\u0026amp; 动态库 差异区别 # 编译连接静态库时, 会copy一份静态库镜像到目标文件; 编译连接动态库时, 不会copy 程序运行时, 无须再去访问原静态库; 程序运行时, 要能访问到动态库文件 静态库 .a 动态库 .so (shared object) 生成方式 # 静态库 A.由源文件编译生成一堆.o，每个.o里都包含这个编译单元的符号表 B.ar命令将很多.o转换成.a，生成文静态库 动态库 A.gcc 加特定参数 编译 fPIC生成动态的.o文件; shared把动态.o文件打包为动态库 gcc -fPIC file1.c -c //这一步生成file1.o gcc -shared file1.o -o libtest.so //把.o文件打包为动态库(.o文件必须是 fPIC生成) 常见问题 # 运行时候找不到动态库, 处理方式 （1) 最直接最简单的方法就是把so拉到/usr/lib或/lib中去，但这好像有点污染环境吧？ （2）export LD_LIBRARY_PATH=$(pwd) （3）可以在/etc/ld.so.conf文件里加入我们生成的库的目录，然后/sbin/ldconfig 加载动态库 函数原型：void *dlopen(const char *libname,int flag); 参数中的libname一般是库的全路径，这样dlopen会直接装载该文件； 如果只是指定了库名称，在dlopen在查找库的过程中会按照如下路径进行搜索： a.根据环境变量LD_LIBRARY_PATH查找 b.根据/etc/ld.so.cache查找 c.查找依次在/lib和/usr/lib目录查找。 flag参数表示处理未定义函数的方式，可以使用RTLD_LAZY或RTLD_NOW。 RTLD_LAZY表示暂时不去处理未定义函数，先把库装载到内存，等用到没定义的函数再说； RTLD_NOW表示马上检查是否存在未定义的函数，若存在，则dlopen以失败告终。 动态库再认知 # 结论 # 动态库允许延迟定义, 但是在连接为可执行文件时, 所有动态库的声明必须有定义 测试 # A 依赖libbase.so, B依赖libA A编译的时候, 不指定libbase.so(但是要include base的头文件), 可以编译成功 延迟定义 B -lA 编译, 编译成功, 连接失败, 提示libA没有xxx的定义(在libbase中) 若B -lA -lbase, 则编译连接都成功 连接为执行文件的时候, 所有的声明都必须要有定义 而且这个定义可以是在A中-lbase, 也可以是在B中 -lbase 说明-lbase只是告之符合连接表而已 "},{"id":34,"href":"/docs/tool/redis/","title":"redis","section":"tools","content":"redis学习记录 基础 # 数据结构 # 二进制安全字符串 (key, value) 列表 (链表实现) 集合 排序集合 哈希 位数组(简单的位图) HyperLogLogs 概率数据结构 Streams 键值注意事项 # 键一般不要太大, 但又不要太短, 导致不可阅读. 需要平衡 值不能大于512MB 常用的指令 # 通用命令 # exist 返回1表示存在, 0表示不存在 del 删除 type 返回key对应值的类型, 不存在值, 则为none expire 设置过期时间(秒). key对应的过期时间也会被保存在磁盘上 或者set key 100 ex 10 -- 使用ex来简化expire\rpersist 删除key的过期时间, 并永久化 字符串 # get set getset 将键设置为新值, 并返回旧值为结果 链表相关 # 索引从0开始\rlpush (key v) 在链表的左侧(头部)添加元素 \u0026ndash; 常数时间 rpush (key v) 在链表的右侧(尾部)添加元素 \u0026ndash; 常数时间 可以一次推送多个数据. 返回结果为当前链表中的元素个数\rlrange (key arg1 arg2) 从链表中提取元素范围 \u0026ndash; 需要的时间与元素数量正比, 非常慢 参数可以为负数表示. -1表示最后一个元素, -2表示倒数第二个\rlpop (key) rpop (key) 返回结果为左侧或右侧的元素\rltrim (key arg1 arg2) 只保留范围内的元素, 删除链表其他元素 llen (key) 链表的长度 Hash # hmset hmget 检索多个字段(可单, 可全部) hget 检索单个字段 hgetall 检索所有字段 hincrby 可以对单个字段的val执行加操作 Set # sadd 添加新的元素 smembers 返回集合中的元素(未排序的, redis随意返回) sismember (Set key) 检测key是否是Set的成员. 返回1是,0不是 spop (key option\u0026amp; count) 删除count个随机的元素, 并返回给客户端 scard 返回集合中的元素个数 Sorted Set # 现根据score排序, score一致则根据key的字典值排序 zadd (ZSet key score val) 添加新的元素. 多了一个score的写入 zrange (ZSet index_b index_e option\u0026amp; withscores) 返回范围内的元素(正序的) zrevrange (ZSet index_b index_E option\u0026amp; withscores) 返回范围内的元素(倒序的) 额外参数withscores会输出元素的score\rzrangebyscore (ZSet -inf score_val) 返回有序集合中的score \u0026lt;= score_val的元素 zremrangebyscore (ZSet score_b zsocre_e) 删除集合中所有score在b,e之间的元素 zrank (ZSet key) 返回元素在正序集合中的index zrevrank (ZSet key) 返回元素在倒叙集合中的index "},{"id":35,"href":"/docs/tool/sql/","title":"数据库","section":"tools","content":"数据库开发 数据库开发 # win下 # 详细解释 原生接口 ODBC OLE ADO linux下 # 原生接口 ODBC sqlserver # 优缺点 # Docker安装sqlserver # 官方文档 搜索镜像 docker search mssql 安装镜像(这个是官网的) docker pull microsoft/mssql-server-linux 运行镜像, 创建容器 docker run -e \u0026ldquo;ACCEPT_EULA=Y\u0026rdquo; -e \u0026ldquo;SA_PASSWORD=hack@2020\u0026rdquo; -p 9988:1433 \u0026ndash;name mssql -d microsoft/mssql-server-linux 注: 如果不指定映射的端口, 则可能随机使用一个端口 密码必须8位数, 否则会创建失败 -p 第一个参数为主机端口, 第二参数为docker容器端口 进入容器 docker exec -it mssql bash 测试sql server命令 /opt/mssql-tools/bin/sqlcmd -S localhost -U SA -P \u0026ldquo;passwd\u0026rdquo; 如果启动失败 docker logs mssql 查看日志信息 sqlcmd用法 # 登录 /opt/mssql-tools/bin/sqlcmd -S 127.0.0.1 -U SA -P \u0026quot;hack@2020\u0026quot; 执行语句查询 select * from sys.databeses go 一定记得使用go unicode支持 # 排序规则会影响字符集 服务器 排序规则 数据库 排序规则 表中的字段 排序规则 排序规则会影响字符集, 比如排序规则为xx_UTF8, 那么其默认的字符集为unicode nchar nvarchar类型会无视排序规则, 直接把改字段变为unicode编码 使用的时候 记得加N, exp: N'排序规则' client 与 server # 最理想的状态 server 是 unicode编码(只要nchar, nvarchar即可) client 是 unicode编码 unixodbc 编译的时候, 添加了 utf8的支持 ./configure --enable-iconv=yes --with-iconv-char-enc=UTF-8 总结: 数据库表字段的编码, 服务器程序运行环境的编码, unixodbc编译时候的字符编码 三者需要统一, 这样写入数据库的时候 才不会乱码 服务器运行环境 locale可以查看 locale -a显示系统支持的字符集 遇到的奇怪的问题 \u0026amp;\u0026amp; 解决思路 # 简述: 通过odbc 操作sqlserver, 插入中文错误 现象: 读取sqlserver中文正常 插入sqlserver中文乱码 思路: 查看sqlserver 的编码集(排序规则) 查看qy-server的运行环境 locale 编译unixodbc的时候是否加入了编码的支持 查看odbc的配置文件 odbcinst -j 这次的问题在于 odb的配置文件中 有重名的DSN mysql # 优点: 缺点: 没有存储过程 ODBC # 安装odbc驱动 建议使用官方源码安装 http://www.unixodbc.org 下载源码之后 ./configure --enable-gui=no --enable-iconv=yes --with-iconv-char-enc=UTF-8 ./configure --enable-gui=no --enable-iconv=yes --with-iconv-char-enc=GB18030 这里需要添加中文支持, 不然会发生数据库读取中文正常, 写入中文时候乱码 安装对应的sql的驱动 这里sql的驱动是 odbc下的sql驱动 以mssql为例. 在microsoft官网下载 查看sql的驱动信息 debin在 /usr/local/etc/odbcinst.ini [ODBC Driver 17 for SQL Server] Description=Microsoft ODBC Driver 17 for SQL Server Driver=/opt/microsoft/msodbcsql17/lib64/libmsodbcsql-17.6.so.1.1 UsageCount=1 说明sql的驱动安装成功 编写DSN debin在 /usr/local/etc/odbc.ini [MssqlDB] Driver = ODBC Driver 17 for SQL Server Server = tcp:172.16.238.10,1433 测试安装 # 查看odbc是否已经安装 odbcinst -j # 查看驱动是否安装 odbcinst.ini odbcinst -q -d # 查看源是否安装 odbc.init odbcinst -q -s 测试连接 上面安装测试完成之后, 测试连接 isql MssqlDB user_name user_passwd -v 如果连接成功 +---------------------------------------+ | Connected! | | | | sql-statement | | help [tablename] | | quit | | | +---------------------------------------+ 连接失败的可能分析 先确认安装测试的3个命令执行正常 确认数据库的密码是否正确 在数据库的容器中查看$SA_PASSWORD, 与本地的密码比较 常用数据库语句 # sql server 查询sql版本 select @@version go 查询支持的字符集 只有2019版本 才支付utf-8字符集 select * from ::fn_helpcollations() go 查询当前系统的排序规则 SELECT SERVERPROPERTY('Collation') 查询排序规则的字符集 SELECT COLLATIONPROPERTY('Chinese_PRC_Stroke_CI_AI_KS_WS', 'CodePage') 936 简体中文GBK 950 繁体中文BIG5 437 美国/加拿大英语 932 日文 949 韩文 866 俄文 65001 unicode UFT-8 查询所有的库 select * from sys.databeses order by name go 有时候显示的数据太多, 我们可以只显示需要的比如 select name from sys.databeses order by name go 查询当前数据库所有表 方法一 select * from sys.objects where type='U' go \u0026ndash;XType=\u0026lsquo;U\u0026rsquo;:表示所有用户表; \u0026ndash;XType=\u0026lsquo;S\u0026rsquo;:表示所有系统表; 方法二 select * from sys.tables go 查询表中所有的字段 SELECT * FROM SysColumns WHERE id=Object_Id(\u0026lsquo;TableName\u0026rsquo;); SELECT COLLATIONPROPERTY(\u0026lsquo;Chinese_PRC_CS_AS_WS\u0026rsquo;, \u0026lsquo;CodePage\u0026rsquo;) SELECT COLLATIONPROPERTY(\u0026lsquo;Chinese_PRC_90_CI_AS_SC_UTF8\u0026rsquo;, \u0026lsquo;CodePage\u0026rsquo;) SELECT COLLATIONPROPERTY(\u0026lsquo;Latin1_General_100_CI_AI_SC_UTF8\u0026rsquo;, \u0026lsquo;CodePage\u0026rsquo;) SELECT COLLATIONPROPERTY(\u0026lsquo;SQL_Latin1_General_CP1_CI_AS\u0026rsquo;, \u0026lsquo;CodePage\u0026rsquo;) SELECT COLLATIONPROPERTY(\u0026lsquo;Chinese_Simplified_Stroke_Order_100_CI_AI\u0026rsquo;, \u0026lsquo;CodePage\u0026rsquo;) "},{"id":36,"href":"/docs/tool/protocol/","title":"乱七八糟的协议合集","section":"tools","content":"协议太多, 不好分类, 真是乱七八糟 简单协议 # 字符编码 # 写入内存过程: 符号 \u0026ndash;\u0026gt; 根据符号表(编码表), 找到符号的value \u0026ndash;\u0026gt; 根据实现算法(utf-8等), 计算出在内存中的值 \u0026ndash;\u0026gt; 内存值 解析过程: 内存值 \u0026ndash;\u0026gt; 根据算法, 计算出符号的value \u0026ndash;\u0026gt; 根据符号表, 找到value对应的符号 \u0026ndash;\u0026gt; 符号 编码小知识 # ios-8859-1 为http上所使用的编码 我在gitlab上面下载的代码虽然最原始是GBK编码（win下）， 下载到mac后 通过file -I 会被识别为iso-8859-1, 就是因为是http协议下载的。 所以转换为mac下可以使用的时候，做法应该是： iconv -f GBK -t UTF-8 file \u0026gt; file2 ASCII \u0026amp;\u0026amp; Unicode # 由来 ASCII码 \u0026ndash; 保存英文以及一些特殊控制字符 byte即2^8=256个符号 Unicode \u0026ndash; 1. ASCII符号表只能有256个符号, 不够其他国家使用, 比如汉字有10W+ 各个国家符号表(key)对应的value不同, 导致web通信困难(乱码), 为了统一, unicode出现 Unicode \u0026amp;\u0026amp; utf-8 # Unicod只是符号表, 其内部类似于这样 符号 Value 严 4E25 即我们的汉字\u0026quot;严\u0026quot; 对应的Unicode Value就是 4E25 但Unicode只是规定了符号表的map(key, value), 并没有规定value在内存中的存储形式, 比如little endian中\u0026quot;严\u0026quot;是25 4E 第一个字节为25, 第二个字节为4E 而 big endian中则是 4E 25 除了大小字节序问题, 4E 25的如何实现也有非常多的方法 常见的有utf-8 utf-16等等 所以utf-8只是实现Unicode的一种方式 比较重要的一点是, 为了兼容ASCII, ASCII对应的符号value, 在ASCII与utf-8中一致(即英文与控制符号一致) ASCII \u0026amp;\u0026amp; Unicode转换 # 这个转换确实纠结了我很久 转换的复杂性在于 字节长度问题 ASCII码的value是一个BYTE, 其value在内存中的实现也是一个byte Unicode的value是二个byte, 其Value在内存中的实现(utf-8)有1-5个byte 字节长度不同, 导致我们需要在char* 和 wchar_t*间转换 编码格式 注: 其实1应该也属于编码格式 因为ASCII 和 Unicode(自身)之间的实现方式差异很大, 在其中转换的时候要非常熟悉各种编码实现的原理 为了解决2个问题, 可以考虑一下2个函数, 虽然是windows下的: MultiByteToWideChar和WideCharToMultiByte 大小字节序 # 对于多字节, 比如 AE FF Big—Endian 大字节 如果在内存中 0x 0000 0001 AE 0x 0000 0002 FF 即内存中的低位保存的是高字节 则为Big-Endian little-Endian 小字节 如果在内存中 0x 0000 0001 FF 0x 0000 0002 AE 即内存中的低位保存的是低字节 则为little-Endian 网络上的传输为大字节序 所以在host传入到internet时候, 比如socket, 应该将字节序转换 ip地址详解 # 主机host的数量 决定了 选择 A类 B类 或者C类地址 hosts的划分, 即子网 决定了 掩码的值 掩码的值 决定了 ip地址的网络id 与 主机id A类的掩码 为 255.0.0.0 B类的掩码 为 255.255.0.0 C类的掩码 为 255.255.255.0 通过A类掩码 计算出 所能承载的host数量n, 按ip从0.0.0.0开始, 数到host数量n, 计算出A类ip地址范围 通过B类掩码 计算出 所能承载的host数量m 按A类广播地址+1开始, 数到m, 计算出B类ip地址范围 通过C类掩码 计算出 所能承载的host数量x 按B类广播地址+1开始, 数到x, 计算出C类ip地址范围 子网的第一个ip地址 和最后一个ip地址有特殊含义 第一个ip地址为 本机地址?????? 最后一个ip地址为广播地址 这2个地址 被设计用来做其他事情, 设计的时候不应该考虑吧进去 "},{"id":37,"href":"/posts/rup/","title":"rup架构图","section":"Posts","content":"RUP4+1架构图 临时记录 # 参考文章01 参考文章02 logic view # 逻辑视图. 逻辑视图关注功能. 在uml中由类图来表示 用户可见的功能 为实现用户功能而必须提供的\u0026quot;辅助功能模块\u0026quot; 它们可能是逻辑层、功能模块等 deployment view # 物理视图. 开发出的软件最终如何运行在物理或软件环境上. 在uml中通常使用部署图表示 \u0026ldquo;目标程序及其依赖的运行库和系统软件\u0026quot;最终如何安装或部署到物理机器 如何部署机器和网络来配合软件系统的可靠性、可伸缩性等要求 物理视图和处理视图的关系：\nprocess view特别关注目标程序的动态执行情况; 而deployment view重视目标程序的静态位置问题；deployment view是综合考虑软件系统和整个IT系统相互影响的架构视图。 implementation view # 开发视图. 关注软件开发环境下实际模块的组织, 反映系统开发实施过程. 在uml通常使用 ???TODO??? 表示. 关注程序包，不仅包括要编写的源程序，还包括可以直接使用的第三方SDK和现成框架、类库 以及开发的系统将运行于其上的系统软件或中间件 开发视图和逻辑视图之间可能存在一定的映射关系：比如逻辑层一般会映射到多个程序包等.\n一个设计良好的开发视图，应该能够满足以下要求：\n通过逻辑架构元素，能够找到它所有代码和所有的二进制交付件 每一个代码源文件，都能够找到它所属的逻辑架构元素 每一个二进制交付件，都能够找到它集成了哪些逻辑架构元素 process view # 处理视图. 在uml通常用时序图和流程图表示 关注进程、线程、对象等运行时概念 并发、同步、通信等问题 处理视图和开发视图的关系：\n开发视图一般偏重程序包在编译时期的静态依赖关系;\n而这些程序运行起来之后会表现为对象、线程、进程，处理视图比较关注的正是这些运行时单元的交互问题. use case viw # 场景视图，即4+1中的1.\n从前面的图可以看到，4+1中的4个视图都是围绕着场景视图为核心的. 它用于描述系统的参与者与功能用例间的关系，反映系统的最终需求和交互设计.\n在UML中通常由用例图表示 "},{"id":38,"href":"/posts/readme/","title":"Readme","section":"Posts","content":" 目录说明 # path desc org blog org源码 static hugo静态文件 config.toml hugo配置文件 流程 # push触发github action 下载 clay9/emacs.git 执行init-for-script.el, export org to md 执行hugo的编译, export md to html 执行hugo的发布 "}]